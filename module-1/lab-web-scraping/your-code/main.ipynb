{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping Lab\n",
    "\n",
    "You will find in this notebook some scrapy exercises to practise your scraping skills.\n",
    "\n",
    "**Tips:**\n",
    "\n",
    "- Check the response status code for each request to ensure you have obtained the intended contennt.\n",
    "- Print the response text in each request to understand the kind of info you are getting and its format.\n",
    "- Check for patterns in the response text to extract the data/info requested in each question.\n",
    "- Visit each url and take a look at its source through Chrome DevTools. You'll need to identify the html tags, special class names etc. used for the html content you are expected to extract."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Requests library](http://docs.python-requests.org/en/master/#the-user-guide) documentation \n",
    "- [Beautiful Soup Doc](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)\n",
    "- [Urllib](https://docs.python.org/3/library/urllib.html#module-urllib)\n",
    "- [re lib](https://docs.python.org/3/library/re.html)\n",
    "- [lxml lib](https://lxml.de/)\n",
    "- [Scrapy](https://scrapy.org/)\n",
    "- [List of HTTP status codes](https://en.wikipedia.org/wiki/List_of_HTTP_status_codes)\n",
    "- [HTML basics](http://www.simplehtmlguide.com/cheatsheet.php)\n",
    "- [CSS basics](https://www.cssbasics.com/#page_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Below are the libraries and modules you may need. `requests`,  `BeautifulSoup` and `pandas` are imported for you. If you prefer to use additional libraries feel free to uncomment them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "# from pprint import pprint\n",
    "# from lxml import html\n",
    "# from lxml.html import fromstring\n",
    "# import urllib.request\n",
    "# from urllib.request import urlopen\n",
    "# import random\n",
    "import re\n",
    "# import scrapy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download, parse (using BeautifulSoup), and print the content from the Trending Developers page from GitHub:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://github.com/trending/developers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code\n",
    "html = requests.get(url).content\n",
    "soup = BeautifulSoup(html, \"lxml\")\n",
    "#soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tiangolo\n",
      "felangel\n",
      "Tyriar\n",
      "bryphe\n",
      "imanghafoori1\n",
      "zhanghang1989\n",
      "coocood\n",
      "alex\n",
      "JakeWharton\n",
      "fzaninotto\n",
      "Palakis\n",
      "sapegin\n",
      "yurishkuro\n",
      "sorrycc\n",
      "edenhill\n",
      "soumith\n",
      "mholt\n",
      "mpociot\n",
      "hugobowne\n",
      "medikoo\n",
      "ijjk\n",
      "stsewd\n",
      "maximkulkin\n",
      "layershifter\n",
      "frenck\n"
     ]
    }
   ],
   "source": [
    "Boxes = soup.select('article',{\"class\":\"Box-row d-flex\"})\n",
    "for Box in Boxes:\n",
    "    match = re.findall('(id=\"(.*?)\")',str(Box)) \n",
    "    if match:\n",
    "        print (re.sub('(pa-)','',(match[0])[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the names of the trending developers retrieved in the previous step.\n",
    "\n",
    "Your output should be a Python list of developer names. Each name should not contain any html tag.\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "1. Find out the html tag and class names used for the developer names. You can achieve this using Chrome DevTools.\n",
    "\n",
    "1. Use BeautifulSoup to extract all the html elements that contain the developer names.\n",
    "\n",
    "1. Use string manipulation techniques to replace whitespaces and linebreaks (i.e. `\\n`) in the *text* of each html element. Use a list to store the clean names.\n",
    "\n",
    "1. Print the list of names.\n",
    "\n",
    "Your output should look like below:\n",
    "\n",
    "```\n",
    "['trimstray (@trimstray)',\n",
    " 'joewalnes (JoeWalnes)',\n",
    " 'charlax (Charles-AxelDein)',\n",
    " 'ForrestKnight (ForrestKnight)',\n",
    " 'revery-ui (revery-ui)',\n",
    " 'alibaba (Alibaba)',\n",
    " 'Microsoft (Microsoft)',\n",
    " 'github (GitHub)',\n",
    " 'facebook (Facebook)',\n",
    " 'boazsegev (Bo)',\n",
    " 'google (Google)',\n",
    " 'cloudfetch',\n",
    " 'sindresorhus (SindreSorhus)',\n",
    " 'tensorflow',\n",
    " 'apache (TheApacheSoftwareFoundation)',\n",
    " 'DevonCrawford (DevonCrawford)',\n",
    " 'ARMmbed (ArmMbed)',\n",
    " 'vuejs (vuejs)',\n",
    " 'fastai (fast.ai)',\n",
    " 'QiShaoXuan (Qi)',\n",
    " 'joelparkerhenderson (JoelParkerHenderson)',\n",
    " 'torvalds (LinusTorvalds)',\n",
    " 'CyC2018',\n",
    " 'komeiji-satori (神楽坂覚々)',\n",
    " 'script-8']\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the trending Python repositories in GitHub\n",
    "\n",
    "The steps to solve this problem is similar to the previous one except that you need to find out the repository names instead of developer names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://github.com/trending/python?since=daily'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>/rojter-tech/pluradl.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>/google-research/text-to-text-transfer-transfo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>/manchenkoff/skillbox-async-chat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>/senguptaumd/Background-Matting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>/pcomputo/Whole-Foods-Delivery-Slot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>/yenchenlin/nerf-pytorch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>/0voice/interview_internal_reference</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>/kon9chunkit/GitHub-Chinese-Top-Charts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>/qilingframework/qiling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>/CharlesPikachu/Games</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>/d2l-ai/d2l-zh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>/quantopian/zipline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>/aws/sagemaker-python-sdk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>/facebookresearch/maskrcnn-benchmark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>/TheAlgorithms/Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>/shenweichen/DeepMatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>/alex04072000/ObstructionRemoval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>/mkdocs/mkdocs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>/huggingface/transformers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>/renatoviolin/Question-Answering-Albert-Electra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>/nicolargo/glances</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>/quantumblacklabs/kedro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>/xingyizhou/CenterNet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>/kivy/kivy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>/pyqtgraph/pyqtgraph</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    0\n",
       "0                             /rojter-tech/pluradl.py\n",
       "1   /google-research/text-to-text-transfer-transfo...\n",
       "2                    /manchenkoff/skillbox-async-chat\n",
       "3                     /senguptaumd/Background-Matting\n",
       "4                 /pcomputo/Whole-Foods-Delivery-Slot\n",
       "5                            /yenchenlin/nerf-pytorch\n",
       "6                /0voice/interview_internal_reference\n",
       "7              /kon9chunkit/GitHub-Chinese-Top-Charts\n",
       "8                             /qilingframework/qiling\n",
       "9                               /CharlesPikachu/Games\n",
       "10                                     /d2l-ai/d2l-zh\n",
       "11                                /quantopian/zipline\n",
       "12                          /aws/sagemaker-python-sdk\n",
       "13               /facebookresearch/maskrcnn-benchmark\n",
       "14                              /TheAlgorithms/Python\n",
       "15                             /shenweichen/DeepMatch\n",
       "16                   /alex04072000/ObstructionRemoval\n",
       "17                                     /mkdocs/mkdocs\n",
       "18                          /huggingface/transformers\n",
       "19    /renatoviolin/Question-Answering-Albert-Electra\n",
       "20                                 /nicolargo/glances\n",
       "21                            /quantumblacklabs/kedro\n",
       "22                              /xingyizhou/CenterNet\n",
       "23                                         /kivy/kivy\n",
       "24                               /pyqtgraph/pyqtgraph"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#your code\n",
    "html = requests.get(url).content\n",
    "soup = BeautifulSoup(html, \"lxml\")\n",
    "Boxes = soup.select('h1',{\"class\":\"Box-row\"})\n",
    "Boxes\n",
    "Names = []\n",
    "for Box in Boxes:\n",
    "    match = re.findall('(href=\"(.*?)\")',str(Box)) \n",
    "    if match:\n",
    "        Names.append(re.sub('(href=)','',(match[0])[1]))\n",
    "pd.DataFrame(Names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display all the image links from Walt Disney wikipedia page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://en.wikipedia.org/wiki/Walt_Disney'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image links</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>upload.wikimedia.org/wikipedia/en/thumb/e/e7/C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>upload.wikimedia.org/wikipedia/en/thumb/1/1b/S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>upload.wikimedia.org/wikipedia/commons/thumb/d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>upload.wikimedia.org/wikipedia/commons/thumb/8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>upload.wikimedia.org/wikipedia/commons/thumb/c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>upload.wikimedia.org/wikipedia/commons/thumb/4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>upload.wikimedia.org/wikipedia/commons/thumb/0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>upload.wikimedia.org/wikipedia/commons/thumb/7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>upload.wikimedia.org/wikipedia/en/thumb/4/4e/S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>upload.wikimedia.org/wikipedia/commons/thumb/5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>upload.wikimedia.org/wikipedia/commons/thumb/c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>upload.wikimedia.org/wikipedia/commons/thumb/1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>upload.wikimedia.org/wikipedia/commons/thumb/1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>upload.wikimedia.org/wikipedia/commons/thumb/8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>upload.wikimedia.org/wikipedia/commons/thumb/f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>upload.wikimedia.org/wikipedia/commons/thumb/1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>upload.wikimedia.org/wikipedia/commons/thumb/2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>upload.wikimedia.org/wikipedia/commons/thumb/a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>upload.wikimedia.org/wikipedia/commons/thumb/6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>upload.wikimedia.org/wikipedia/en/thumb/8/8a/O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>upload.wikimedia.org/wikipedia/commons/thumb/4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>upload.wikimedia.org/wikipedia/commons/thumb/d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>upload.wikimedia.org/wikipedia/en/thumb/6/69/P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>upload.wikimedia.org/wikipedia/commons/thumb/1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>upload.wikimedia.org/wikipedia/en/thumb/e/e7/V...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>upload.wikimedia.org/wikipedia/commons/thumb/a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>upload.wikimedia.org/wikipedia/commons/thumb/8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>upload.wikimedia.org/wikipedia/en/thumb/a/a4/F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>upload.wikimedia.org/wikipedia/en/thumb/4/4a/C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>upload.wikimedia.org/wikipedia/commons/thumb/f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>upload.wikimedia.org/wikipedia/commons/thumb/f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>upload.wikimedia.org/wikipedia/en/thumb/8/8a/O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>en.wikipedia.org/wiki/Special:CentralAutoLogin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>/static/images/wikimedia-button.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>/static/images/poweredby_mediawiki_88x31.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          image links\n",
       "0   upload.wikimedia.org/wikipedia/en/thumb/e/e7/C...\n",
       "1   upload.wikimedia.org/wikipedia/en/thumb/1/1b/S...\n",
       "2   upload.wikimedia.org/wikipedia/commons/thumb/d...\n",
       "3   upload.wikimedia.org/wikipedia/commons/thumb/8...\n",
       "4   upload.wikimedia.org/wikipedia/commons/thumb/c...\n",
       "5   upload.wikimedia.org/wikipedia/commons/thumb/4...\n",
       "6   upload.wikimedia.org/wikipedia/commons/thumb/0...\n",
       "7   upload.wikimedia.org/wikipedia/commons/thumb/7...\n",
       "8   upload.wikimedia.org/wikipedia/en/thumb/4/4e/S...\n",
       "9   upload.wikimedia.org/wikipedia/commons/thumb/5...\n",
       "10  upload.wikimedia.org/wikipedia/commons/thumb/c...\n",
       "11  upload.wikimedia.org/wikipedia/commons/thumb/1...\n",
       "12  upload.wikimedia.org/wikipedia/commons/thumb/1...\n",
       "13  upload.wikimedia.org/wikipedia/commons/thumb/8...\n",
       "14  upload.wikimedia.org/wikipedia/commons/thumb/f...\n",
       "15  upload.wikimedia.org/wikipedia/commons/thumb/1...\n",
       "16  upload.wikimedia.org/wikipedia/commons/thumb/2...\n",
       "17  upload.wikimedia.org/wikipedia/commons/thumb/a...\n",
       "18  upload.wikimedia.org/wikipedia/commons/thumb/6...\n",
       "19  upload.wikimedia.org/wikipedia/en/thumb/8/8a/O...\n",
       "20  upload.wikimedia.org/wikipedia/commons/thumb/4...\n",
       "21  upload.wikimedia.org/wikipedia/commons/thumb/d...\n",
       "22  upload.wikimedia.org/wikipedia/en/thumb/6/69/P...\n",
       "23  upload.wikimedia.org/wikipedia/commons/thumb/1...\n",
       "24  upload.wikimedia.org/wikipedia/en/thumb/e/e7/V...\n",
       "25  upload.wikimedia.org/wikipedia/commons/thumb/a...\n",
       "26  upload.wikimedia.org/wikipedia/commons/thumb/8...\n",
       "27  upload.wikimedia.org/wikipedia/en/thumb/a/a4/F...\n",
       "28  upload.wikimedia.org/wikipedia/en/thumb/4/4a/C...\n",
       "29  upload.wikimedia.org/wikipedia/commons/thumb/f...\n",
       "30  upload.wikimedia.org/wikipedia/commons/thumb/f...\n",
       "31  upload.wikimedia.org/wikipedia/en/thumb/8/8a/O...\n",
       "32  en.wikipedia.org/wiki/Special:CentralAutoLogin...\n",
       "33                /static/images/wikimedia-button.png\n",
       "34       /static/images/poweredby_mediawiki_88x31.png"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#your code\n",
    "html = requests.get(url).content\n",
    "soup_images = BeautifulSoup(html, \"lxml\")\n",
    "images = soup_images.find_all('img')\n",
    "Images_list = []\n",
    "for image in images:\n",
    "    match = re.findall('(src=\"(.*?)\")',str(image)) \n",
    "    if match:\n",
    "        Images_list.append(re.sub('([/]{2})','',(match[0])[1]))\n",
    "pd.DataFrame(Images_list.copy(),columns = ['image links'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieve an arbitary Wikipedia page of \"Python\" and create a list of links on that page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url ='https://en.wikipedia.org/wiki/Python' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code\n",
    "html = requests.get(url).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>links</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>://en.wiktionary.org/wiki/Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>://en.wiktionary.org/wiki/Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>://en.wiktionary.org/wiki/Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>://en.wiktionary.org/wiki/Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>://en.wiktionary.org/wiki/Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>154</td>\n",
       "      <td>://en.wiktionary.org/wiki/Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155</td>\n",
       "      <td>://en.wiktionary.org/wiki/Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>156</td>\n",
       "      <td>://en.wiktionary.org/wiki/Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>157</td>\n",
       "      <td>://en.wiktionary.org/wiki/Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>158</td>\n",
       "      <td>://en.wiktionary.org/wiki/Python</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                links\n",
       "0    ://en.wiktionary.org/wiki/Python\n",
       "1    ://en.wiktionary.org/wiki/Python\n",
       "2    ://en.wiktionary.org/wiki/Python\n",
       "3    ://en.wiktionary.org/wiki/Python\n",
       "4    ://en.wiktionary.org/wiki/Python\n",
       "..                                ...\n",
       "154  ://en.wiktionary.org/wiki/Python\n",
       "155  ://en.wiktionary.org/wiki/Python\n",
       "156  ://en.wiktionary.org/wiki/Python\n",
       "157  ://en.wiktionary.org/wiki/Python\n",
       "158  ://en.wiktionary.org/wiki/Python\n",
       "\n",
       "[159 rows x 1 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup_Links = BeautifulSoup(html, \"lxml\")\n",
    "links = soup_Links.find_all('a')\n",
    "links_list = []\n",
    "for link in links:\n",
    "    match = re.findall('(href=\"https(.*?)\")',str(links)) \n",
    "    if match:\n",
    "        links_list.append(re.sub('(https=)','',(match[0])[1]))\n",
    "pd.DataFrame(links_list.copy(),columns=['links'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Titles that have changed in the United States Code since its last release point "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'http://uscode.house.gov/download/download.shtml'\n",
    "html = requests.get(url).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>titles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Title 1 - General Provisions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Title 3 - The President</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Title 4 - Flag and Seal, Seat of Government, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Title 5 - Government Organization and Employees</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Title 9 - Arbitration</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              titles\n",
       "0                      Title 1 - General Provisions \n",
       "1                           Title 3 - The President \n",
       "2  Title 4 - Flag and Seal, Seat of Government, a...\n",
       "3   Title 5 - Government Organization and Employees \n",
       "4                             Title 9 - Arbitration "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#your code\n",
    "soup_items = BeautifulSoup(html, \"lxml\")\n",
    "items = soup_items.find_all('div',{'class':'uscitem'})\n",
    "items\n",
    "items_list = []\n",
    "for item in items:\n",
    "    match = re.findall('((Title)+\\ . - (.*?) \\<)',str(item)) \n",
    "    if match:\n",
    "        #print(match[0])\n",
    "        items_list.append(re.sub('(<)','',(match[0])[0]))\n",
    "pd.DataFrame(items_list.copy(),columns=['titles'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A Python list with the top ten FBI's Most Wanted names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://www.fbi.gov/wanted/topten'\n",
    "html = requests.get(url).content\n",
    "soup_items = BeautifulSoup(html, \"lxml\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Top_Ten</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ALEXIS FLORES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>EUGENE PALMER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>SANTIAGO VILLALBA MEDEROS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>RAFAEL CARO-QUINTERO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ROBERT WILLIAM FISHER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>BHADRESHKUMAR CHETANBHAI PATEL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>ALEJANDRO ROSALES CASTILLO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>ARNOLDO JIMENEZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>YASER ABDEL SAID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>JASON DEREK BROWN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Top_Ten\n",
       "0                   ALEXIS FLORES\n",
       "1                   EUGENE PALMER\n",
       "2       SANTIAGO VILLALBA MEDEROS\n",
       "3            RAFAEL CARO-QUINTERO\n",
       "4           ROBERT WILLIAM FISHER\n",
       "5  BHADRESHKUMAR CHETANBHAI PATEL\n",
       "6      ALEJANDRO ROSALES CASTILLO\n",
       "7                 ARNOLDO JIMENEZ\n",
       "8                YASER ABDEL SAID\n",
       "9               JASON DEREK BROWN"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#your code  portal-type-person castle-grid-block-item\n",
    "names = soup_items.find_all('li',{'class':'portal-type-person castle-grid-block-item'})\n",
    "names\n",
    "names_list = []\n",
    "for name in names:\n",
    "    match = re.findall('(\\>(.*?)\\<)',str(name)) \n",
    "    if match:\n",
    "        names_list.append((match[2])[1])\n",
    "        \n",
    "pd.DataFrame(names_list.copy(),columns=['Top_Ten'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  20 latest earthquakes info (date, time, latitude, longitude and region name) by the EMSC as a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://www.emsc-csem.org/Earthquake/'\n",
    "res=requests.get(url) \n",
    "\n",
    "data=res.text\n",
    "\n",
    "soup=BeautifulSoup(data, 'html.parser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>2020-04-08   15:46:43.5</td>\n",
       "      <td>21min ago</td>\n",
       "      <td>37.47</td>\n",
       "      <td>N</td>\n",
       "      <td>36.01</td>\n",
       "      <td>E</td>\n",
       "      <td>3.0</td>\n",
       "      <td>CENTRAL TURKEY</td>\n",
       "      <td>2020-04-08 16:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>2020-04-08   15:29:30.0</td>\n",
       "      <td>39min ago</td>\n",
       "      <td>40.40</td>\n",
       "      <td>N</td>\n",
       "      <td>142.20</td>\n",
       "      <td>E</td>\n",
       "      <td>3.6</td>\n",
       "      <td>NEAR EAST COAST OF HONSHU, JAPAN</td>\n",
       "      <td>2020-04-08 15:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>2020-04-08   15:16:33.0</td>\n",
       "      <td>51min ago</td>\n",
       "      <td>16.85</td>\n",
       "      <td>N</td>\n",
       "      <td>100.25</td>\n",
       "      <td>W</td>\n",
       "      <td>4.0</td>\n",
       "      <td>OFFSHORE GUERRERO, MEXICO</td>\n",
       "      <td>2020-04-08 15:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>2020-04-08   15:10:47.3</td>\n",
       "      <td>57min ago</td>\n",
       "      <td>46.22</td>\n",
       "      <td>N</td>\n",
       "      <td>12.54</td>\n",
       "      <td>E</td>\n",
       "      <td>2.9</td>\n",
       "      <td>NORTHERN ITALY</td>\n",
       "      <td>2020-04-08 16:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>2020-04-08   14:57:27.0</td>\n",
       "      <td>1hr 11min ago</td>\n",
       "      <td>2.45</td>\n",
       "      <td>S</td>\n",
       "      <td>139.25</td>\n",
       "      <td>E</td>\n",
       "      <td>4.6</td>\n",
       "      <td>NEAR N COAST OF PAPUA, INDONESIA</td>\n",
       "      <td>2020-04-08 15:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>2020-04-08   14:32:30.0</td>\n",
       "      <td>1hr 36min ago</td>\n",
       "      <td>10.54</td>\n",
       "      <td>N</td>\n",
       "      <td>83.31</td>\n",
       "      <td>W</td>\n",
       "      <td>4.8</td>\n",
       "      <td>COSTA RICA</td>\n",
       "      <td>2020-04-08 14:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>2020-04-08   14:17:30.6</td>\n",
       "      <td>1hr 50min ago</td>\n",
       "      <td>44.38</td>\n",
       "      <td>N</td>\n",
       "      <td>115.20</td>\n",
       "      <td>W</td>\n",
       "      <td>3.2</td>\n",
       "      <td>SOUTHERN IDAHO</td>\n",
       "      <td>2020-04-08 14:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>2020-04-08   14:17:23.4</td>\n",
       "      <td>1hr 51min ago</td>\n",
       "      <td>42.90</td>\n",
       "      <td>N</td>\n",
       "      <td>13.15</td>\n",
       "      <td>E</td>\n",
       "      <td>2.4</td>\n",
       "      <td>CENTRAL ITALY</td>\n",
       "      <td>2020-04-08 14:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>2020-04-08   14:15:23.9</td>\n",
       "      <td>1hr 53min ago</td>\n",
       "      <td>44.40</td>\n",
       "      <td>N</td>\n",
       "      <td>115.13</td>\n",
       "      <td>W</td>\n",
       "      <td>2.6</td>\n",
       "      <td>SOUTHERN IDAHO</td>\n",
       "      <td>2020-04-08 14:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>2020-04-08   13:56:35.0</td>\n",
       "      <td>2hr 11min ago</td>\n",
       "      <td>4.03</td>\n",
       "      <td>S</td>\n",
       "      <td>133.83</td>\n",
       "      <td>E</td>\n",
       "      <td>3.7</td>\n",
       "      <td>NEAR S COAST OF PAPUA, INDONESIA</td>\n",
       "      <td>2020-04-08 14:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>2020-04-08   13:45:44.3</td>\n",
       "      <td>2hr 22min ago</td>\n",
       "      <td>17.96</td>\n",
       "      <td>N</td>\n",
       "      <td>66.83</td>\n",
       "      <td>W</td>\n",
       "      <td>2.6</td>\n",
       "      <td>PUERTO RICO</td>\n",
       "      <td>2020-04-08 14:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>2020-04-08   13:33:14.6</td>\n",
       "      <td>2hr 35min ago</td>\n",
       "      <td>19.22</td>\n",
       "      <td>N</td>\n",
       "      <td>155.42</td>\n",
       "      <td>W</td>\n",
       "      <td>2.3</td>\n",
       "      <td>ISLAND OF HAWAII, HAWAII</td>\n",
       "      <td>2020-04-08 13:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>2020-04-08   13:25:45.0</td>\n",
       "      <td>2hr 42min ago</td>\n",
       "      <td>18.70</td>\n",
       "      <td>N</td>\n",
       "      <td>71.68</td>\n",
       "      <td>W</td>\n",
       "      <td>3.3</td>\n",
       "      <td>DOMINICAN REPUBLIC</td>\n",
       "      <td>2020-04-08 15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>2020-04-08   13:20:21.2</td>\n",
       "      <td>2hr 48min ago</td>\n",
       "      <td>18.02</td>\n",
       "      <td>N</td>\n",
       "      <td>66.77</td>\n",
       "      <td>W</td>\n",
       "      <td>3.0</td>\n",
       "      <td>PUERTO RICO</td>\n",
       "      <td>2020-04-08 13:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>2020-04-08   13:13:55.8</td>\n",
       "      <td>2hr 54min ago</td>\n",
       "      <td>44.25</td>\n",
       "      <td>N</td>\n",
       "      <td>115.13</td>\n",
       "      <td>W</td>\n",
       "      <td>2.4</td>\n",
       "      <td>SOUTHERN IDAHO</td>\n",
       "      <td>2020-04-08 15:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>2020-04-08   13:04:07.5</td>\n",
       "      <td>3hr 04min ago</td>\n",
       "      <td>46.72</td>\n",
       "      <td>N</td>\n",
       "      <td>7.70</td>\n",
       "      <td>E</td>\n",
       "      <td>1.8</td>\n",
       "      <td>SWITZERLAND</td>\n",
       "      <td>2020-04-08 13:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>2020-04-08   12:38:13.9</td>\n",
       "      <td>3hr 30min ago</td>\n",
       "      <td>19.35</td>\n",
       "      <td>N</td>\n",
       "      <td>155.11</td>\n",
       "      <td>W</td>\n",
       "      <td>2.1</td>\n",
       "      <td>ISLAND OF HAWAII, HAWAII</td>\n",
       "      <td>2020-04-08 12:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>2020-04-08   12:32:30.0</td>\n",
       "      <td>3hr 36min ago</td>\n",
       "      <td>37.60</td>\n",
       "      <td>N</td>\n",
       "      <td>140.60</td>\n",
       "      <td>E</td>\n",
       "      <td>100</td>\n",
       "      <td>3.9</td>\n",
       "      <td>EASTERN HONSHU, JAPAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>2020-04-08 12:40</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>2020-04-08   12:26:37.0</td>\n",
       "      <td>3hr 41min ago</td>\n",
       "      <td>2.09</td>\n",
       "      <td>S</td>\n",
       "      <td>140.67</td>\n",
       "      <td>E</td>\n",
       "      <td>3.2</td>\n",
       "      <td>NEAR N COAST OF PAPUA, INDONESIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>2020-04-08 12:45</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>2020-04-08   12:23:29.2</td>\n",
       "      <td>3hr 45min ago</td>\n",
       "      <td>19.25</td>\n",
       "      <td>N</td>\n",
       "      <td>155.39</td>\n",
       "      <td>W</td>\n",
       "      <td>2.7</td>\n",
       "      <td>ISLAND OF HAWAII, HAWAII</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2020-04-08 12:56</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>2020-04-08   12:14:28.2</td>\n",
       "      <td>3hr 54min ago</td>\n",
       "      <td>17.87</td>\n",
       "      <td>N</td>\n",
       "      <td>66.89</td>\n",
       "      <td>W</td>\n",
       "      <td>2.7</td>\n",
       "      <td>PUERTO RICO REGION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>2020-04-08 12:32</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>2020-04-08   12:08:25.0</td>\n",
       "      <td>4hr 00min ago</td>\n",
       "      <td>18.47</td>\n",
       "      <td>N</td>\n",
       "      <td>68.25</td>\n",
       "      <td>W</td>\n",
       "      <td>3.4</td>\n",
       "      <td>MONA PASSAGE, DOMINICAN REPUBLIC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>2020-04-08 14:55</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>2020-04-08   11:50:09.0</td>\n",
       "      <td>4hr 18min ago</td>\n",
       "      <td>1.58</td>\n",
       "      <td>N</td>\n",
       "      <td>127.28</td>\n",
       "      <td>E</td>\n",
       "      <td>122</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>HALMAHERA, INDONESIA</td>\n",
       "      <td>2020-04-08 12:00</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>2020-04-08   11:50:03.7</td>\n",
       "      <td>4hr 18min ago</td>\n",
       "      <td>17.98</td>\n",
       "      <td>N</td>\n",
       "      <td>66.83</td>\n",
       "      <td>W</td>\n",
       "      <td>2.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>PUERTO RICO</td>\n",
       "      <td>2020-04-08 12:29</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>2020-04-08   11:44:46.8</td>\n",
       "      <td>4hr 23min ago</td>\n",
       "      <td>19.22</td>\n",
       "      <td>N</td>\n",
       "      <td>155.42</td>\n",
       "      <td>W</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>ISLAND OF HAWAII, HAWAII</td>\n",
       "      <td>2020-04-08 11:50</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>2020-04-08   11:36:02.2</td>\n",
       "      <td>4hr 32min ago</td>\n",
       "      <td>38.40</td>\n",
       "      <td>N</td>\n",
       "      <td>39.14</td>\n",
       "      <td>E</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>EASTERN TURKEY</td>\n",
       "      <td>2020-04-08 12:39</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>2020-04-08   11:35:22.6</td>\n",
       "      <td>4hr 33min ago</td>\n",
       "      <td>17.98</td>\n",
       "      <td>N</td>\n",
       "      <td>66.73</td>\n",
       "      <td>W</td>\n",
       "      <td>2.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>PUERTO RICO REGION</td>\n",
       "      <td>2020-04-08 12:03</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>2020-04-08   11:31:03.4</td>\n",
       "      <td>4hr 37min ago</td>\n",
       "      <td>19.21</td>\n",
       "      <td>N</td>\n",
       "      <td>155.41</td>\n",
       "      <td>W</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>ISLAND OF HAWAII, HAWAII</td>\n",
       "      <td>2020-04-08 11:36</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>2020-04-08   11:27:02.2</td>\n",
       "      <td>4hr 41min ago</td>\n",
       "      <td>19.24</td>\n",
       "      <td>N</td>\n",
       "      <td>155.43</td>\n",
       "      <td>W</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>ISLAND OF HAWAII, HAWAII</td>\n",
       "      <td>2020-04-08 11:39</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>2020-04-08   10:50:48.0</td>\n",
       "      <td>5hr 17min ago</td>\n",
       "      <td>37.41</td>\n",
       "      <td>N</td>\n",
       "      <td>20.69</td>\n",
       "      <td>E</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>IONIAN SEA</td>\n",
       "      <td>2020-04-08 11:43</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>2020-04-08   10:44:30.0</td>\n",
       "      <td>5hr 24min ago</td>\n",
       "      <td>39.60</td>\n",
       "      <td>N</td>\n",
       "      <td>142.10</td>\n",
       "      <td>E</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>NEAR EAST COAST OF HONSHU, JAPAN</td>\n",
       "      <td>2020-04-08 10:50</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>2020-04-08   10:40:01.0</td>\n",
       "      <td>5hr 28min ago</td>\n",
       "      <td>3.18</td>\n",
       "      <td>S</td>\n",
       "      <td>130.47</td>\n",
       "      <td>E</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>SERAM, INDONESIA</td>\n",
       "      <td>2020-04-08 11:10</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>2020-04-08   10:37:38.0</td>\n",
       "      <td>5hr 30min ago</td>\n",
       "      <td>3.13</td>\n",
       "      <td>S</td>\n",
       "      <td>130.51</td>\n",
       "      <td>E</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>SERAM, INDONESIA</td>\n",
       "      <td>2020-04-08 12:00</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>2020-04-08   10:34:16.9</td>\n",
       "      <td>5hr 34min ago</td>\n",
       "      <td>17.92</td>\n",
       "      <td>N</td>\n",
       "      <td>66.91</td>\n",
       "      <td>W</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>PUERTO RICO REGION</td>\n",
       "      <td>2020-04-08 12:02</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>2020-04-08   10:32:51.0</td>\n",
       "      <td>5hr 35min ago</td>\n",
       "      <td>0.86</td>\n",
       "      <td>S</td>\n",
       "      <td>100.00</td>\n",
       "      <td>E</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>SOUTHERN SUMATRA, INDONESIA</td>\n",
       "      <td>2020-04-08 12:00</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>2020-04-08   10:28:26.3</td>\n",
       "      <td>5hr 40min ago</td>\n",
       "      <td>17.93</td>\n",
       "      <td>N</td>\n",
       "      <td>66.92</td>\n",
       "      <td>W</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>PUERTO RICO REGION</td>\n",
       "      <td>2020-04-08 10:48</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>2020-04-08   10:06:24.1</td>\n",
       "      <td>6hr 02min ago</td>\n",
       "      <td>17.97</td>\n",
       "      <td>N</td>\n",
       "      <td>66.84</td>\n",
       "      <td>W</td>\n",
       "      <td>2.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>PUERTO RICO</td>\n",
       "      <td>2020-04-08 12:02</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>2020-04-08   10:02:31.8</td>\n",
       "      <td>6hr 05min ago</td>\n",
       "      <td>15.70</td>\n",
       "      <td>S</td>\n",
       "      <td>177.55</td>\n",
       "      <td>W</td>\n",
       "      <td>418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>5.4</td>\n",
       "      <td>FIJI REGION</td>\n",
       "      <td>2020-04-08 12:11</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>2020-04-08   09:41:09.7</td>\n",
       "      <td>6hr 27min ago</td>\n",
       "      <td>33.52</td>\n",
       "      <td>N</td>\n",
       "      <td>116.55</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>2.2</td>\n",
       "      <td>SOUTHERN CALIFORNIA</td>\n",
       "      <td>2020-04-08 09:43</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>2020-04-08   09:39:47.0</td>\n",
       "      <td>6hr 28min ago</td>\n",
       "      <td>15.60</td>\n",
       "      <td>N</td>\n",
       "      <td>95.44</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>3.9</td>\n",
       "      <td>OFFSHORE OAXACA, MEXICO</td>\n",
       "      <td>2020-04-08 13:05</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>2020-04-08   09:33:42.0</td>\n",
       "      <td>6hr 34min ago</td>\n",
       "      <td>18.08</td>\n",
       "      <td>N</td>\n",
       "      <td>71.56</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>3.1</td>\n",
       "      <td>DOMINICAN REPUBLIC</td>\n",
       "      <td>2020-04-08 10:50</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>2020-04-08   09:30:25.0</td>\n",
       "      <td>6hr 38min ago</td>\n",
       "      <td>33.52</td>\n",
       "      <td>N</td>\n",
       "      <td>116.54</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>2.2</td>\n",
       "      <td>SOUTHERN CALIFORNIA</td>\n",
       "      <td>2020-04-08 09:34</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>2020-04-08   09:27:00.7</td>\n",
       "      <td>6hr 41min ago</td>\n",
       "      <td>19.25</td>\n",
       "      <td>N</td>\n",
       "      <td>155.41</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>2.1</td>\n",
       "      <td>ISLAND OF HAWAII, HAWAII</td>\n",
       "      <td>2020-04-08 09:30</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>2020-04-08   09:19:02.2</td>\n",
       "      <td>6hr 49min ago</td>\n",
       "      <td>17.86</td>\n",
       "      <td>N</td>\n",
       "      <td>66.87</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>2.7</td>\n",
       "      <td>PUERTO RICO REGION</td>\n",
       "      <td>2020-04-08 09:48</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>2020-04-08   09:13:30.0</td>\n",
       "      <td>6hr 55min ago</td>\n",
       "      <td>23.92</td>\n",
       "      <td>S</td>\n",
       "      <td>67.03</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>245</td>\n",
       "      <td>3.9</td>\n",
       "      <td>SALTA, ARGENTINA</td>\n",
       "      <td>2020-04-08 09:27</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>2020-04-08   09:09:28.0</td>\n",
       "      <td>6hr 59min ago</td>\n",
       "      <td>9.95</td>\n",
       "      <td>S</td>\n",
       "      <td>119.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>E</td>\n",
       "      <td>3.7</td>\n",
       "      <td>SUMBA REGION, INDONESIA</td>\n",
       "      <td>2020-04-08 09:25</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>2020-04-08   09:05:54.0</td>\n",
       "      <td>7hr 02min ago</td>\n",
       "      <td>19.10</td>\n",
       "      <td>N</td>\n",
       "      <td>71.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>W</td>\n",
       "      <td>3.1</td>\n",
       "      <td>DOMINICAN REPUBLIC</td>\n",
       "      <td>2020-04-08 10:50</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>2020-04-08   09:02:31.5</td>\n",
       "      <td>7hr 05min ago</td>\n",
       "      <td>19.22</td>\n",
       "      <td>N</td>\n",
       "      <td>155.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>W</td>\n",
       "      <td>2.2</td>\n",
       "      <td>ISLAND OF HAWAII, HAWAII</td>\n",
       "      <td>2020-04-08 09:05</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>2020-04-08   08:54:58.0</td>\n",
       "      <td>7hr 13min ago</td>\n",
       "      <td>19.22</td>\n",
       "      <td>N</td>\n",
       "      <td>155.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>W</td>\n",
       "      <td>2.1</td>\n",
       "      <td>ISLAND OF HAWAII, HAWAII</td>\n",
       "      <td>2020-04-08 09:00</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>2020-04-08   08:52:10.0</td>\n",
       "      <td>7hr 16min ago</td>\n",
       "      <td>21.77</td>\n",
       "      <td>S</td>\n",
       "      <td>67.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>W</td>\n",
       "      <td>196</td>\n",
       "      <td>3.8</td>\n",
       "      <td>POTOSI, BOLIVIA</td>\n",
       "      <td>2020-04-08 09:07</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    0                          1  \\\n",
       "0                          earthquake    2020-04-08   15:46:43.5   \n",
       "1                          earthquake    2020-04-08   15:29:30.0   \n",
       "2                          earthquake    2020-04-08   15:16:33.0   \n",
       "3                          earthquake    2020-04-08   15:10:47.3   \n",
       "4                          earthquake    2020-04-08   14:57:27.0   \n",
       "5                          earthquake    2020-04-08   14:32:30.0   \n",
       "6                          earthquake    2020-04-08   14:17:30.6   \n",
       "7                          earthquake    2020-04-08   14:17:23.4   \n",
       "8                          earthquake    2020-04-08   14:15:23.9   \n",
       "9                          earthquake    2020-04-08   13:56:35.0   \n",
       "10                         earthquake    2020-04-08   13:45:44.3   \n",
       "11                         earthquake    2020-04-08   13:33:14.6   \n",
       "12                         earthquake    2020-04-08   13:25:45.0   \n",
       "13                         earthquake    2020-04-08   13:20:21.2   \n",
       "14                         earthquake    2020-04-08   13:13:55.8   \n",
       "15                         earthquake    2020-04-08   13:04:07.5   \n",
       "16                         earthquake    2020-04-08   12:38:13.9   \n",
       "17                         earthquake    2020-04-08   12:32:30.0   \n",
       "18                   2020-04-08 12:40                 earthquake   \n",
       "19                   2020-04-08 12:45                 earthquake   \n",
       "20                   2020-04-08 12:56                 earthquake   \n",
       "21                   2020-04-08 12:32                 earthquake   \n",
       "22                   2020-04-08 14:55                 earthquake   \n",
       "23               HALMAHERA, INDONESIA           2020-04-08 12:00   \n",
       "24                        PUERTO RICO           2020-04-08 12:29   \n",
       "25           ISLAND OF HAWAII, HAWAII           2020-04-08 11:50   \n",
       "26                     EASTERN TURKEY           2020-04-08 12:39   \n",
       "27                 PUERTO RICO REGION           2020-04-08 12:03   \n",
       "28           ISLAND OF HAWAII, HAWAII           2020-04-08 11:36   \n",
       "29           ISLAND OF HAWAII, HAWAII           2020-04-08 11:39   \n",
       "30                         IONIAN SEA           2020-04-08 11:43   \n",
       "31   NEAR EAST COAST OF HONSHU, JAPAN           2020-04-08 10:50   \n",
       "32                   SERAM, INDONESIA           2020-04-08 11:10   \n",
       "33                   SERAM, INDONESIA           2020-04-08 12:00   \n",
       "34                 PUERTO RICO REGION           2020-04-08 12:02   \n",
       "35        SOUTHERN SUMATRA, INDONESIA           2020-04-08 12:00   \n",
       "36                 PUERTO RICO REGION           2020-04-08 10:48   \n",
       "37                        PUERTO RICO           2020-04-08 12:02   \n",
       "38                                5.4                FIJI REGION   \n",
       "39                                2.2        SOUTHERN CALIFORNIA   \n",
       "40                                3.9    OFFSHORE OAXACA, MEXICO   \n",
       "41                                3.1         DOMINICAN REPUBLIC   \n",
       "42                                2.2        SOUTHERN CALIFORNIA   \n",
       "43                                2.1   ISLAND OF HAWAII, HAWAII   \n",
       "44                                2.7         PUERTO RICO REGION   \n",
       "45                                245                        3.9   \n",
       "46                                E                          3.7   \n",
       "47                                W                          3.1   \n",
       "48                                W                          2.2   \n",
       "49                                W                          2.1   \n",
       "50                                W                          196   \n",
       "\n",
       "                            2                        3  \\\n",
       "0                   21min ago                   37.47    \n",
       "1                   39min ago                   40.40    \n",
       "2                   51min ago                   16.85    \n",
       "3                   57min ago                   46.22    \n",
       "4               1hr 11min ago                    2.45    \n",
       "5               1hr 36min ago                   10.54    \n",
       "6               1hr 50min ago                   44.38    \n",
       "7               1hr 51min ago                   42.90    \n",
       "8               1hr 53min ago                   44.40    \n",
       "9               2hr 11min ago                    4.03    \n",
       "10              2hr 22min ago                   17.96    \n",
       "11              2hr 35min ago                   19.22    \n",
       "12              2hr 42min ago                   18.70    \n",
       "13              2hr 48min ago                   18.02    \n",
       "14              2hr 54min ago                   44.25    \n",
       "15              3hr 04min ago                   46.72    \n",
       "16              3hr 30min ago                   19.35    \n",
       "17              3hr 36min ago                   37.60    \n",
       "18    2020-04-08   12:26:37.0            3hr 41min ago   \n",
       "19    2020-04-08   12:23:29.2            3hr 45min ago   \n",
       "20    2020-04-08   12:14:28.2            3hr 54min ago   \n",
       "21    2020-04-08   12:08:25.0            4hr 00min ago   \n",
       "22    2020-04-08   11:50:09.0            4hr 18min ago   \n",
       "23                 earthquake  2020-04-08   11:50:03.7   \n",
       "24                 earthquake  2020-04-08   11:44:46.8   \n",
       "25                 earthquake  2020-04-08   11:36:02.2   \n",
       "26                 earthquake  2020-04-08   11:35:22.6   \n",
       "27                 earthquake  2020-04-08   11:31:03.4   \n",
       "28                 earthquake  2020-04-08   11:27:02.2   \n",
       "29                 earthquake  2020-04-08   10:50:48.0   \n",
       "30                 earthquake  2020-04-08   10:44:30.0   \n",
       "31                 earthquake  2020-04-08   10:40:01.0   \n",
       "32                 earthquake  2020-04-08   10:37:38.0   \n",
       "33                 earthquake  2020-04-08   10:34:16.9   \n",
       "34                 earthquake  2020-04-08   10:32:51.0   \n",
       "35                 earthquake  2020-04-08   10:28:26.3   \n",
       "36                 earthquake  2020-04-08   10:06:24.1   \n",
       "37                 earthquake  2020-04-08   10:02:31.8   \n",
       "38           2020-04-08 12:11               earthquake   \n",
       "39           2020-04-08 09:43               earthquake   \n",
       "40           2020-04-08 13:05               earthquake   \n",
       "41           2020-04-08 10:50               earthquake   \n",
       "42           2020-04-08 09:34               earthquake   \n",
       "43           2020-04-08 09:30               earthquake   \n",
       "44           2020-04-08 09:48               earthquake   \n",
       "45           SALTA, ARGENTINA         2020-04-08 09:27   \n",
       "46    SUMBA REGION, INDONESIA         2020-04-08 09:25   \n",
       "47         DOMINICAN REPUBLIC         2020-04-08 10:50   \n",
       "48   ISLAND OF HAWAII, HAWAII         2020-04-08 09:05   \n",
       "49   ISLAND OF HAWAII, HAWAII         2020-04-08 09:00   \n",
       "50                        3.8          POTOSI, BOLIVIA   \n",
       "\n",
       "                          4                        5              6        7  \\\n",
       "0                       N                     36.01             E        3.0   \n",
       "1                       N                    142.20             E        3.6   \n",
       "2                       N                    100.25             W        4.0   \n",
       "3                       N                     12.54             E        2.9   \n",
       "4                       S                    139.25             E        4.6   \n",
       "5                       N                     83.31             W        4.8   \n",
       "6                       N                    115.20             W        3.2   \n",
       "7                       N                     13.15             E        2.4   \n",
       "8                       N                    115.13             W        2.6   \n",
       "9                       S                    133.83             E        3.7   \n",
       "10                      N                     66.83             W        2.6   \n",
       "11                      N                    155.42             W        2.3   \n",
       "12                      N                     71.68             W        3.3   \n",
       "13                      N                     66.77             W        3.0   \n",
       "14                      N                    115.13             W        2.4   \n",
       "15                      N                      7.70             E        1.8   \n",
       "16                      N                    155.11             W        2.1   \n",
       "17                      N                    140.60             E        100   \n",
       "18                    2.09                       S          140.67       E     \n",
       "19                   19.25                       N          155.39       W     \n",
       "20                   17.87                       N           66.89       W     \n",
       "21                   18.47                       N           68.25       W     \n",
       "22                    1.58                       N          127.28       E     \n",
       "23            4hr 18min ago                   17.98             N     66.83    \n",
       "24            4hr 23min ago                   19.22             N    155.42    \n",
       "25            4hr 32min ago                   38.40             N     39.14    \n",
       "26            4hr 33min ago                   17.98             N     66.73    \n",
       "27            4hr 37min ago                   19.21             N    155.41    \n",
       "28            4hr 41min ago                   19.24             N    155.43    \n",
       "29            5hr 17min ago                   37.41             N     20.69    \n",
       "30            5hr 24min ago                   39.60             N    142.10    \n",
       "31            5hr 28min ago                    3.18             S    130.47    \n",
       "32            5hr 30min ago                    3.13             S    130.51    \n",
       "33            5hr 34min ago                   17.92             N     66.91    \n",
       "34            5hr 35min ago                    0.86             S    100.00    \n",
       "35            5hr 40min ago                   17.93             N     66.92    \n",
       "36            6hr 02min ago                   17.97             N     66.84    \n",
       "37            6hr 05min ago                   15.70             S    177.55    \n",
       "38  2020-04-08   09:41:09.7            6hr 27min ago         33.52       N     \n",
       "39  2020-04-08   09:39:47.0            6hr 28min ago         15.60       N     \n",
       "40  2020-04-08   09:33:42.0            6hr 34min ago         18.08       N     \n",
       "41  2020-04-08   09:30:25.0            6hr 38min ago         33.52       N     \n",
       "42  2020-04-08   09:27:00.7            6hr 41min ago         19.25       N     \n",
       "43  2020-04-08   09:19:02.2            6hr 49min ago         17.86       N     \n",
       "44  2020-04-08   09:13:30.0            6hr 55min ago         23.92       S     \n",
       "45               earthquake  2020-04-08   09:09:28.0  6hr 59min ago    9.95    \n",
       "46               earthquake  2020-04-08   09:05:54.0  7hr 02min ago   19.10    \n",
       "47               earthquake  2020-04-08   09:02:31.5  7hr 05min ago   19.22    \n",
       "48               earthquake  2020-04-08   08:54:58.0  7hr 13min ago   19.22    \n",
       "49               earthquake  2020-04-08   08:52:10.0  7hr 16min ago   21.77    \n",
       "50         2020-04-08 09:07                     None           None     None   \n",
       "\n",
       "                                    8                                  9  \n",
       "0                      CENTRAL TURKEY                   2020-04-08 16:05  \n",
       "1    NEAR EAST COAST OF HONSHU, JAPAN                   2020-04-08 15:35  \n",
       "2           OFFSHORE GUERRERO, MEXICO                   2020-04-08 15:41  \n",
       "3                      NORTHERN ITALY                   2020-04-08 16:05  \n",
       "4    NEAR N COAST OF PAPUA, INDONESIA                   2020-04-08 15:10  \n",
       "5                          COSTA RICA                   2020-04-08 14:43  \n",
       "6                      SOUTHERN IDAHO                   2020-04-08 14:35  \n",
       "7                       CENTRAL ITALY                   2020-04-08 14:24  \n",
       "8                      SOUTHERN IDAHO                   2020-04-08 14:44  \n",
       "9    NEAR S COAST OF PAPUA, INDONESIA                   2020-04-08 14:07  \n",
       "10                        PUERTO RICO                   2020-04-08 14:15  \n",
       "11           ISLAND OF HAWAII, HAWAII                   2020-04-08 13:38  \n",
       "12                 DOMINICAN REPUBLIC                   2020-04-08 15:00  \n",
       "13                        PUERTO RICO                   2020-04-08 13:45  \n",
       "14                     SOUTHERN IDAHO                   2020-04-08 15:19  \n",
       "15                        SWITZERLAND                   2020-04-08 13:11  \n",
       "16           ISLAND OF HAWAII, HAWAII                   2020-04-08 12:43  \n",
       "17                                3.9              EASTERN HONSHU, JAPAN  \n",
       "18                                3.2   NEAR N COAST OF PAPUA, INDONESIA  \n",
       "19                                2.7           ISLAND OF HAWAII, HAWAII  \n",
       "20                                2.7                 PUERTO RICO REGION  \n",
       "21                                3.4   MONA PASSAGE, DOMINICAN REPUBLIC  \n",
       "22                                122                                4.5  \n",
       "23                                W                                  2.9  \n",
       "24                                W                                  2.2  \n",
       "25                                E                                  2.5  \n",
       "26                                W                                  2.6  \n",
       "27                                W                                  2.3  \n",
       "28                                W                                  3.6  \n",
       "29                                E                                  2.8  \n",
       "30                                E                                  3.7  \n",
       "31                                E                                  4.3  \n",
       "32                                E                                  3.0  \n",
       "33                                W                                  3.2  \n",
       "34                                E                                  3.3  \n",
       "35                                W                                  3.2  \n",
       "36                                W                                  2.9  \n",
       "37                                W                                  418  \n",
       "38                            116.55                                 W    \n",
       "39                             95.44                                 W    \n",
       "40                             71.56                                 W    \n",
       "41                            116.54                                 W    \n",
       "42                            155.41                                 W    \n",
       "43                             66.87                                 W    \n",
       "44                             67.03                                 W    \n",
       "45                                S                              119.11   \n",
       "46                                N                               71.08   \n",
       "47                                N                              155.42   \n",
       "48                                N                              155.42   \n",
       "49                                S                               67.64   \n",
       "50                               None                               None  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#your code\n",
    "tables=soup.select('tbody')\n",
    "tables\n",
    "tables2 = []\n",
    "match = re.findall('(\\>(.*?)\\<)',str(tables))\n",
    "for i in match:\n",
    "    if len(i[1]) > 2:\n",
    "        tables2.append(i[1])\n",
    "tables3 =[]\n",
    "for i in range(0, len(tables2), 10):\n",
    "    chunk = tables2[i:i + 10]\n",
    "    tables3.append(chunk)\n",
    "earthq = pd.DataFrame(tables3)\n",
    "earthq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the date, days, title, city, country of next 25 hackathon events as a Pandas dataframe table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url ='https://hackevents.co/hackathons'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count number of tweets by a given Twitter account."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to include a ***try/except block*** for account names not found. \n",
    "<br>***Hint:*** the program should count the number of tweets for any provided account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise \n",
    "# You will need to add the account credentials to this url\n",
    "url = 'https://twitter.com/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of followers of a given twitter account"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to include a ***try/except block*** in case account/s name not found. \n",
    "<br>***Hint:*** the program should count the followers for any provided account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise \n",
    "# You will need to add the account credentials to this url\n",
    "url = 'https://twitter.com/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List all language names and number of related articles in the order they appear in wikipedia.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://www.wikipedia.org/'\n",
    "resp = requests.get(url).content\n",
    "soup = BeautifulSoup(resp,'lxml')\n",
    "languajes = soup.find_all('strong')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['English',\n",
       " 'Español',\n",
       " '日本語',\n",
       " 'Deutsch',\n",
       " 'Français',\n",
       " 'Русский',\n",
       " 'Italiano',\n",
       " '中文',\n",
       " 'Português',\n",
       " 'Polski']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#your code\n",
    "languajes_list=[]\n",
    "for i in range(1,len(strong)-1):\n",
    "    languajes_list.append(strong[i].text)\n",
    "languajes_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting unidecode\n",
      "  Downloading https://files.pythonhosted.org/packages/d0/42/d9edfed04228bacea2d824904cae367ee9efd05e6cce7ceaaedd0b0ad964/Unidecode-1.1.1-py2.py3-none-any.whl (238kB)\n",
      "Installing collected packages: unidecode\n",
      "Successfully installed unidecode-1.1.1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['6 050 000+ articles',\n",
       " '1 588 000+ articulos',\n",
       " '1 198 000+ Ji Shi ',\n",
       " '2 416 000+ Artikel',\n",
       " '2 197 000+ articles',\n",
       " '1 611 000+ statei',\n",
       " '1 595 000+ voci',\n",
       " '1 109 000+ Tiao Mu ',\n",
       " '1 027 000+ artigos',\n",
       " '1 399 000+ hasel']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!pip install unidecode\n",
    "import unidecode\n",
    "numbers = soup.find_all('small')\n",
    "numbers\n",
    "ln_1 = []\n",
    "for i in range(len(numbers)-3):\n",
    "    ln_1.append(unidecode.unidecode(numbers[i].text))\n",
    "ln_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Languajes</th>\n",
       "      <th>N.Articles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>English</td>\n",
       "      <td>6 050 000+ articles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Español</td>\n",
       "      <td>1 588 000+ articulos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>日本語</td>\n",
       "      <td>1 198 000+ Ji Shi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Deutsch</td>\n",
       "      <td>2 416 000+ Artikel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Français</td>\n",
       "      <td>2 197 000+ articles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Русский</td>\n",
       "      <td>1 611 000+ statei</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Italiano</td>\n",
       "      <td>1 595 000+ voci</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>中文</td>\n",
       "      <td>1 109 000+ Tiao Mu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Português</td>\n",
       "      <td>1 027 000+ artigos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Polski</td>\n",
       "      <td>1 399 000+ hasel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Languajes            N.Articles\n",
       "0    English   6 050 000+ articles\n",
       "1    Español  1 588 000+ articulos\n",
       "2        日本語    1 198 000+ Ji Shi \n",
       "3    Deutsch    2 416 000+ Artikel\n",
       "4   Français   2 197 000+ articles\n",
       "5    Русский     1 611 000+ statei\n",
       "6   Italiano       1 595 000+ voci\n",
       "7         中文   1 109 000+ Tiao Mu \n",
       "8  Português    1 027 000+ artigos\n",
       "9     Polski      1 399 000+ hasel"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_languajes = pd.DataFrame({\"Languajes\":languajes_list,\"N.Articles\":ln_1})\n",
    "df_languajes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A list with the different kind of datasets available in data.gov.uk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://data.gov.uk/'\n",
    "resp = requests.get(url).content\n",
    "soup = BeautifulSoup(resp,'lxml')\n",
    "dtasets_uk = soup.find_all('h2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Business and economy',\n",
       " 'Crime and justice',\n",
       " 'Defence',\n",
       " 'Education',\n",
       " 'Environment',\n",
       " 'Government',\n",
       " 'Government spending',\n",
       " 'Health',\n",
       " 'Mapping',\n",
       " 'Society',\n",
       " 'Towns and cities',\n",
       " 'Transport']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#your code \n",
    "dtasets_uk\n",
    "datasets = []\n",
    "for e in dtasets_uk:\n",
    "    datasets.append(e.text)\n",
    "datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top 10 languages by number of native speakers stored in a Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_languages_by_number_of_native_speakers'\n",
    "resp = requests.get(url).content\n",
    "soup = BeautifulSoup(resp,'lxml')\n",
    "tables = soup.find_all('table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Language</th>\n",
       "      <th>Speakers(millions)</th>\n",
       "      <th>% of the World population (March 2019)[8]</th>\n",
       "      <th>Language familyBranch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Mandarin Chinese</td>\n",
       "      <td>918.0</td>\n",
       "      <td>11.922</td>\n",
       "      <td>Sino-TibetanSinitic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>480.0</td>\n",
       "      <td>5.994</td>\n",
       "      <td>Indo-EuropeanRomance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>English</td>\n",
       "      <td>379.0</td>\n",
       "      <td>4.922</td>\n",
       "      <td>Indo-EuropeanGermanic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Hindi (Sanskritised Hindustani)[9]</td>\n",
       "      <td>341.0</td>\n",
       "      <td>4.429</td>\n",
       "      <td>Indo-EuropeanIndo-Aryan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>Bengali</td>\n",
       "      <td>228.0</td>\n",
       "      <td>2.961</td>\n",
       "      <td>Indo-EuropeanIndo-Aryan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                            Language  Speakers(millions)  \\\n",
       "0     1                    Mandarin Chinese               918.0   \n",
       "1     2                             Spanish               480.0   \n",
       "2     3                             English               379.0   \n",
       "3     4  Hindi (Sanskritised Hindustani)[9]               341.0   \n",
       "4     5                             Bengali               228.0   \n",
       "\n",
       "   % of the World population (March 2019)[8]    Language familyBranch  \n",
       "0                                     11.922      Sino-TibetanSinitic  \n",
       "1                                      5.994     Indo-EuropeanRomance  \n",
       "2                                      4.922    Indo-EuropeanGermanic  \n",
       "3                                      4.429  Indo-EuropeanIndo-Aryan  \n",
       "4                                      2.961  Indo-EuropeanIndo-Aryan  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#your code\n",
    "df_tables = pd.read_html(resp)\n",
    "df_tables[0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BONUS QUESTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scrape a certain number of tweets of a given Twitter account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise \n",
    "# You will need to add the account credentials to this url\n",
    "url = 'https://twitter.com/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IMDB's Top 250 data (movie name, Initial release, director name and stars) as a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise \n",
    "url = 'https://www.imdb.com/chart/top'\n",
    "resp = requests.get(url).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Rank &amp; Title</th>\n",
       "      <th>IMDb Rating</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.  Sueños de libertad  (1994)</td>\n",
       "      <td>9.2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.  El Padrino  (1972)</td>\n",
       "      <td>9.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.  El padrino 2a parte  (1974)</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.  Batman: El Caballero de la Noche  (2008)</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.  12 hombres en pugna  (1957)</td>\n",
       "      <td>8.9</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>245</td>\n",
       "      <td>NaN</td>\n",
       "      <td>246.  PK  (2014)</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>246</td>\n",
       "      <td>NaN</td>\n",
       "      <td>247.  Aladdín  (1992)</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>247</td>\n",
       "      <td>NaN</td>\n",
       "      <td>248.  Alma negra  (1949)</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>248</td>\n",
       "      <td>NaN</td>\n",
       "      <td>249.  Trono de sangre  (1957)</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>249</td>\n",
       "      <td>NaN</td>\n",
       "      <td>250.  El gabinete del Dr. Caligari  (1920)</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                  Rank & Title  IMDb Rating  \\\n",
       "0           NaN                1.  Sueños de libertad  (1994)          9.2   \n",
       "1           NaN                        2.  El Padrino  (1972)          9.1   \n",
       "2           NaN               3.  El padrino 2a parte  (1974)          9.0   \n",
       "3           NaN  4.  Batman: El Caballero de la Noche  (2008)          9.0   \n",
       "4           NaN               5.  12 hombres en pugna  (1957)          8.9   \n",
       "..          ...                                           ...          ...   \n",
       "245         NaN                              246.  PK  (2014)          8.0   \n",
       "246         NaN                         247.  Aladdín  (1992)          8.0   \n",
       "247         NaN                      248.  Alma negra  (1949)          8.0   \n",
       "248         NaN                 249.  Trono de sangre  (1957)          8.0   \n",
       "249         NaN    250.  El gabinete del Dr. Caligari  (1920)          8.0   \n",
       "\n",
       "     Unnamed: 4  \n",
       "0           NaN  \n",
       "1           NaN  \n",
       "2           NaN  \n",
       "3           NaN  \n",
       "4           NaN  \n",
       "..          ...  \n",
       "245         NaN  \n",
       "246         NaN  \n",
       "247         NaN  \n",
       "248         NaN  \n",
       "249         NaN  \n",
       "\n",
       "[250 rows x 4 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code\n",
    "df_tables = pd.read_html(resp)\n",
    "df_tops = df_tables[0]\n",
    "df_tops.drop('Your Rating', axis=1, inplace=True)\n",
    "df_tops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Movie name, year and a brief summary of the top 10 random movies (IMDB) as a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the url you will scrape in this exercise\n",
    "url = 'http://www.imdb.com/chart/top'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Rank &amp; Title</th>\n",
       "      <th>IMDb Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.  Sueños de libertad  (1994)</td>\n",
       "      <td>9.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.  El Padrino  (1972)</td>\n",
       "      <td>9.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.  El padrino 2a parte  (1974)</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.  Batman: El Caballero de la Noche  (2008)</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.  12 hombres en pugna  (1957)</td>\n",
       "      <td>8.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.  La lista de Schindler  (1993)</td>\n",
       "      <td>8.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.  El señor de los anillos: El retorno del re...</td>\n",
       "      <td>8.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.  Tiempos violentos  (1994)</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.  El bueno, el malo y el feo  (1966)</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.  El señor de los anillos: La comunidad del...</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                       Rank & Title  IMDb Rating\n",
       "0         NaN                     1.  Sueños de libertad  (1994)          9.2\n",
       "1         NaN                             2.  El Padrino  (1972)          9.1\n",
       "2         NaN                    3.  El padrino 2a parte  (1974)          9.0\n",
       "3         NaN       4.  Batman: El Caballero de la Noche  (2008)          9.0\n",
       "4         NaN                    5.  12 hombres en pugna  (1957)          8.9\n",
       "5         NaN                  6.  La lista de Schindler  (1993)          8.9\n",
       "6         NaN  7.  El señor de los anillos: El retorno del re...          8.9\n",
       "7         NaN                      8.  Tiempos violentos  (1994)          8.8\n",
       "8         NaN             9.  El bueno, el malo y el feo  (1966)          8.8\n",
       "9         NaN  10.  El señor de los anillos: La comunidad del...          8.8"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#your code\n",
    "df_tops.drop('Unnamed: 4', axis=1, inplace=True)\n",
    "df_tops.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the live weather report (temperature, wind speed, description and weather) of a given city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://openweathermap.org/current\n",
    "city = city=input('Enter the city:')\n",
    "url = 'http://api.openweathermap.org/data/2.5/weather?'+'q='+city+'&APPID=b35975e18dc93725acb092f7272cc6b8&units=metric'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Book name,price and stock availability as a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise. \n",
    "# It is a fictional bookstore created to be scraped. \n",
    "url = 'http://books.toscrape.com/'\n",
    "resp = requests.get(url).content\n",
    "soup = BeautifulSoup(resp,'lxml')\n",
    "books = soup.find_all('article')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>libro</th>\n",
       "      <th>precio</th>\n",
       "      <th>añadir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>A Light in the ...</td>\n",
       "      <td>£51.77</td>\n",
       "      <td>Add to basket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Tipping the Velvet</td>\n",
       "      <td>£53.74</td>\n",
       "      <td>Add to basket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Soumission</td>\n",
       "      <td>£50.10</td>\n",
       "      <td>Add to basket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Sharp Objects</td>\n",
       "      <td>£47.82</td>\n",
       "      <td>Add to basket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Sapiens: A Brief History ...</td>\n",
       "      <td>£54.23</td>\n",
       "      <td>Add to basket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>The Requiem Red</td>\n",
       "      <td>£22.65</td>\n",
       "      <td>Add to basket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>The Dirty Little Secrets ...</td>\n",
       "      <td>£33.34</td>\n",
       "      <td>Add to basket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>The Coming Woman: A ...</td>\n",
       "      <td>£17.93</td>\n",
       "      <td>Add to basket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>The Boys in the ...</td>\n",
       "      <td>£22.60</td>\n",
       "      <td>Add to basket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>The Black Maria</td>\n",
       "      <td>£52.15</td>\n",
       "      <td>Add to basket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>Starving Hearts (Triangular Trade ...</td>\n",
       "      <td>£13.99</td>\n",
       "      <td>Add to basket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>Shakespeare's Sonnets</td>\n",
       "      <td>£20.66</td>\n",
       "      <td>Add to basket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>Set Me Free</td>\n",
       "      <td>£17.46</td>\n",
       "      <td>Add to basket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>Scott Pilgrim's Precious Little ...</td>\n",
       "      <td>£52.29</td>\n",
       "      <td>Add to basket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>Rip it Up and ...</td>\n",
       "      <td>£35.02</td>\n",
       "      <td>Add to basket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>Our Band Could Be ...</td>\n",
       "      <td>£57.25</td>\n",
       "      <td>Add to basket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>Olio</td>\n",
       "      <td>£23.88</td>\n",
       "      <td>Add to basket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>Mesaerion: The Best Science ...</td>\n",
       "      <td>£37.59</td>\n",
       "      <td>Add to basket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>Libertarianism for Beginners</td>\n",
       "      <td>£51.33</td>\n",
       "      <td>Add to basket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>It's Only the Himalayas</td>\n",
       "      <td>£45.17</td>\n",
       "      <td>Add to basket</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    libro  precio         añadir\n",
       "0                      A Light in the ...  £51.77  Add to basket\n",
       "1                      Tipping the Velvet  £53.74  Add to basket\n",
       "2                              Soumission  £50.10  Add to basket\n",
       "3                           Sharp Objects  £47.82  Add to basket\n",
       "4            Sapiens: A Brief History ...  £54.23  Add to basket\n",
       "5                         The Requiem Red  £22.65  Add to basket\n",
       "6            The Dirty Little Secrets ...  £33.34  Add to basket\n",
       "7                 The Coming Woman: A ...  £17.93  Add to basket\n",
       "8                     The Boys in the ...  £22.60  Add to basket\n",
       "9                         The Black Maria  £52.15  Add to basket\n",
       "10  Starving Hearts (Triangular Trade ...  £13.99  Add to basket\n",
       "11                  Shakespeare's Sonnets  £20.66  Add to basket\n",
       "12                            Set Me Free  £17.46  Add to basket\n",
       "13    Scott Pilgrim's Precious Little ...  £52.29  Add to basket\n",
       "14                      Rip it Up and ...  £35.02  Add to basket\n",
       "15                  Our Band Could Be ...  £57.25  Add to basket\n",
       "16                                   Olio  £23.88  Add to basket\n",
       "17        Mesaerion: The Best Science ...  £37.59  Add to basket\n",
       "18           Libertarianism for Beginners  £51.33  Add to basket\n",
       "19                It's Only the Himalayas  £45.17  Add to basket"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#your code\n",
    "books\n",
    "books_data = []\n",
    "for row in books:\n",
    "    match = re.findall('(\\>(.*?)\\<)',str(row))\n",
    "    for e in match:\n",
    "        if len(e[1]) > 2:\n",
    "            books_data.append(e[1])\n",
    "books_data2 = []\n",
    "for i in range(0, len(books_data), 3):\n",
    "    chunk = books_data[i:i + 3]\n",
    "    books_data2.append(chunk)\n",
    "lib = pd.DataFrame(books_data2,columns = ['libro','precio','añadir'])\n",
    "lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
