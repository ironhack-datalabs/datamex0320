<!DOCTYPE html>
<html class="client-nojs" dir="ltr" lang="en">
<head>
<meta charset="utf-8"/>
<title>Generative adversarial network - Wikipedia</title>
<script>document.documentElement.className="client-js";RLCONF={"wgBreakFrames":!1,"wgSeparatorTransformTable":["",""],"wgDigitTransformTable":["",""],"wgDefaultDateFormat":"dmy","wgMonthNames":["","January","February","March","April","May","June","July","August","September","October","November","December"],"wgRequestId":"0d2dc783-8d17-4045-9f0b-42bd8301f4a9","wgCSPNonce":!1,"wgCanonicalNamespace":"","wgCanonicalSpecialPageName":!1,"wgNamespaceNumber":0,"wgPageName":"Generative_adversarial_network","wgTitle":"Generative adversarial network","wgCurRevisionId":949655233,"wgRevisionId":949655233,"wgArticleId":50073184,"wgIsArticle":!0,"wgIsRedirect":!1,"wgAction":"view","wgUserName":null,"wgUserGroups":["*"],"wgCategories":["CS1 errors: missing periodical","Articles with short description","All articles with unsourced statements","Articles with unsourced statements from January 2020","Articles with unsourced statements from February 2018","Portal templates with redlinked portals",
"Artificial neural networks","Cognitive science","Unsupervised learning"],"wgPageContentLanguage":"en","wgPageContentModel":"wikitext","wgRelevantPageName":"Generative_adversarial_network","wgRelevantArticleId":50073184,"wgIsProbablyEditable":!0,"wgRelevantPageIsProbablyEditable":!0,"wgRestrictionEdit":[],"wgRestrictionMove":[],"wgMediaViewerOnClick":!0,"wgMediaViewerEnabledByDefault":!0,"wgPopupsReferencePreviews":!1,"wgPopupsConflictsWithNavPopupGadget":!1,"wgVisualEditor":{"pageLanguageCode":"en","pageLanguageDir":"ltr","pageVariantFallbacks":"en"},"wgMFDisplayWikibaseDescriptions":{"search":!0,"nearby":!0,"watchlist":!0,"tagline":!1},"wgWMESchemaEditAttemptStepOversample":!1,"wgULSCurrentAutonym":"English","wgNoticeProject":"wikipedia","wgWikibaseItemId":"Q25104379","wgCentralAuthMobileDomain":!1,"wgEditSubmitButtonLabelPublish":!0};RLSTATE={"ext.globalCssJs.user.styles":"ready","site.styles":"ready","noscript":"ready","user.styles":"ready",
"ext.globalCssJs.user":"ready","user":"ready","user.options":"loading","ext.cite.styles":"ready","mediawiki.toc.styles":"ready","skins.vector.styles.legacy":"ready","wikibase.client.init":"ready","ext.visualEditor.desktopArticleTarget.noscript":"ready","ext.uls.interlanguage":"ready","ext.wikimediaBadges":"ready"};RLPAGEMODULES=["ext.cite.ux-enhancements","site","mediawiki.page.startup","skins.vector.js","mediawiki.page.ready","mediawiki.toc","ext.gadget.ReferenceTooltips","ext.gadget.charinsert","ext.gadget.refToolbar","ext.gadget.extra-toolbar-buttons","ext.gadget.switcher","ext.centralauth.centralautologin","mmv.head","mmv.bootstrap.autostart","ext.popups","ext.visualEditor.desktopArticleTarget.init","ext.visualEditor.targetLoader","ext.eventLogging","ext.wikimediaEvents","ext.navigationTiming","ext.uls.compactlinks","ext.uls.interface","ext.cx.eventlogging.campaigns","ext.quicksurveys.init","ext.centralNotice.geoIP","ext.centralNotice.startUp"];</script>
<script>(RLQ=window.RLQ||[]).push(function(){mw.loader.implement("user.options@1hzgi",function($,jQuery,require,module){/*@nomin*/mw.user.tokens.set({"patrolToken":"+\\","watchToken":"+\\","csrfToken":"+\\"});
});});</script>
<link href="/w/load.php?lang=en&amp;modules=ext.cite.styles%7Cext.uls.interlanguage%7Cext.visualEditor.desktopArticleTarget.noscript%7Cext.wikimediaBadges%7Cmediawiki.toc.styles%7Cskins.vector.styles.legacy%7Cwikibase.client.init&amp;only=styles&amp;skin=vector" rel="stylesheet"/>
<script async="" src="/w/load.php?lang=en&amp;modules=startup&amp;only=scripts&amp;raw=1&amp;skin=vector"></script>
<meta content="" name="ResourceLoaderDynamicStyles"/>
<link href="/w/load.php?lang=en&amp;modules=site.styles&amp;only=styles&amp;skin=vector" rel="stylesheet"/>
<meta content="MediaWiki 1.35.0-wmf.26" name="generator"/>
<meta content="origin" name="referrer"/>
<meta content="origin-when-crossorigin" name="referrer"/>
<meta content="origin-when-cross-origin" name="referrer"/>
<meta content="https://upload.wikimedia.org/wikipedia/commons/thumb/f/fe/Kernel_Machine.svg/1200px-Kernel_Machine.svg.png" property="og:image"/>
<link href="/w/index.php?title=Generative_adversarial_network&amp;action=edit" rel="alternate" title="Edit this page" type="application/x-wiki"/>
<link href="/w/index.php?title=Generative_adversarial_network&amp;action=edit" rel="edit" title="Edit this page"/>
<link href="/static/apple-touch/wikipedia.png" rel="apple-touch-icon"/>
<link href="/static/favicon/wikipedia.ico" rel="shortcut icon"/>
<link href="/w/opensearch_desc.php" rel="search" title="Wikipedia (en)" type="application/opensearchdescription+xml"/>
<link href="//en.wikipedia.org/w/api.php?action=rsd" rel="EditURI" type="application/rsd+xml"/>
<link href="//creativecommons.org/licenses/by-sa/3.0/" rel="license"/>
<link href="/w/index.php?title=Special:RecentChanges&amp;feed=atom" rel="alternate" title="Wikipedia Atom feed" type="application/atom+xml"/>
<link href="https://en.wikipedia.org/wiki/Generative_adversarial_network" rel="canonical"/>
<link href="//login.wikimedia.org" rel="dns-prefetch"/>
<link href="//meta.wikimedia.org" rel="dns-prefetch"/>
<!--[if lt IE 9]><script src="/w/resources/lib/html5shiv/html5shiv.js"></script><![endif]-->
</head>
<body class="mediawiki ltr sitedir-ltr mw-hide-empty-elt ns-0 ns-subject mw-editable page-Generative_adversarial_network rootpage-Generative_adversarial_network skin-vector action-view">
<div class="noprint" id="mw-page-base"></div>
<div class="noprint" id="mw-head-base"></div>
<div class="mw-body" id="content" role="main">
<a id="top"></a>
<div class="mw-body-content" id="siteNotice"><!-- CentralNotice --></div>
<div class="mw-indicators mw-body-content">
</div>
<h1 class="firstHeading" id="firstHeading" lang="en">Generative adversarial network</h1>
<div class="mw-body-content" id="bodyContent">
<div class="noprint" id="siteSub">From Wikipedia, the free encyclopedia</div>
<div id="contentSub"></div>
<div id="jump-to-nav"></div>
<a class="mw-jump-link" href="#mw-head">Jump to navigation</a>
<a class="mw-jump-link" href="#p-search">Jump to search</a>
<div class="mw-content-ltr" dir="ltr" id="mw-content-text" lang="en"><div class="mw-parser-output"><div class="hatnote navigation-not-searchable" role="note">Not to be confused with <a href="/wiki/Adversarial_machine_learning" title="Adversarial machine learning">Adversarial machine learning</a>.</div>
<div class="shortdescription nomobile noexcerpt noprint searchaux" style="display:none">Deep learning method</div>
<table class="vertical-navbox nowraplinks" style="float:right;clear:right;width:22.0em;margin:0 0 1.0em 1.0em;background:#f9f9f9;border:1px solid #aaa;padding:0.2em;border-spacing:0.4em 0;text-align:center;line-height:1.4em;font-size:88%"><tbody><tr><th style="padding:0.2em 0.4em 0.2em;font-size:145%;line-height:1.2em"><a href="/wiki/Machine_learning" title="Machine learning">Machine learning</a> and<br/><a href="/wiki/Data_mining" title="Data mining">data mining</a></th></tr><tr><td style="padding:0.2em 0 0.4em;padding:0.25em 0.25em 0.75em;"><a class="image" href="/wiki/File:Kernel_Machine.svg"><img alt="Kernel Machine.svg" data-file-height="233" data-file-width="512" decoding="async" height="100" src="//upload.wikimedia.org/wikipedia/commons/thumb/f/fe/Kernel_Machine.svg/220px-Kernel_Machine.svg.png" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/f/fe/Kernel_Machine.svg/330px-Kernel_Machine.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/f/fe/Kernel_Machine.svg/440px-Kernel_Machine.svg.png 2x" width="220"/></a></td></tr><tr><td style="padding:0 0.1em 0.4em">
<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left">Problems</div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">
<ul><li><a href="/wiki/Statistical_classification" title="Statistical classification">Classification</a></li>
<li><a href="/wiki/Cluster_analysis" title="Cluster analysis">Clustering</a></li>
<li><a href="/wiki/Regression_analysis" title="Regression analysis">Regression</a></li>
<li><a href="/wiki/Anomaly_detection" title="Anomaly detection">Anomaly detection</a></li>
<li><a href="/wiki/Automated_machine_learning" title="Automated machine learning">AutoML</a></li>
<li><a href="/wiki/Association_rule_learning" title="Association rule learning">Association rules</a></li>
<li><a href="/wiki/Reinforcement_learning" title="Reinforcement learning">Reinforcement learning</a></li>
<li><a href="/wiki/Structured_prediction" title="Structured prediction">Structured prediction</a></li>
<li><a href="/wiki/Feature_engineering" title="Feature engineering">Feature engineering</a></li>
<li><a href="/wiki/Feature_learning" title="Feature learning">Feature learning</a></li>
<li><a href="/wiki/Online_machine_learning" title="Online machine learning">Online learning</a></li>
<li><a href="/wiki/Semi-supervised_learning" title="Semi-supervised learning">Semi-supervised learning</a></li>
<li><a href="/wiki/Unsupervised_learning" title="Unsupervised learning">Unsupervised learning</a></li>
<li><a href="/wiki/Learning_to_rank" title="Learning to rank">Learning to rank</a></li>
<li><a href="/wiki/Grammar_induction" title="Grammar induction">Grammar induction</a></li></ul>
</div></div></div></td>
</tr><tr><td style="padding:0 0.1em 0.4em">
<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><div style="padding:0.1em 0;line-height:1.2em;"><a href="/wiki/Supervised_learning" title="Supervised learning">Supervised learning</a><br/><style data-mw-deduplicate="TemplateStyles:r886047488">.mw-parser-output .nobold{font-weight:normal}</style><span class="nobold"><span style="font-size:85%;">(<b><a href="/wiki/Statistical_classification" title="Statistical classification">classification</a></b> • <b><a href="/wiki/Regression_analysis" title="Regression analysis">regression</a></b>)</span></span> </div></div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">
<ul><li><a href="/wiki/Decision_tree_learning" title="Decision tree learning">Decision trees</a></li>
<li><a href="/wiki/Ensemble_learning" title="Ensemble learning">Ensembles</a>
<ul><li><a href="/wiki/Bootstrap_aggregating" title="Bootstrap aggregating">Bagging</a></li>
<li><a href="/wiki/Boosting_(machine_learning)" title="Boosting (machine learning)">Boosting</a></li>
<li><a href="/wiki/Random_forest" title="Random forest">Random forest</a></li></ul></li>
<li><a href="/wiki/K-nearest_neighbors_algorithm" title="K-nearest neighbors algorithm"><i>k</i>-NN</a></li>
<li><a href="/wiki/Linear_regression" title="Linear regression">Linear regression</a></li>
<li><a href="/wiki/Naive_Bayes_classifier" title="Naive Bayes classifier">Naive Bayes</a></li>
<li><a href="/wiki/Artificial_neural_network" title="Artificial neural network">Artificial neural networks</a></li>
<li><a href="/wiki/Logistic_regression" title="Logistic regression">Logistic regression</a></li>
<li><a href="/wiki/Perceptron" title="Perceptron">Perceptron</a></li>
<li><a href="/wiki/Relevance_vector_machine" title="Relevance vector machine">Relevance vector machine (RVM)</a></li>
<li><a href="/wiki/Support-vector_machine" title="Support-vector machine">Support vector machine (SVM)</a></li></ul>
</div></div></div></td>
</tr><tr><td style="padding:0 0.1em 0.4em">
<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><a href="/wiki/Cluster_analysis" title="Cluster analysis">Clustering</a></div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">
<ul><li><a href="/wiki/BIRCH" title="BIRCH">BIRCH</a></li>
<li><a class="mw-redirect" href="/wiki/CURE_data_clustering_algorithm" title="CURE data clustering algorithm">CURE</a></li>
<li><a href="/wiki/Hierarchical_clustering" title="Hierarchical clustering">Hierarchical</a></li>
<li><a href="/wiki/K-means_clustering" title="K-means clustering"><i>k</i>-means</a></li>
<li><a href="/wiki/Expectation%E2%80%93maximization_algorithm" title="Expectation–maximization algorithm">Expectation–maximization (EM)</a></li>
<li><br/><a href="/wiki/DBSCAN" title="DBSCAN">DBSCAN</a></li>
<li><a href="/wiki/OPTICS_algorithm" title="OPTICS algorithm">OPTICS</a></li>
<li><a class="mw-redirect" href="/wiki/Mean-shift" title="Mean-shift">Mean-shift</a></li></ul>
</div></div></div></td>
</tr><tr><td style="padding:0 0.1em 0.4em">
<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><a href="/wiki/Dimensionality_reduction" title="Dimensionality reduction">Dimensionality reduction</a></div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">
<ul><li><a href="/wiki/Factor_analysis" title="Factor analysis">Factor analysis</a></li>
<li><a href="/wiki/Canonical_correlation" title="Canonical correlation">CCA</a></li>
<li><a href="/wiki/Independent_component_analysis" title="Independent component analysis">ICA</a></li>
<li><a href="/wiki/Linear_discriminant_analysis" title="Linear discriminant analysis">LDA</a></li>
<li><a href="/wiki/Non-negative_matrix_factorization" title="Non-negative matrix factorization">NMF</a></li>
<li><a href="/wiki/Principal_component_analysis" title="Principal component analysis">PCA</a></li>
<li><a href="/wiki/Proper_generalized_decomposition" title="Proper generalized decomposition">PGD</a></li>
<li><a href="/wiki/T-distributed_stochastic_neighbor_embedding" title="T-distributed stochastic neighbor embedding">t-SNE</a></li></ul>
</div></div></div></td>
</tr><tr><td style="padding:0 0.1em 0.4em">
<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><a href="/wiki/Structured_prediction" title="Structured prediction">Structured prediction</a></div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">
<ul><li><a href="/wiki/Graphical_model" title="Graphical model">Graphical models</a>
<ul><li><a href="/wiki/Bayesian_network" title="Bayesian network">Bayes net</a></li>
<li><a href="/wiki/Conditional_random_field" title="Conditional random field">Conditional random field</a></li>
<li><a href="/wiki/Hidden_Markov_model" title="Hidden Markov model">Hidden Markov</a></li></ul></li></ul>
</div></div></div></td>
</tr><tr><td style="padding:0 0.1em 0.4em">
<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><a href="/wiki/Anomaly_detection" title="Anomaly detection">Anomaly detection</a></div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">
<ul><li><a class="mw-redirect" href="/wiki/K-nearest_neighbors_classification" title="K-nearest neighbors classification"><i>k</i>-NN</a></li>
<li><a href="/wiki/Local_outlier_factor" title="Local outlier factor">Local outlier factor</a></li></ul>
</div></div></div></td>
</tr><tr><td style="padding:0 0.1em 0.4em">
<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><a href="/wiki/Artificial_neural_network" title="Artificial neural network">Artificial neural network</a></div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">
<ul><li><a href="/wiki/Autoencoder" title="Autoencoder">Autoencoder</a></li>
<li><a href="/wiki/Deep_learning" title="Deep learning">Deep learning</a></li>
<li><a href="/wiki/DeepDream" title="DeepDream">DeepDream</a></li>
<li><a href="/wiki/Multilayer_perceptron" title="Multilayer perceptron">Multilayer perceptron</a></li>
<li><a href="/wiki/Recurrent_neural_network" title="Recurrent neural network">RNN</a>
<ul><li><a href="/wiki/Long_short-term_memory" title="Long short-term memory">LSTM</a></li>
<li><a href="/wiki/Gated_recurrent_unit" title="Gated recurrent unit">GRU</a></li></ul></li>
<li><a href="/wiki/Restricted_Boltzmann_machine" title="Restricted Boltzmann machine">Restricted Boltzmann machine</a></li>
<li><a class="mw-selflink selflink">GAN</a></li>
<li><a href="/wiki/Self-organizing_map" title="Self-organizing map">SOM</a></li>
<li><a href="/wiki/Convolutional_neural_network" title="Convolutional neural network">Convolutional neural network</a>
<ul><li><a href="/wiki/U-Net" title="U-Net">U-Net</a></li></ul></li></ul>
</div></div></div></td>
</tr><tr><td style="padding:0 0.1em 0.4em">
<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><a href="/wiki/Reinforcement_learning" title="Reinforcement learning">Reinforcement learning</a></div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">
<ul><li><a href="/wiki/Q-learning" title="Q-learning">Q-learning</a></li>
<li><a href="/wiki/State%E2%80%93action%E2%80%93reward%E2%80%93state%E2%80%93action" title="State–action–reward–state–action">SARSA</a></li>
<li><a href="/wiki/Temporal_difference_learning" title="Temporal difference learning">Temporal difference (TD)</a></li></ul>
</div></div></div></td>
</tr><tr><td style="padding:0 0.1em 0.4em">
<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left">Theory</div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">
<ul><li><a class="mw-redirect" href="/wiki/Bias%E2%80%93variance_dilemma" title="Bias–variance dilemma">Bias–variance dilemma</a></li>
<li><a href="/wiki/Computational_learning_theory" title="Computational learning theory">Computational learning theory</a></li>
<li><a href="/wiki/Empirical_risk_minimization" title="Empirical risk minimization">Empirical risk minimization</a></li>
<li><a href="/wiki/Occam_learning" title="Occam learning">Occam learning</a></li>
<li><a href="/wiki/Probably_approximately_correct_learning" title="Probably approximately correct learning">PAC learning</a></li>
<li><a href="/wiki/Statistical_learning_theory" title="Statistical learning theory">Statistical learning</a></li>
<li><a href="/wiki/Vapnik%E2%80%93Chervonenkis_theory" title="Vapnik–Chervonenkis theory">VC theory</a></li></ul>
</div></div></div></td>
</tr><tr><td style="padding:0 0.1em 0.4em">
<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left">Machine-learning venues</div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">
<ul><li><a href="/wiki/Conference_on_Neural_Information_Processing_Systems" title="Conference on Neural Information Processing Systems">NeurIPS</a></li>
<li><a href="/wiki/International_Conference_on_Machine_Learning" title="International Conference on Machine Learning">ICML</a></li>
<li><a href="/wiki/Machine_Learning_(journal)" title="Machine Learning (journal)">ML</a></li>
<li><a href="/wiki/Journal_of_Machine_Learning_Research" title="Journal of Machine Learning Research">JMLR</a></li>
<li><a class="external text" href="https://arxiv.org/list/cs.LG/recent" rel="nofollow">ArXiv:cs.LG</a></li></ul>
</div></div></div></td>
</tr><tr><td style="padding:0 0.1em 0.4em">
<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><a href="/wiki/Glossary_of_artificial_intelligence" title="Glossary of artificial intelligence">Glossary of artificial intelligence</a></div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">
<ul><li><a href="/wiki/Glossary_of_artificial_intelligence" title="Glossary of artificial intelligence">Glossary of artificial intelligence</a></li></ul>
</div></div></div></td>
</tr><tr><td style="padding:0 0.1em 0.4em">
<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left">Related articles</div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">
<ul><li><a href="/wiki/List_of_datasets_for_machine-learning_research" title="List of datasets for machine-learning research">List of datasets for machine-learning research</a></li>
<li><a href="/wiki/Outline_of_machine_learning" title="Outline of machine learning">Outline of machine learning</a></li></ul>
</div></div></div></td>
</tr><tr><td style="text-align:right;font-size:115%;padding-top: 0.6em;"><div class="plainlinks hlist navbar mini"><ul><li class="nv-view"><a href="/wiki/Template:Machine_learning_bar" title="Template:Machine learning bar"><abbr title="View this template">v</abbr></a></li><li class="nv-talk"><a href="/wiki/Template_talk:Machine_learning_bar" title="Template talk:Machine learning bar"><abbr title="Discuss this template">t</abbr></a></li><li class="nv-edit"><a class="external text" href="https://en.wikipedia.org/w/index.php?title=Template:Machine_learning_bar&amp;action=edit"><abbr title="Edit this template">e</abbr></a></li></ul></div></td></tr></tbody></table>
<p>A <b>generative adversarial network</b> (<b>GAN</b>) is a class of <a href="/wiki/Machine_learning" title="Machine learning">machine learning</a> systems invented by <a href="/wiki/Ian_Goodfellow" title="Ian Goodfellow">Ian Goodfellow</a> and his colleagues in 2014.<sup class="reference" id="cite_ref-GANnips_1-0"><a href="#cite_note-GANnips-1">[1]</a></sup> Two <a href="/wiki/Neural_network" title="Neural network">neural networks</a> contest with each other in a game (in the sense of <a href="/wiki/Game_theory" title="Game theory">game theory</a>, often but not always in the form of a <a href="/wiki/Zero-sum_game" title="Zero-sum game">zero-sum game</a>). Given a training set, this technique learns to generate new data with the same statistics as the training set. For example, a GAN trained on photographs can generate new photographs that look at least superficially authentic to human observers, having many realistic characteristics. Though originally proposed as a form of <a href="/wiki/Generative_model" title="Generative model">generative model</a> for <a href="/wiki/Unsupervised_learning" title="Unsupervised learning">unsupervised learning</a>, GANs have also proven useful for <a href="/wiki/Semi-supervised_learning" title="Semi-supervised learning">semi-supervised learning</a>,<sup class="reference" id="cite_ref-ITT_GANs_2-0"><a href="#cite_note-ITT_GANs-2">[2]</a></sup> fully <a href="/wiki/Supervised_learning" title="Supervised learning">supervised learning</a>,<sup class="reference" id="cite_ref-3"><a href="#cite_note-3">[3]</a></sup> and <a href="/wiki/Reinforcement_learning" title="Reinforcement learning">reinforcement learning</a>.<sup class="reference" id="cite_ref-4"><a href="#cite_note-4">[4]</a></sup> In a 2016 seminar, <a href="/wiki/Yann_LeCun" title="Yann LeCun">Yann LeCun</a> described GANs as "the coolest idea in machine learning in the last twenty years".<sup class="reference" id="cite_ref-5"><a href="#cite_note-5">[5]</a></sup>
</p>
<div aria-labelledby="mw-toc-heading" class="toc" id="toc" role="navigation"><input class="toctogglecheckbox" id="toctogglecheckbox" role="button" style="display:none" type="checkbox"/><div class="toctitle" dir="ltr" lang="en"><h2 id="mw-toc-heading">Contents</h2><span class="toctogglespan"><label class="toctogglelabel" for="toctogglecheckbox"></label></span></div>
<ul>
<li class="toclevel-1 tocsection-1"><a href="#Method"><span class="tocnumber">1</span> <span class="toctext">Method</span></a></li>
<li class="toclevel-1 tocsection-2"><a href="#Applications"><span class="tocnumber">2</span> <span class="toctext">Applications</span></a>
<ul>
<li class="toclevel-2 tocsection-3"><a href="#Fashion,_art_and_advertising"><span class="tocnumber">2.1</span> <span class="toctext">Fashion, art and advertising</span></a></li>
<li class="toclevel-2 tocsection-4"><a href="#Science"><span class="tocnumber">2.2</span> <span class="toctext">Science</span></a></li>
<li class="toclevel-2 tocsection-5"><a href="#Video_games"><span class="tocnumber">2.3</span> <span class="toctext">Video games</span></a></li>
<li class="toclevel-2 tocsection-6"><a href="#Concerns_about_malicious_applications"><span class="tocnumber">2.4</span> <span class="toctext">Concerns about malicious applications</span></a></li>
<li class="toclevel-2 tocsection-7"><a href="#Miscellaneous_applications"><span class="tocnumber">2.5</span> <span class="toctext">Miscellaneous applications</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-8"><a href="#History"><span class="tocnumber">3</span> <span class="toctext">History</span></a></li>
<li class="toclevel-1 tocsection-9"><a href="#Classification"><span class="tocnumber">4</span> <span class="toctext">Classification</span></a>
<ul>
<li class="toclevel-2 tocsection-10"><a href="#Bidirectional_GAN"><span class="tocnumber">4.1</span> <span class="toctext">Bidirectional GAN</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-11"><a href="#References"><span class="tocnumber">5</span> <span class="toctext">References</span></a></li>
<li class="toclevel-1 tocsection-12"><a href="#External_links"><span class="tocnumber">6</span> <span class="toctext">External links</span></a></li>
</ul>
</div>
<h2><span class="mw-headline" id="Method">Method</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Generative_adversarial_network&amp;action=edit&amp;section=1" title="Edit section: Method">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>The <a href="/wiki/Generative_model" title="Generative model"><i>generative</i> network</a> generates candidates while the <a href="/wiki/Discriminative_model" title="Discriminative model"><i>discriminative</i> network</a> evaluates them.<sup class="reference" id="cite_ref-GANnips_1-1"><a href="#cite_note-GANnips-1">[1]</a></sup> The contest operates in terms of data distributions. Typically, the generative network learns to map from a <a href="/wiki/Latent_variable" title="Latent variable">latent space</a> to a data distribution of interest, while the discriminative network distinguishes candidates produced by the generator from the true data distribution. The generative network's training objective is to increase the error rate of the discriminative network (i.e., "fool" the discriminator network by producing novel candidates that the discriminator thinks are not synthesized (are part of the true data distribution)).<sup class="reference" id="cite_ref-GANnips_1-2"><a href="#cite_note-GANnips-1">[1]</a></sup><sup class="reference" id="cite_ref-6"><a href="#cite_note-6">[6]</a></sup>
</p><p>A known dataset serves as the initial training data for the discriminator. Training it involves presenting it with samples from the training dataset, until it achieves acceptable accuracy. The generator trains based on whether it succeeds in fooling the discriminator. Typically the generator is seeded with randomized input that is sampled from a predefined <a href="/wiki/Latent_variable" title="Latent variable">latent space</a> (e.g. a <a href="/wiki/Multivariate_normal_distribution" title="Multivariate normal distribution">multivariate normal distribution</a>). Thereafter, candidates synthesized by the generator are evaluated by the discriminator. <a href="/wiki/Backpropagation" title="Backpropagation">Backpropagation</a> is applied in both networks so that the generator produces better images, while the discriminator becomes more skilled at flagging synthetic images.<sup class="reference" id="cite_ref-OpenAI_com_7-0"><a href="#cite_note-OpenAI_com-7">[7]</a></sup> The generator is typically a deconvolutional neural network, and the discriminator is a <a href="/wiki/Convolutional_neural_network" title="Convolutional neural network">convolutional neural network</a>.
</p>
<h2><span class="mw-headline" id="Applications">Applications</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Generative_adversarial_network&amp;action=edit&amp;section=2" title="Edit section: Applications">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>GAN applications have increased rapidly.<sup class="reference" id="cite_ref-8"><a href="#cite_note-8">[8]</a></sup>
</p>
<h3><span id="Fashion.2C_art_and_advertising"></span><span class="mw-headline" id="Fashion,_art_and_advertising">Fashion, art and advertising</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Generative_adversarial_network&amp;action=edit&amp;section=3" title="Edit section: Fashion, art and advertising">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>GANs can be used to create photos of imaginary fashion models, with no need to hire a model, photographer, makeup artist, or pay for a studio and transportation.<sup class="reference" id="cite_ref-9"><a href="#cite_note-9">[9]</a></sup> GANs can be used to create fashion advertising campaigns including more diverse groups of models, which may increase intent to buy among people resembling the models.<sup class="reference" id="cite_ref-10"><a href="#cite_note-10">[10]</a></sup> GANs can also be used to create <a class="external text" href="https://www.artbreeder.com/" rel="nofollow">portraits, landscapes, and album covers</a>.
</p>
<h3><span class="mw-headline" id="Science">Science</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Generative_adversarial_network&amp;action=edit&amp;section=4" title="Edit section: Science">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>GANs can <a href="/wiki/Image_restoration" title="Image restoration">improve</a> <a href="/wiki/Astrophotography" title="Astrophotography">astronomical images</a><sup class="reference" id="cite_ref-11"><a href="#cite_note-11">[11]</a></sup> and simulate gravitational lensing for dark matter research.<sup class="reference" id="cite_ref-12"><a href="#cite_note-12">[12]</a></sup><sup class="reference" id="cite_ref-13"><a href="#cite_note-13">[13]</a></sup><sup class="reference" id="cite_ref-14"><a href="#cite_note-14">[14]</a></sup> They were used in 2019 to successfully model the distribution of <a href="/wiki/Dark_matter" title="Dark matter">dark matter</a> in a particular direction in space and to predict the <a class="mw-redirect" href="/wiki/Gravitational_Lensing" title="Gravitational Lensing">gravitational lensing</a> that will occur.<sup class="reference" id="cite_ref-15"><a href="#cite_note-15">[15]</a></sup><sup class="reference" id="cite_ref-16"><a href="#cite_note-16">[16]</a></sup>
</p><p>GANs have been proposed as a fast and accurate way of modeling high energy jet formation<sup class="reference" id="cite_ref-17"><a href="#cite_note-17">[17]</a></sup> and modeling <a href="/wiki/Particle_shower" title="Particle shower">showers</a> through <a href="/wiki/Calorimeter_(particle_physics)" title="Calorimeter (particle physics)">calorimeters</a> of <a href="/wiki/Particle_physics" title="Particle physics">high-energy physics</a> experiments.<sup class="reference" id="cite_ref-18"><a href="#cite_note-18">[18]</a></sup><sup class="reference" id="cite_ref-19"><a href="#cite_note-19">[19]</a></sup><sup class="reference" id="cite_ref-20"><a href="#cite_note-20">[20]</a></sup><sup class="reference" id="cite_ref-21"><a href="#cite_note-21">[21]</a></sup> GANs have also been trained to accurately approximate bottlenecks in computationally expensive simulations of particle physics experiments. Applications in the context of present and proposed <a href="/wiki/CERN" title="CERN">CERN</a> experiments have demonstrated the potential of these methods for accelerating simulation and/or improving simulation fidelity.<sup class="reference" id="cite_ref-22"><a href="#cite_note-22">[22]</a></sup><sup class="reference" id="cite_ref-23"><a href="#cite_note-23">[23]</a></sup>
</p>
<h3><span class="mw-headline" id="Video_games">Video games</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Generative_adversarial_network&amp;action=edit&amp;section=5" title="Edit section: Video games">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>In 2018, GANs reached the <a class="mw-redirect" href="/wiki/Mod_(video_gaming)" title="Mod (video gaming)">video game modding</a> community, as a method of <a href="/wiki/Image_scaling" title="Image scaling">up-scaling</a> low-resolution 2D textures in old video games by recreating them in <a href="/wiki/4K_resolution" title="4K resolution">4k</a> or higher resolutions via image training, and then down-sampling them to fit the game's native resolution (with results resembling the <a href="/wiki/Supersampling" title="Supersampling">supersampling</a> method of <a href="/wiki/Spatial_anti-aliasing" title="Spatial anti-aliasing">anti-aliasing</a>).<sup class="reference" id="cite_ref-24"><a href="#cite_note-24">[24]</a></sup> With proper training, GANs provide a clearer and sharper 2D texture image magnitudes higher in quality than the original, while fully retaining the original's level of details, colors, etc. Known examples of extensive GAN usage include <a href="/wiki/Final_Fantasy_VIII" title="Final Fantasy VIII">Final Fantasy VIII</a>, <a href="/wiki/Final_Fantasy_IX" title="Final Fantasy IX">Final Fantasy IX</a>, <a href="/wiki/Resident_Evil_(2002_video_game)" title="Resident Evil (2002 video game)">Resident Evil</a> REmake HD Remaster, and <a href="/wiki/Max_Payne" title="Max Payne">Max Payne</a>.<sup class="noprint Inline-Template Template-Fact" style="white-space:nowrap;">[<i><a href="/wiki/Wikipedia:Citation_needed" title="Wikipedia:Citation needed"><span title="This claim needs references to reliable sources. (January 2020)">citation needed</span></a></i>]</sup>
</p>
<h3><span class="mw-headline" id="Concerns_about_malicious_applications">Concerns about malicious applications</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Generative_adversarial_network&amp;action=edit&amp;section=6" title="Edit section: Concerns about malicious applications">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<div class="thumb tright"><div class="thumbinner" style="width:222px;"><a class="image" href="/wiki/File:Woman_1.jpg"><img alt="" class="thumbimage" data-file-height="1024" data-file-width="1024" decoding="async" height="220" src="//upload.wikimedia.org/wikipedia/commons/thumb/1/1f/Woman_1.jpg/220px-Woman_1.jpg" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/1/1f/Woman_1.jpg/330px-Woman_1.jpg 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/1/1f/Woman_1.jpg/440px-Woman_1.jpg 2x" width="220"/></a> <div class="thumbcaption"><div class="magnify"><a class="internal" href="/wiki/File:Woman_1.jpg" title="Enlarge"></a></div>An image generated by a <a href="/wiki/StyleGAN" title="StyleGAN">StyleGAN</a> that looks deceptively like a photograph of a real person. This image was generated by a StyleGAN based on an analysis of portraits.</div></div></div>
<p>Concerns have been raised about the potential use of GAN-based <a href="/wiki/Human_image_synthesis" title="Human image synthesis">human image synthesis</a> for sinister purposes, e.g., to produce fake and/or incriminating photographs and videos.<sup class="reference" id="cite_ref-TPDNEwuaitcryhf|_25-0"><a href="#cite_note-TPDNEwuaitcryhf|-25">[25]</a></sup>
GANs can be used to generate unique, realistic profile photos of people who do not exist, in order to automate creation of fake social media profiles.<sup class="reference" id="cite_ref-26"><a href="#cite_note-26">[26]</a></sup>
</p><p>In 2019 the state of California considered<sup class="reference" id="cite_ref-27"><a href="#cite_note-27">[27]</a></sup> and passed on October 3, 2019 the <a class="external text" href="https://leginfo.legislature.ca.gov/faces/billTextClient.xhtml?bill_id=201920200AB602" rel="nofollow">bill AB-602</a>, which bans the use of human image synthesis technologies to make fake pornography without the consent of the people depicted, and <a class="external text" href="https://leginfo.legislature.ca.gov/faces/billTextClient.xhtml?bill_id=201920200AB730" rel="nofollow">bill AB-730</a>, which prohibits distribution of manipulated videos of a political candidate within 60 days of an election. Both bills were authored by Assembly member <a href="/wiki/Marc_Berman" title="Marc Berman">Marc Berman and signed by Governor</a> <a href="/wiki/Gavin_Newsom" title="Gavin Newsom">Gavin Newsom</a>. The laws will come into effect in 2020.<sup class="reference" id="cite_ref-CNET2019_28-0"><a href="#cite_note-CNET2019-28">[28]</a></sup>
</p><p>DARPA's Media Forensics program studies ways to counteract fake media, including fake media produced using GANs.<sup class="reference" id="cite_ref-29"><a href="#cite_note-29">[29]</a></sup>
</p>
<h3><span class="mw-headline" id="Miscellaneous_applications">Miscellaneous applications</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Generative_adversarial_network&amp;action=edit&amp;section=7" title="Edit section: Miscellaneous applications">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>GAN can be used to detect glaucomatous images helping the early diagnosis which is essential to avoid partial or total loss
of vision <sup class="reference" id="cite_ref-30"><a href="#cite_note-30">[30]</a></sup>. 
</p><p>GANs that produce <a class="mw-redirect" href="/wiki/Photorealistic_rendering" title="Photorealistic rendering">photorealistic</a> images can be used to visualize <a href="/wiki/Interior_design" title="Interior design">interior design</a>, <a href="/wiki/Industrial_design" title="Industrial design">industrial design</a>, shoes,<sup class="reference" id="cite_ref-31"><a href="#cite_note-31">[31]</a></sup> bags, and <a href="/wiki/Clothing" title="Clothing">clothing</a> items or items for <a href="/wiki/PC_game" title="PC game">computer games</a>' scenes.<sup class="noprint Inline-Template Template-Fact" style="white-space:nowrap;">[<i><a href="/wiki/Wikipedia:Citation_needed" title="Wikipedia:Citation needed"><span title="No source provided. How does a GAN do this? (February 2018)">citation needed</span></a></i>]</sup> Such networks were reported to be used by <a href="/wiki/Facebook" title="Facebook">Facebook</a>.<sup class="reference" id="cite_ref-32"><a href="#cite_note-32">[32]</a></sup>
</p><p>GANs can <a href="/wiki/3D_reconstruction_from_multiple_images" title="3D reconstruction from multiple images">reconstruct 3D models of objects from images</a>,<sup class="reference" id="cite_ref-33"><a href="#cite_note-33">[33]</a></sup> and model patterns of motion in video.<sup class="reference" id="cite_ref-34"><a href="#cite_note-34">[34]</a></sup>
</p><p>GANs can be used to age face photographs to show how an individual's appearance might change with age.<sup class="reference" id="cite_ref-35"><a href="#cite_note-35">[35]</a></sup>
</p><p>GANs can also be used to transfer map styles in cartography<sup class="reference" id="cite_ref-36"><a href="#cite_note-36">[36]</a></sup> or augment street view imagery.<sup class="reference" id="cite_ref-37"><a href="#cite_note-37">[37]</a></sup>
</p><p>A variation of the GANs is used in training a network to generate optimal control inputs to nonlinear dynamical systems. Where the discriminatory network is known as a critic that checks the optimality of the solution and the generative network is known as an Adaptive network that generates the optimal control. The critic and adaptive network train each other to approximate a nonlinear optimal control.<sup class="reference" id="cite_ref-38"><a href="#cite_note-38">[38]</a></sup>
</p><p>GANs have been used to visualize the effect that climate change will have on specific houses.<sup class="reference" id="cite_ref-39"><a href="#cite_note-39">[39]</a></sup>
</p><p>A GAN model called Speech2Face can reconstruct an image of a person's face after listening to their voice.<sup class="reference" id="cite_ref-40"><a href="#cite_note-40">[40]</a></sup>
</p><p>In 2016 GANs were used to generate new molecules for a variety of protein targets implicated in cancer, inflammation, and fibrosis. In 2019 GAN-generated molecules were validated experimentally all the way into mice.<sup class="reference" id="cite_ref-41"><a href="#cite_note-41">[41]</a></sup><sup class="reference" id="cite_ref-42"><a href="#cite_note-42">[42]</a></sup>
</p>
<h2><span class="mw-headline" id="History">History</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Generative_adversarial_network&amp;action=edit&amp;section=8" title="Edit section: History">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>The most direct inspiration for GANs was noise-contrastive estimation,<sup class="reference" id="cite_ref-43"><a href="#cite_note-43">[43]</a></sup> which uses the same loss function as GANs and which Goodfellow studied during his PhD in 2010–2014.
</p><p>Other people had similar ideas but did not develop them similarly. An idea involving adversarial networks was published in a 2010 blog post by Olli Niemitalo.<sup class="reference" id="cite_ref-olli2010_44-0"><a href="#cite_note-olli2010-44">[44]</a></sup> This idea was never implemented and did not involve stochasticity in the generator and thus was not a generative model. It is now known as a conditional GAN or cGAN.<sup class="reference" id="cite_ref-reddit3_45-0"><a href="#cite_note-reddit3-45">[45]</a></sup> An idea similar to GANs was used to model animal behavior by Li, Gauci and Gross in 2013.<sup class="reference" id="cite_ref-Li-etal-GECCO2013_46-0"><a href="#cite_note-Li-etal-GECCO2013-46">[46]</a></sup>
</p><p><a href="/wiki/Adversarial_machine_learning" title="Adversarial machine learning">Adversarial machine learning</a> has other uses besides generative modeling and can be applied to models other than neural networks. In control theory, adversarial learning based on neural networks was used in 2006 to train robust controllers in a game theoretic sense, by alternating the iterations between a minimizer policy, the controller, and a maximizer policy, the disturbance <sup class="reference" id="cite_ref-47"><a href="#cite_note-47">[47]</a></sup><sup class="reference" id="cite_ref-48"><a href="#cite_note-48">[48]</a></sup>.
</p><p>In 2017, a GAN was used for image enhancement focusing on realistic textures rather than pixel-accuracy, producing a higher image quality at high magnification.<sup class="reference" id="cite_ref-49"><a href="#cite_note-49">[49]</a></sup> In 2017, the first faces were generated.<sup class="reference" id="cite_ref-50"><a href="#cite_note-50">[50]</a></sup> These were exhibited in February 2018 at the Grand Palais.<sup class="reference" id="cite_ref-51"><a href="#cite_note-51">[51]</a></sup><sup class="reference" id="cite_ref-52"><a href="#cite_note-52">[52]</a></sup> Faces generated by <a href="/wiki/StyleGAN" title="StyleGAN">StyleGAN</a><sup class="reference" id="cite_ref-53"><a href="#cite_note-53">[53]</a></sup> in 2019 drew comparisons with <a href="/wiki/Deepfake" title="Deepfake">deepfakes</a>.<sup class="reference" id="cite_ref-TPDNEitboowo2019_54-0"><a href="#cite_note-TPDNEitboowo2019-54">[54]</a></sup><sup class="reference" id="cite_ref-TPDNE_55-0"><a href="#cite_note-TPDNE-55">[55]</a></sup><sup class="reference" id="cite_ref-Style-based_GANs_–_Generating_and_Tuning_Realistic_Artificial_Faces_56-0"><a href="#cite_note-Style-based_GANs_–_Generating_and_Tuning_Realistic_Artificial_Faces-56">[56]</a></sup>
</p><p>Beginning in 2017, GAN technology began to make its presence felt in the fine arts arena with the appearance of a newly developed implementation which was said to have crossed the threshold of being able to generate unique and appealing abstract paintings, and thus dubbed a "CAN", for "creative adversarial network".<sup class="reference" id="cite_ref-57"><a href="#cite_note-57">[57]</a></sup> A GAN system was used to create the 2018 painting <i><a href="/wiki/Edmond_de_Belamy" title="Edmond de Belamy">Edmond de Belamy</a>,</i> which sold for US$432,500.<sup class="reference" id="cite_ref-58"><a href="#cite_note-58">[58]</a></sup> An early 2019 article by members of the original CAN team discussed further progress with that system, and gave consideration as well to the overall prospects for an AI-enabled art.<sup class="reference" id="cite_ref-59"><a href="#cite_note-59">[59]</a></sup>
</p><p>In May 2019, researchers at Samsung demonstrated a GAN-based system that produces videos of a person speaking given only a single photo of that person.<sup class="reference" id="cite_ref-60"><a href="#cite_note-60">[60]</a></sup>
</p><p>In August 2019, A large dataset consisting of 12,197 MIDI songs each with paired lyrics and melody alignment was created for neural melody generation from lyrics using conditional GAN-LSTM (refer to sources at GitHub <a class="external text" href="https://github.com/yy1lab/Lyrics-Conditioned-Neural-Melody-Generation" rel="nofollow">AI Melody Generation from Lyrics</a>).<sup class="reference" id="cite_ref-61"><a href="#cite_note-61">[61]</a></sup>
</p>
<h2><span class="mw-headline" id="Classification">Classification</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Generative_adversarial_network&amp;action=edit&amp;section=9" title="Edit section: Classification">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<h3><span class="mw-headline" id="Bidirectional_GAN">Bidirectional GAN</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Generative_adversarial_network&amp;action=edit&amp;section=10" title="Edit section: Bidirectional GAN">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>Bidirectional GAN(BiGAN) aims to introduce a generator model to act as the discriminator, whereby the discriminator naturally considers the entire translation space so that the inadequate training problem can be alleviated. To satisfy this property, generator and discriminator are both designed to model the joint probability of sentence pairs, with the difference that, the generator decomposes the joint probability with a source language model and a source-to-target translation model, while the discriminator is formulated as a target language model and a target-to-source translation model. To further leverage the symmetry of them, an auxiliary GAN is introduced and adopts generator and discriminator models of original one as its own discriminator and generator respectively. Two GANs are alternately trained to update the parameters. The resulting learned feature representation is useful for auxiliary supervised discrimination tasks, competitive with contemporary approaches to unsupervised and self-supervised feature learning.<sup class="reference" id="cite_ref-62"><a href="#cite_note-62">[62]</a></sup>
</p>
<h2><span class="mw-headline" id="References">References</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Generative_adversarial_network&amp;action=edit&amp;section=11" title="Edit section: References">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<div class="reflist columns references-column-width" style="-moz-column-width: 30em; -webkit-column-width: 30em; column-width: 30em; list-style-type: decimal;">
<ol class="references">
<li id="cite_note-GANnips-1"><span class="mw-cite-backlink">^ <a href="#cite_ref-GANnips_1-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-GANnips_1-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-GANnips_1-2"><sup><i><b>c</b></i></sup></a></span> <span class="reference-text"><cite class="citation conference">Goodfellow, Ian; Pouget-Abadie, Jean; Mirza, Mehdi; Xu, Bing; Warde-Farley, David; Ozair, Sherjil; Courville, Aaron; Bengio, Yoshua (2014). <a class="external text" href="https://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf" rel="nofollow"><i>Generative Adversarial Networks</i></a> <span class="cs1-format">(PDF)</span>. Proceedings of the International Conference on Neural Information Processing Systems (NIPS 2014). pp. 2672–2680.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=conference&amp;rft.btitle=Generative+Adversarial+Networks&amp;rft.pages=2672-2680&amp;rft.date=2014&amp;rft.aulast=Goodfellow&amp;rft.aufirst=Ian&amp;rft.au=Pouget-Abadie%2C+Jean&amp;rft.au=Mirza%2C+Mehdi&amp;rft.au=Xu%2C+Bing&amp;rft.au=Warde-Farley%2C+David&amp;rft.au=Ozair%2C+Sherjil&amp;rft.au=Courville%2C+Aaron&amp;rft.au=Bengio%2C+Yoshua&amp;rft_id=https%3A%2F%2Fpapers.nips.cc%2Fpaper%2F5423-generative-adversarial-nets.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGenerative+adversarial+network"></span><style data-mw-deduplicate="TemplateStyles:r935243608">.mw-parser-output cite.citation{font-style:inherit}.mw-parser-output .citation q{quotes:"\"""\"""'""'"}.mw-parser-output .id-lock-free a,.mw-parser-output .citation .cs1-lock-free a{background:url("//upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/9px-Lock-green.svg.png")no-repeat;background-position:right .1em center}.mw-parser-output .id-lock-limited a,.mw-parser-output .id-lock-registration a,.mw-parser-output .citation .cs1-lock-limited a,.mw-parser-output .citation .cs1-lock-registration a{background:url("//upload.wikimedia.org/wikipedia/commons/thumb/d/d6/Lock-gray-alt-2.svg/9px-Lock-gray-alt-2.svg.png")no-repeat;background-position:right .1em center}.mw-parser-output .id-lock-subscription a,.mw-parser-output .citation .cs1-lock-subscription a{background:url("//upload.wikimedia.org/wikipedia/commons/thumb/a/aa/Lock-red-alt-2.svg/9px-Lock-red-alt-2.svg.png")no-repeat;background-position:right .1em center}.mw-parser-output .cs1-subscription,.mw-parser-output .cs1-registration{color:#555}.mw-parser-output .cs1-subscription span,.mw-parser-output .cs1-registration span{border-bottom:1px dotted;cursor:help}.mw-parser-output .cs1-ws-icon a{background:url("//upload.wikimedia.org/wikipedia/commons/thumb/4/4c/Wikisource-logo.svg/12px-Wikisource-logo.svg.png")no-repeat;background-position:right .1em center}.mw-parser-output code.cs1-code{color:inherit;background:inherit;border:inherit;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;font-size:100%}.mw-parser-output .cs1-visible-error{font-size:100%}.mw-parser-output .cs1-maint{display:none;color:#33aa33;margin-left:0.3em}.mw-parser-output .cs1-subscription,.mw-parser-output .cs1-registration,.mw-parser-output .cs1-format{font-size:95%}.mw-parser-output .cs1-kern-left,.mw-parser-output .cs1-kern-wl-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right,.mw-parser-output .cs1-kern-wl-right{padding-right:0.2em}</style></span>
</li>
<li id="cite_note-ITT_GANs-2"><span class="mw-cite-backlink"><b><a href="#cite_ref-ITT_GANs_2-0">^</a></b></span> <span class="reference-text"><cite class="citation arxiv">Salimans, Tim; Goodfellow, Ian; Zaremba, Wojciech; Cheung, Vicki; Radford, Alec; Chen, Xi (2016). "Improved Techniques for Training GANs". <a href="/wiki/ArXiv" title="ArXiv">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="//arxiv.org/abs/1606.03498" rel="nofollow">1606.03498</a></span> [<a class="external text" href="//arxiv.org/archive/cs.LG" rel="nofollow">cs.LG</a>].</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=Improved+Techniques+for+Training+GANs&amp;rft.date=2016&amp;rft_id=info%3Aarxiv%2F1606.03498&amp;rft.aulast=Salimans&amp;rft.aufirst=Tim&amp;rft.au=Goodfellow%2C+Ian&amp;rft.au=Zaremba%2C+Wojciech&amp;rft.au=Cheung%2C+Vicki&amp;rft.au=Radford%2C+Alec&amp;rft.au=Chen%2C+Xi&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGenerative+adversarial+network"></span><link href="mw-data:TemplateStyles:r935243608" rel="mw-deduplicated-inline-style"/></span>
</li>
<li id="cite_note-3"><span class="mw-cite-backlink"><b><a href="#cite_ref-3">^</a></b></span> <span class="reference-text"><cite class="citation journal">Isola, Phillip; Zhu, Jun-Yan; Zhou, Tinghui; Efros, Alexei (2017). <a class="external text" href="https://phillipi.github.io/pix2pix/" rel="nofollow">"Image-to-Image Translation with Conditional Adversarial Nets"</a>. <i>Computer Vision and Pattern Recognition</i>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Computer+Vision+and+Pattern+Recognition&amp;rft.atitle=Image-to-Image+Translation+with+Conditional+Adversarial+Nets&amp;rft.date=2017&amp;rft.aulast=Isola&amp;rft.aufirst=Phillip&amp;rft.au=Zhu%2C+Jun-Yan&amp;rft.au=Zhou%2C+Tinghui&amp;rft.au=Efros%2C+Alexei&amp;rft_id=https%3A%2F%2Fphillipi.github.io%2Fpix2pix%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGenerative+adversarial+network"></span><link href="mw-data:TemplateStyles:r935243608" rel="mw-deduplicated-inline-style"/></span>
</li>
<li id="cite_note-4"><span class="mw-cite-backlink"><b><a href="#cite_ref-4">^</a></b></span> <span class="reference-text"><cite class="citation journal">Ho, Jonathon; Ermon, Stefano (2016). <a class="external text" href="http://papers.nips.cc/paper/6391-generative-adversarial-imitation-learning" rel="nofollow">"Generative Adversarial Imitation Learning"</a>. <i>Advances in Neural Information Processing Systems</i>: 4565–4573. <a href="/wiki/ArXiv" title="ArXiv">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="//arxiv.org/abs/1606.03476" rel="nofollow">1606.03476</a></span>. <a href="/wiki/Bibcode" title="Bibcode">Bibcode</a>:<a class="external text" href="https://ui.adsabs.harvard.edu/abs/2016arXiv160603476H" rel="nofollow">2016arXiv160603476H</a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Advances+in+Neural+Information+Processing+Systems&amp;rft.atitle=Generative+Adversarial+Imitation+Learning&amp;rft.pages=4565-4573&amp;rft.date=2016&amp;rft_id=info%3Aarxiv%2F1606.03476&amp;rft_id=info%3Abibcode%2F2016arXiv160603476H&amp;rft.aulast=Ho&amp;rft.aufirst=Jonathon&amp;rft.au=Ermon%2C+Stefano&amp;rft_id=http%3A%2F%2Fpapers.nips.cc%2Fpaper%2F6391-generative-adversarial-imitation-learning&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGenerative+adversarial+network"></span><link href="mw-data:TemplateStyles:r935243608" rel="mw-deduplicated-inline-style"/></span>
</li>
<li id="cite_note-5"><span class="mw-cite-backlink"><b><a href="#cite_ref-5">^</a></b></span> <span class="reference-text"><cite class="citation web">LeCun, Yann. <a class="external text" href="https://www.youtube.com/watch?v=IbjF5VjniVE" rel="nofollow">"RL Seminar: The Next Frontier in AI: Unsupervised Learning"</a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=RL+Seminar%3A+The+Next+Frontier+in+AI%3A+Unsupervised+Learning&amp;rft.aulast=LeCun&amp;rft.aufirst=Yann&amp;rft_id=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DIbjF5VjniVE&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGenerative+adversarial+network"></span><link href="mw-data:TemplateStyles:r935243608" rel="mw-deduplicated-inline-style"/></span>
</li>
<li id="cite_note-6"><span class="mw-cite-backlink"><b><a href="#cite_ref-6">^</a></b></span> <span class="reference-text"><cite class="citation journal">Luc, Pauline; Couprie, Camille; Chintala, Soumith; Verbeek, Jakob (2016-11-25). "Semantic Segmentation using Adversarial Networks". <i>NIPS Workshop on Adversarial Training, Dec, Barcelona, Spain</i>. <b>2016</b>. <a href="/wiki/ArXiv" title="ArXiv">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="//arxiv.org/abs/1611.08408" rel="nofollow">1611.08408</a></span>. <a href="/wiki/Bibcode" title="Bibcode">Bibcode</a>:<a class="external text" href="https://ui.adsabs.harvard.edu/abs/2016arXiv161108408L" rel="nofollow">2016arXiv161108408L</a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=NIPS+Workshop+on+Adversarial+Training%2C+Dec%2C+Barcelona%2C+Spain&amp;rft.atitle=Semantic+Segmentation+using+Adversarial+Networks&amp;rft.volume=2016&amp;rft.date=2016-11-25&amp;rft_id=info%3Aarxiv%2F1611.08408&amp;rft_id=info%3Abibcode%2F2016arXiv161108408L&amp;rft.aulast=Luc&amp;rft.aufirst=Pauline&amp;rft.au=Couprie%2C+Camille&amp;rft.au=Chintala%2C+Soumith&amp;rft.au=Verbeek%2C+Jakob&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGenerative+adversarial+network"></span><link href="mw-data:TemplateStyles:r935243608" rel="mw-deduplicated-inline-style"/></span>
</li>
<li id="cite_note-OpenAI_com-7"><span class="mw-cite-backlink"><b><a href="#cite_ref-OpenAI_com_7-0">^</a></b></span> <span class="reference-text"><cite class="citation" id="CITEREFAndrej_KarpathyPieter_AbbeelGreg_BrockmanPeter_Chen"><a href="/wiki/Andrej_Karpathy" title="Andrej Karpathy">Andrej Karpathy</a>; <a href="/wiki/Pieter_Abbeel" title="Pieter Abbeel">Pieter Abbeel</a>; Greg Brockman; Peter Chen; Vicki Cheung; Rocky Duan; Ian Goodfellow; Durk Kingma; Jonathan Ho; Rein Houthooft; Tim Salimans; John Schulman; Ilya Sutskever; Wojciech Zaremba, <a class="external text" href="https://openai.com/blog/generative-models/" rel="nofollow"><i>Generative Models</i></a>, <a href="/wiki/OpenAI" title="OpenAI">OpenAI</a><span class="reference-accessdate">, retrieved <span class="nowrap">April 7,</span> 2016</span></cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Generative+Models&amp;rft.pub=OpenAI&amp;rft.au=Andrej+Karpathy&amp;rft.au=Pieter+Abbeel&amp;rft.au=Greg+Brockman&amp;rft.au=Peter+Chen&amp;rft.au=Vicki+Cheung&amp;rft.au=Rocky+Duan&amp;rft.au=Ian+Goodfellow&amp;rft.au=Durk+Kingma&amp;rft.au=Jonathan+Ho&amp;rft.au=Rein+Houthooft&amp;rft.au=Tim+Salimans&amp;rft.au=John+Schulman&amp;rft.au=Ilya+Sutskever&amp;rft.au=Wojciech+Zaremba&amp;rft_id=https%3A%2F%2Fopenai.com%2Fblog%2Fgenerative-models%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGenerative+adversarial+network"></span><link href="mw-data:TemplateStyles:r935243608" rel="mw-deduplicated-inline-style"/></span>
</li>
<li id="cite_note-8"><span class="mw-cite-backlink"><b><a href="#cite_ref-8">^</a></b></span> <span class="reference-text"><cite class="citation" id="CITEREFCaesar2019">Caesar, Holger (2019-03-01), <a class="external text" href="https://github.com/nightrome/really-awesome-gan" rel="nofollow"><i>A list of papers on Generative Adversarial (Neural) Networks: nightrome/really-awesome-gan</i></a><span class="reference-accessdate">, retrieved <span class="nowrap">2019-03-02</span></span></cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=A+list+of+papers+on+Generative+Adversarial+%28Neural%29+Networks%3A+nightrome%2Freally-awesome-gan&amp;rft.date=2019-03-01&amp;rft.aulast=Caesar&amp;rft.aufirst=Holger&amp;rft_id=https%3A%2F%2Fgithub.com%2Fnightrome%2Freally-awesome-gan&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGenerative+adversarial+network"></span><link href="mw-data:TemplateStyles:r935243608" rel="mw-deduplicated-inline-style"/></span>
</li>
<li id="cite_note-9"><span class="mw-cite-backlink"><b><a href="#cite_ref-9">^</a></b></span> <span class="reference-text"><cite class="citation web">Wong, Ceecee. <a class="external text" href="https://www.cdotrends.com/story/14300/rise-ai-supermodels" rel="nofollow">"The Rise of AI Supermodels"</a>. <i>CDO Trends</i>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=CDO+Trends&amp;rft.atitle=The+Rise+of+AI+Supermodels&amp;rft.aulast=Wong&amp;rft.aufirst=Ceecee&amp;rft_id=https%3A%2F%2Fwww.cdotrends.com%2Fstory%2F14300%2Frise-ai-supermodels&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGenerative+adversarial+network"></span><link href="mw-data:TemplateStyles:r935243608" rel="mw-deduplicated-inline-style"/></span>
</li>
<li id="cite_note-10"><span class="mw-cite-backlink"><b><a href="#cite_ref-10">^</a></b></span> <span class="reference-text"><cite class="citation web">Dietmar, Julia. <a class="external text" href="https://www.forbes.com/sites/forbestechcouncil/2019/05/21/gans-and-deepfakes-could-revolutionize-the-fashion-industry/#515624593d17" rel="nofollow">"GANs and Deepfakes Could Revolutionize The Fashion Industry"</a>. <i>Forbes</i>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Forbes&amp;rft.atitle=GANs+and+Deepfakes+Could+Revolutionize+The+Fashion+Industry&amp;rft.aulast=Dietmar&amp;rft.aufirst=Julia&amp;rft_id=https%3A%2F%2Fwww.forbes.com%2Fsites%2Fforbestechcouncil%2F2019%2F05%2F21%2Fgans-and-deepfakes-could-revolutionize-the-fashion-industry%2F%23515624593d17&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGenerative+adversarial+network"></span><link href="mw-data:TemplateStyles:r935243608" rel="mw-deduplicated-inline-style"/></span>
</li>
<li id="cite_note-11"><span class="mw-cite-backlink"><b><a href="#cite_ref-11">^</a></b></span> <span class="reference-text"><cite class="citation journal">Schawinski, Kevin; Zhang, Ce; Zhang, Hantian; Fowler, Lucas; Santhanam, Gokula Krishnan (2017-02-01). "Generative Adversarial Networks recover features in astrophysical images of galaxies beyond the deconvolution limit". <i>Monthly Notices of the Royal Astronomical Society: Letters</i>. <b>467</b> (1): L110–L114. <a href="/wiki/ArXiv" title="ArXiv">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="//arxiv.org/abs/1702.00403" rel="nofollow">1702.00403</a></span>. <a href="/wiki/Bibcode" title="Bibcode">Bibcode</a>:<a class="external text" href="https://ui.adsabs.harvard.edu/abs/2017MNRAS.467L.110S" rel="nofollow">2017MNRAS.467L.110S</a>. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a class="external text" href="https://doi.org/10.1093%2Fmnrasl%2Fslx008" rel="nofollow">10.1093/mnrasl/slx008</a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Monthly+Notices+of+the+Royal+Astronomical+Society%3A+Letters&amp;rft.atitle=Generative+Adversarial+Networks+recover+features+in+astrophysical+images+of+galaxies+beyond+the+deconvolution+limit&amp;rft.volume=467&amp;rft.issue=1&amp;rft.pages=L110-L114&amp;rft.date=2017-02-01&amp;rft_id=info%3Aarxiv%2F1702.00403&amp;rft_id=info%3Adoi%2F10.1093%2Fmnrasl%2Fslx008&amp;rft_id=info%3Abibcode%2F2017MNRAS.467L.110S&amp;rft.aulast=Schawinski&amp;rft.aufirst=Kevin&amp;rft.au=Zhang%2C+Ce&amp;rft.au=Zhang%2C+Hantian&amp;rft.au=Fowler%2C+Lucas&amp;rft.au=Santhanam%2C+Gokula+Krishnan&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGenerative+adversarial+network"></span><link href="mw-data:TemplateStyles:r935243608" rel="mw-deduplicated-inline-style"/></span>
</li>
<li id="cite_note-12"><span class="mw-cite-backlink"><b><a href="#cite_ref-12">^</a></b></span> <span class="reference-text"><cite class="citation news">Kincade, Kathy. <a class="external text" href="https://www.rdmag.com/news/2019/05/researchers-train-neural-network-study-dark-matter" rel="nofollow">"Researchers Train a Neural Network to Study Dark Matter"</a>. R&amp;D Magazine.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.atitle=Researchers+Train+a+Neural+Network+to+Study+Dark+Matter&amp;rft.aulast=Kincade&amp;rft.aufirst=Kathy&amp;rft_id=https%3A%2F%2Fwww.rdmag.com%2Fnews%2F2019%2F05%2Fresearchers-train-neural-network-study-dark-matter&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGenerative+adversarial+network"></span><link href="mw-data:TemplateStyles:r935243608" rel="mw-deduplicated-inline-style"/></span>
</li>
<li id="cite_note-13"><span class="mw-cite-backlink"><b><a href="#cite_ref-13">^</a></b></span> <span class="reference-text"><cite class="citation news">Kincade, Kathy (May 16, 2019). <a class="external text" href="https://phys.org/news/2019-05-cosmogan-neural-network-dark.html" rel="nofollow">"CosmoGAN: Training a neural network to study dark matter"</a>. <i>Phys.org</i>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Phys.org&amp;rft.atitle=CosmoGAN%3A+Training+a+neural+network+to+study+dark+matter&amp;rft.date=2019-05-16&amp;rft.aulast=Kincade&amp;rft.aufirst=Kathy&amp;rft_id=https%3A%2F%2Fphys.org%2Fnews%2F2019-05-cosmogan-neural-network-dark.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGenerative+adversarial+network"></span><link href="mw-data:TemplateStyles:r935243608" rel="mw-deduplicated-inline-style"/></span>
</li>
<li id="cite_note-14"><span class="mw-cite-backlink"><b><a href="#cite_ref-14">^</a></b></span> <span class="reference-text"><cite class="citation web"><a class="external text" href="https://www.sciencedaily.com/releases/2019/05/190516145206.htm" rel="nofollow">"Training a neural network to study dark matter"</a>. <i>Science Daily</i>. May 16, 2019.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Science+Daily&amp;rft.atitle=Training+a+neural+network+to+study+dark+matter&amp;rft.date=2019-05-16&amp;rft_id=https%3A%2F%2Fwww.sciencedaily.com%2Freleases%2F2019%2F05%2F190516145206.htm&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGenerative+adversarial+network"></span><link href="mw-data:TemplateStyles:r935243608" rel="mw-deduplicated-inline-style"/></span>
</li>
<li id="cite_note-15"><span class="mw-cite-backlink"><b><a href="#cite_ref-15">^</a></b></span> <span class="reference-text"><cite class="citation web">at 06:13, Katyanna Quach 20 May 2019. <a class="external text" href="https://www.theregister.co.uk/2019/05/20/neural_networks_dark_matter/" rel="nofollow">"Cosmoboffins use neural networks to build dark matter maps the easy way"</a>. <i>www.theregister.co.uk</i><span class="reference-accessdate">. Retrieved <span class="nowrap">2019-05-20</span></span>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=www.theregister.co.uk&amp;rft.atitle=Cosmoboffins+use+neural+networks+to+build+dark+matter+maps+the+easy+way&amp;rft.aulast=at+06%3A13&amp;rft.aufirst=Katyanna+Quach+20+May+2019&amp;rft_id=https%3A%2F%2Fwww.theregister.co.uk%2F2019%2F05%2F20%2Fneural_networks_dark_matter%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGenerative+adversarial+network"></span><link href="mw-data:TemplateStyles:r935243608" rel="mw-deduplicated-inline-style"/></span>
</li>
<li id="cite_note-16"><span class="mw-cite-backlink"><b><a href="#cite_ref-16">^</a></b></span> <span class="reference-text"><cite class="citation journal">Mustafa, Mustafa; Bard, Deborah; Bhimji, Wahid; Lukić, Zarija; Al-Rfou, Rami; Kratochvil, Jan M. (2019-05-06). "CosmoGAN: creating high-fidelity weak lensing convergence maps using Generative Adversarial Networks". <i>Computational Astrophysics and Cosmology</i>. <b>6</b> (1): 1. <a href="/wiki/ArXiv" title="ArXiv">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="//arxiv.org/abs/1706.02390" rel="nofollow">1706.02390</a></span>. <a href="/wiki/Bibcode" title="Bibcode">Bibcode</a>:<a class="external text" href="https://ui.adsabs.harvard.edu/abs/2019ComAC...6....1M" rel="nofollow">2019ComAC...6....1M</a>. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a class="external text" href="https://doi.org/10.1186%2Fs40668-019-0029-9" rel="nofollow">10.1186/s40668-019-0029-9</a>. <a href="/wiki/International_Standard_Serial_Number" title="International Standard Serial Number">ISSN</a> <a class="external text" href="//www.worldcat.org/issn/2197-7909" rel="nofollow">2197-7909</a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Computational+Astrophysics+and+Cosmology&amp;rft.atitle=CosmoGAN%3A+creating+high-fidelity+weak+lensing+convergence+maps+using+Generative+Adversarial+Networks&amp;rft.volume=6&amp;rft.issue=1&amp;rft.pages=1&amp;rft.date=2019-05-06&amp;rft_id=info%3Aarxiv%2F1706.02390&amp;rft.issn=2197-7909&amp;rft_id=info%3Adoi%2F10.1186%2Fs40668-019-0029-9&amp;rft_id=info%3Abibcode%2F2019ComAC...6....1M&amp;rft.aulast=Mustafa&amp;rft.aufirst=Mustafa&amp;rft.au=Bard%2C+Deborah&amp;rft.au=Bhimji%2C+Wahid&amp;rft.au=Luki%C4%87%2C+Zarija&amp;rft.au=Al-Rfou%2C+Rami&amp;rft.au=Kratochvil%2C+Jan+M.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGenerative+adversarial+network"></span><link href="mw-data:TemplateStyles:r935243608" rel="mw-deduplicated-inline-style"/></span>
</li>
<li id="cite_note-17"><span class="mw-cite-backlink"><b><a href="#cite_ref-17">^</a></b></span> <span class="reference-text"><cite class="citation journal">Paganini, Michela; de Oliveira, Luke; Nachman, Benjamin (2017). "Learning Particle Physics by Example: Location-Aware Generative Adversarial Networks for Physics Synthesis". <i>Computing and Software for Big Science</i>. <b>1</b>: 4. <a href="/wiki/ArXiv" title="ArXiv">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="//arxiv.org/abs/1701.05927" rel="nofollow">1701.05927</a></span>. <a href="/wiki/Bibcode" title="Bibcode">Bibcode</a>:<a class="external text" href="https://ui.adsabs.harvard.edu/abs/2017arXiv170105927D" rel="nofollow">2017arXiv170105927D</a>. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a class="external text" href="https://doi.org/10.1007%2Fs41781-017-0004-6" rel="nofollow">10.1007/s41781-017-0004-6</a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Computing+and+Software+for+Big+Science&amp;rft.atitle=Learning+Particle+Physics+by+Example%3A+Location-Aware+Generative+Adversarial+Networks+for+Physics+Synthesis&amp;rft.volume=1&amp;rft.pages=4&amp;rft.date=2017&amp;rft_id=info%3Aarxiv%2F1701.05927&amp;rft_id=info%3Adoi%2F10.1007%2Fs41781-017-0004-6&amp;rft_id=info%3Abibcode%2F2017arXiv170105927D&amp;rft.aulast=Paganini&amp;rft.aufirst=Michela&amp;rft.au=de+Oliveira%2C+Luke&amp;rft.au=Nachman%2C+Benjamin&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGenerative+adversarial+network"></span><link href="mw-data:TemplateStyles:r935243608" rel="mw-deduplicated-inline-style"/></span>
</li>
<li id="cite_note-18"><span class="mw-cite-backlink"><b><a href="#cite_ref-18">^</a></b></span> <span class="reference-text"><cite class="citation journal">Paganini, Michela; de Oliveira, Luke; Nachman, Benjamin (2018). "Accelerating Science with Generative Adversarial Networks: An Application to 3D Particle Showers in Multi-Layer Calorimeters". <i>Physical Review Letters</i>. <b>120</b> (4): 042003. <a href="/wiki/ArXiv" title="ArXiv">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="//arxiv.org/abs/1705.02355" rel="nofollow">1705.02355</a></span>. <a href="/wiki/Bibcode" title="Bibcode">Bibcode</a>:<a class="external text" href="https://ui.adsabs.harvard.edu/abs/2018PhRvL.120d2003P" rel="nofollow">2018PhRvL.120d2003P</a>. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a class="external text" href="https://doi.org/10.1103%2FPhysRevLett.120.042003" rel="nofollow">10.1103/PhysRevLett.120.042003</a>. <a class="mw-redirect" href="/wiki/PubMed_Identifier" title="PubMed Identifier">PMID</a> <a class="external text" href="//pubmed.ncbi.nlm.nih.gov/29437460" rel="nofollow">29437460</a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Physical+Review+Letters&amp;rft.atitle=Accelerating+Science+with+Generative+Adversarial+Networks%3A+An+Application+to+3D+Particle+Showers+in+Multi-Layer+Calorimeters&amp;rft.volume=120&amp;rft.issue=4&amp;rft.pages=042003&amp;rft.date=2018&amp;rft_id=info%3Aarxiv%2F1705.02355&amp;rft_id=info%3Apmid%2F29437460&amp;rft_id=info%3Adoi%2F10.1103%2FPhysRevLett.120.042003&amp;rft_id=info%3Abibcode%2F2018PhRvL.120d2003P&amp;rft.aulast=Paganini&amp;rft.aufirst=Michela&amp;rft.au=de+Oliveira%2C+Luke&amp;rft.au=Nachman%2C+Benjamin&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGenerative+adversarial+network"></span><link href="mw-data:TemplateStyles:r935243608" rel="mw-deduplicated-inline-style"/></span>
</li>
<li id="cite_note-19"><span class="mw-cite-backlink"><b><a href="#cite_ref-19">^</a></b></span> <span class="reference-text"><cite class="citation journal">Paganini, Michela; de Oliveira, Luke; Nachman, Benjamin (2018). "CaloGAN: Simulating 3D High Energy Particle Showers in Multi-Layer Electromagnetic Calorimeters with Generative Adversarial Networks". <i>Phys. Rev. D</i>. <b>97</b> (1): 014021. <a href="/wiki/ArXiv" title="ArXiv">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="//arxiv.org/abs/1712.10321" rel="nofollow">1712.10321</a></span>. <a href="/wiki/Bibcode" title="Bibcode">Bibcode</a>:<a class="external text" href="https://ui.adsabs.harvard.edu/abs/2018PhRvD..97a4021P" rel="nofollow">2018PhRvD..97a4021P</a>. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a class="external text" href="https://doi.org/10.1103%2FPhysRevD.97.014021" rel="nofollow">10.1103/PhysRevD.97.014021</a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Phys.+Rev.+D&amp;rft.atitle=CaloGAN%3A+Simulating+3D+High+Energy+Particle+Showers+in+Multi-Layer+Electromagnetic+Calorimeters+with+Generative+Adversarial+Networks&amp;rft.volume=97&amp;rft.issue=1&amp;rft.pages=014021&amp;rft.date=2018&amp;rft_id=info%3Aarxiv%2F1712.10321&amp;rft_id=info%3Adoi%2F10.1103%2FPhysRevD.97.014021&amp;rft_id=info%3Abibcode%2F2018PhRvD..97a4021P&amp;rft.aulast=Paganini&amp;rft.aufirst=Michela&amp;rft.au=de+Oliveira%2C+Luke&amp;rft.au=Nachman%2C+Benjamin&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGenerative+adversarial+network"></span><link href="mw-data:TemplateStyles:r935243608" rel="mw-deduplicated-inline-style"/></span>
</li>
<li id="cite_note-20"><span class="mw-cite-backlink"><b><a href="#cite_ref-20">^</a></b></span> <span class="reference-text"><cite class="citation journal">Erdmann, Martin; Glombitza, Jonas; Quast, Thorben (2019). "Precise Simulation of Electromagnetic Calorimeter Showers Using a Wasserstein Generative Adversarial Network". <i>Computing and Software for Big Science</i>. <b>3</b>: 4. <a href="/wiki/ArXiv" title="ArXiv">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="//arxiv.org/abs/1807.01954" rel="nofollow">1807.01954</a></span>. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a class="external text" href="https://doi.org/10.1007%2Fs41781-018-0019-7" rel="nofollow">10.1007/s41781-018-0019-7</a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Computing+and+Software+for+Big+Science&amp;rft.atitle=Precise+Simulation+of+Electromagnetic+Calorimeter+Showers+Using+a+Wasserstein+Generative+Adversarial+Network&amp;rft.volume=3&amp;rft.pages=4&amp;rft.date=2019&amp;rft_id=info%3Aarxiv%2F1807.01954&amp;rft_id=info%3Adoi%2F10.1007%2Fs41781-018-0019-7&amp;rft.aulast=Erdmann&amp;rft.aufirst=Martin&amp;rft.au=Glombitza%2C+Jonas&amp;rft.au=Quast%2C+Thorben&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGenerative+adversarial+network"></span><link href="mw-data:TemplateStyles:r935243608" rel="mw-deduplicated-inline-style"/></span>
</li>
<li id="cite_note-21"><span class="mw-cite-backlink"><b><a href="#cite_ref-21">^</a></b></span> <span class="reference-text"><cite class="citation journal">Musella, Pasquale; Pandolfi, Francesco (2018). "Fast and Accurate Simulation of Particle Detectors Using Generative Adversarial Networks". <i>Computing and Software for Big Science</i>. <b>2</b>: 8. <a href="/wiki/ArXiv" title="ArXiv">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="//arxiv.org/abs/1805.00850" rel="nofollow">1805.00850</a></span>. <a href="/wiki/Bibcode" title="Bibcode">Bibcode</a>:<a class="external text" href="https://ui.adsabs.harvard.edu/abs/2018arXiv180500850M" rel="nofollow">2018arXiv180500850M</a>. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a class="external text" href="https://doi.org/10.1007%2Fs41781-018-0015-y" rel="nofollow">10.1007/s41781-018-0015-y</a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Computing+and+Software+for+Big+Science&amp;rft.atitle=Fast+and+Accurate+Simulation+of+Particle+Detectors+Using+Generative+Adversarial+Networks&amp;rft.volume=2&amp;rft.pages=8&amp;rft.date=2018&amp;rft_id=info%3Aarxiv%2F1805.00850&amp;rft_id=info%3Adoi%2F10.1007%2Fs41781-018-0015-y&amp;rft_id=info%3Abibcode%2F2018arXiv180500850M&amp;rft.aulast=Musella&amp;rft.aufirst=Pasquale&amp;rft.au=Pandolfi%2C+Francesco&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGenerative+adversarial+network"></span><link href="mw-data:TemplateStyles:r935243608" rel="mw-deduplicated-inline-style"/></span>
</li>
<li id="cite_note-22"><span class="mw-cite-backlink"><b><a href="#cite_ref-22">^</a></b></span> <span class="reference-text"><cite class="citation web">ATLAS, Collaboration (2018). <a class="external text" href="https://atlas.web.cern.ch/Atlas/GROUPS/PHYSICS/PUBNOTES/ATL-SOFT-PUB-2018-001/" rel="nofollow">"Deep generative models for fast shower simulation in ATLAS"</a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Deep+generative+models+for+fast+shower+simulation+in+ATLAS&amp;rft.date=2018&amp;rft.aulast=ATLAS&amp;rft.aufirst=Collaboration&amp;rft_id=https%3A%2F%2Fatlas.web.cern.ch%2FAtlas%2FGROUPS%2FPHYSICS%2FPUBNOTES%2FATL-SOFT-PUB-2018-001%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGenerative+adversarial+network"></span><link href="mw-data:TemplateStyles:r935243608" rel="mw-deduplicated-inline-style"/></span>
</li>
<li id="cite_note-23"><span class="mw-cite-backlink"><b><a href="#cite_ref-23">^</a></b></span> <span class="reference-text"><cite class="citation journal">SHiP, Collaboration (2019). "Fast simulation of muons produced at the SHiP experiment using Generative Adversarial Networks". <i>Journal of Instrumentation</i>. <b>14</b> (11): P11028. <a href="/wiki/ArXiv" title="ArXiv">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="//arxiv.org/abs/1909.04451" rel="nofollow">1909.04451</a></span>. <a href="/wiki/Bibcode" title="Bibcode">Bibcode</a>:<a class="external text" href="https://ui.adsabs.harvard.edu/abs/2019JInst..14P1028A" rel="nofollow">2019JInst..14P1028A</a>. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a class="external text" href="https://doi.org/10.1088%2F1748-0221%2F14%2F11%2FP11028" rel="nofollow">10.1088/1748-0221/14/11/P11028</a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Journal+of+Instrumentation&amp;rft.atitle=Fast+simulation+of+muons+produced+at+the+SHiP+experiment+using+Generative+Adversarial+Networks&amp;rft.volume=14&amp;rft.issue=11&amp;rft.pages=P11028&amp;rft.date=2019&amp;rft_id=info%3Aarxiv%2F1909.04451&amp;rft_id=info%3Adoi%2F10.1088%2F1748-0221%2F14%2F11%2FP11028&amp;rft_id=info%3Abibcode%2F2019JInst..14P1028A&amp;rft.aulast=SHiP&amp;rft.aufirst=Collaboration&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGenerative+adversarial+network"></span><link href="mw-data:TemplateStyles:r935243608" rel="mw-deduplicated-inline-style"/></span>
</li>
<li id="cite_note-24"><span class="mw-cite-backlink"><b><a href="#cite_ref-24">^</a></b></span> <span class="reference-text"><cite class="citation news">Tang, Xiaoou; Qiao, Yu; Loy, Chen Change; Dong, Chao; Liu, Yihao; Gu, Jinjin; Wu, Shixiang; Yu, Ke; Wang, Xintao (2018-09-01). "ESRGAN: Enhanced Super-Resolution Generative Adversarial Networks". <a href="/wiki/ArXiv" title="ArXiv">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="//arxiv.org/abs/1809.00219" rel="nofollow">1809.00219</a></span>. <a href="/wiki/Bibcode" title="Bibcode">Bibcode</a>:<a class="external text" href="https://ui.adsabs.harvard.edu/abs/2018arXiv180900219W" rel="nofollow">2018arXiv180900219W</a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.atitle=ESRGAN%3A+Enhanced+Super-Resolution+Generative+Adversarial+Networks&amp;rft.date=2018-09-01&amp;rft_id=info%3Aarxiv%2F1809.00219&amp;rft_id=info%3Abibcode%2F2018arXiv180900219W&amp;rft.aulast=Tang&amp;rft.aufirst=Xiaoou&amp;rft.au=Qiao%2C+Yu&amp;rft.au=Loy%2C+Chen+Change&amp;rft.au=Dong%2C+Chao&amp;rft.au=Liu%2C+Yihao&amp;rft.au=Gu%2C+Jinjin&amp;rft.au=Wu%2C+Shixiang&amp;rft.au=Yu%2C+Ke&amp;rft.au=Wang%2C+Xintao&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGenerative+adversarial+network"></span><link href="mw-data:TemplateStyles:r935243608" rel="mw-deduplicated-inline-style"/></span>
</li>
<li id="cite_note-TPDNEwuaitcryhf|-25"><span class="mw-cite-backlink"><b><a href="#cite_ref-TPDNEwuaitcryhf|_25-0">^</a></b></span> <span class="reference-text"><cite class="citation web">msmash (2019-02-14). <a class="external text" href="https://tech.slashdot.org/story/19/02/14/199200/this-person-does-not-exist-website-uses-ai-to-create-realistic-yet-horrifying-faces" rel="nofollow">"<span class="cs1-kern-left">'</span>This Person Does Not Exist' Website Uses AI To Create Realistic Yet Horrifying Faces"</a>. <i>Slashdot</i><span class="reference-accessdate">. Retrieved <span class="nowrap">2019-02-16</span></span>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Slashdot&amp;rft.atitle=%27This+Person+Does+Not+Exist%27+Website+Uses+AI+To+Create+Realistic+Yet+Horrifying+Faces&amp;rft.date=2019-02-14&amp;rft.au=msmash&amp;rft_id=https%3A%2F%2Ftech.slashdot.org%2Fstory%2F19%2F02%2F14%2F199200%2Fthis-person-does-not-exist-website-uses-ai-to-create-realistic-yet-horrifying-faces&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGenerative+adversarial+network"></span><link href="mw-data:TemplateStyles:r935243608" rel="mw-deduplicated-inline-style"/></span>
</li>
<li id="cite_note-26"><span class="mw-cite-backlink"><b><a href="#cite_ref-26">^</a></b></span> <span class="reference-text"><cite class="citation news">Doyle, Michael (May 16, 2019). <a class="external text" href="https://www.courierpress.com/story/news/crime/2019/05/16/john-beasley-lives-saddlehorse-drive-evansville-does-he/3700111002/" rel="nofollow">"John Beasley lives on Saddlehorse Drive in Evansville. Or does he?"</a>. Courier and Press.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.atitle=John+Beasley+lives+on+Saddlehorse+Drive+in+Evansville.+Or+does+he%3F&amp;rft.date=2019-05-16&amp;rft.aulast=Doyle&amp;rft.aufirst=Michael&amp;rft_id=https%3A%2F%2Fwww.courierpress.com%2Fstory%2Fnews%2Fcrime%2F2019%2F05%2F16%2Fjohn-beasley-lives-saddlehorse-drive-evansville-does-he%2F3700111002%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGenerative+adversarial+network"></span><link href="mw-data:TemplateStyles:r935243608" rel="mw-deduplicated-inline-style"/></span>
</li>
<li id="cite_note-27"><span class="mw-cite-backlink"><b><a href="#cite_ref-27">^</a></b></span> <span class="reference-text"><cite class="citation news">Targett, Ed (May 16, 2019). "California moves closer to making deepfake pornography illegal". Computer Business Review.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.atitle=California+moves+closer+to+making+deepfake+pornography+illegal&amp;rft.date=2019-05-16&amp;rft.aulast=Targett&amp;rft.aufirst=Ed&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGenerative+adversarial+network"></span><link href="mw-data:TemplateStyles:r935243608" rel="mw-deduplicated-inline-style"/></span>
</li>
<li id="cite_note-CNET2019-28"><span class="mw-cite-backlink"><b><a href="#cite_ref-CNET2019_28-0">^</a></b></span> <span class="reference-text">
<cite class="citation web">Mihalcik, Carrie (2019-10-04). <a class="external text" href="https://www.cnet.com/news/california-laws-seek-to-crack-down-on-deepfakes-in-politics-and-porn/" rel="nofollow">"California laws seek to crack down on deepfakes in politics and porn"</a>. <i><a class="mw-redirect" href="/wiki/Cnet.com" title="Cnet.com">cnet.com</a></i>. <a href="/wiki/CNET" title="CNET">CNET</a><span class="reference-accessdate">. Retrieved <span class="nowrap">2019-10-13</span></span>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=cnet.com&amp;rft.atitle=California+laws+seek+to+crack+down+on+deepfakes+in+politics+and+porn&amp;rft.date=2019-10-04&amp;rft.aulast=Mihalcik&amp;rft.aufirst=Carrie&amp;rft_id=https%3A%2F%2Fwww.cnet.com%2Fnews%2Fcalifornia-laws-seek-to-crack-down-on-deepfakes-in-politics-and-porn%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGenerative+adversarial+network"></span><link href="mw-data:TemplateStyles:r935243608" rel="mw-deduplicated-inline-style"/></span>
</li>
<li id="cite_note-29"><span class="mw-cite-backlink"><b><a href="#cite_ref-29">^</a></b></span> <span class="reference-text"><cite class="citation magazine">Knight, Will (Aug 7, 2018). <a class="external text" href="https://www.technologyreview.com/s/611726/the-defense-department-has-produced-the-first-tools-for-catching-deepfakes/" rel="nofollow">"The Defense Department has produced the first tools for catching deepfakes"</a>. <i>MIT Technology Review</i>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=MIT+Technology+Review&amp;rft.atitle=The+Defense+Department+has+produced+the+first+tools+for+catching+deepfakes&amp;rft.date=2018-08-07&amp;rft.aulast=Knight&amp;rft.aufirst=Will&amp;rft_id=https%3A%2F%2Fwww.technologyreview.com%2Fs%2F611726%2Fthe-defense-department-has-produced-the-first-tools-for-catching-deepfakes%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGenerative+adversarial+network"></span><link href="mw-data:TemplateStyles:r935243608" rel="mw-deduplicated-inline-style"/></span>
</li>
<li id="cite_note-30"><span class="mw-cite-backlink"><b><a href="#cite_ref-30">^</a></b></span> <span class="reference-text"><cite class="citation journal">Bisneto, Tomaz Ribeiro Viana; de Carvalho Filho, Antonio Oseas; Magalhães, Deborah Maria Vieira (February 2020). "Generative adversarial network and texture features applied to automatic glaucoma detection". <i>Applied Soft Computing</i>. <b>90</b>: 106165. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a class="external text" href="https://doi.org/10.1016%2Fj.asoc.2020.106165" rel="nofollow">10.1016/j.asoc.2020.106165</a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Applied+Soft+Computing&amp;rft.atitle=Generative+adversarial+network+and+texture+features+applied+to+automatic+glaucoma+detection&amp;rft.volume=90&amp;rft.pages=106165&amp;rft.date=2020-02&amp;rft_id=info%3Adoi%2F10.1016%2Fj.asoc.2020.106165&amp;rft.aulast=Bisneto&amp;rft.aufirst=Tomaz+Ribeiro+Viana&amp;rft.au=de+Carvalho+Filho%2C+Antonio+Oseas&amp;rft.au=Magalh%C3%A3es%2C+Deborah+Maria+Vieira&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGenerative+adversarial+network"></span><link href="mw-data:TemplateStyles:r935243608" rel="mw-deduplicated-inline-style"/></span>
</li>
<li id="cite_note-31"><span class="mw-cite-backlink"><b><a href="#cite_ref-31">^</a></b></span> <span class="reference-text"><cite class="citation web">Wei, Jerry (2019-07-03). <a class="external text" href="https://towardsdatascience.com/generating-shoe-designs-with-deep-learning-5dde432a23b8" rel="nofollow">"Generating Shoe Designs with Machine Learning"</a>. <i>Medium</i><span class="reference-accessdate">. Retrieved <span class="nowrap">2019-11-06</span></span>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Medium&amp;rft.atitle=Generating+Shoe+Designs+with+Machine+Learning&amp;rft.date=2019-07-03&amp;rft.aulast=Wei&amp;rft.aufirst=Jerry&amp;rft_id=https%3A%2F%2Ftowardsdatascience.com%2Fgenerating-shoe-designs-with-deep-learning-5dde432a23b8&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGenerative+adversarial+network"></span><link href="mw-data:TemplateStyles:r935243608" rel="mw-deduplicated-inline-style"/></span>
</li>
<li id="cite_note-32"><span class="mw-cite-backlink"><b><a href="#cite_ref-32">^</a></b></span> <span class="reference-text"><cite class="citation web">Greenemeier, Larry (June 20, 2016). <a class="external text" href="https://www.scientificamerican.com/article/when-will-computers-have-common-sense-ask-facebook/" rel="nofollow">"When Will Computers Have Common Sense? Ask Facebook"</a>. <i>Scientific American</i><span class="reference-accessdate">. Retrieved <span class="nowrap">July 31,</span> 2016</span>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Scientific+American&amp;rft.atitle=When+Will+Computers+Have+Common+Sense%3F+Ask+Facebook&amp;rft.date=2016-06-20&amp;rft.aulast=Greenemeier&amp;rft.aufirst=Larry&amp;rft_id=https%3A%2F%2Fwww.scientificamerican.com%2Farticle%2Fwhen-will-computers-have-common-sense-ask-facebook%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGenerative+adversarial+network"></span><link href="mw-data:TemplateStyles:r935243608" rel="mw-deduplicated-inline-style"/></span>
</li>
<li id="cite_note-33"><span class="mw-cite-backlink"><b><a href="#cite_ref-33">^</a></b></span> <span class="reference-text"><cite class="citation web"><a class="external text" href="http://3dgan.csail.mit.edu/" rel="nofollow">"3D Generative Adversarial Network"</a>. <i>3dgan.csail.mit.edu</i>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=3dgan.csail.mit.edu&amp;rft.atitle=3D+Generative+Adversarial+Network&amp;rft_id=http%3A%2F%2F3dgan.csail.mit.edu%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGenerative+adversarial+network"></span><link href="mw-data:TemplateStyles:r935243608" rel="mw-deduplicated-inline-style"/></span>
</li>
<li id="cite_note-34"><span class="mw-cite-backlink"><b><a href="#cite_ref-34">^</a></b></span> <span class="reference-text"><cite class="citation web">Vondrick, Carl; Pirsiavash, Hamed; Torralba, Antonio (2016). <a class="external text" href="https://www.cs.columbia.edu/~vondrick/tinyvideo/" rel="nofollow">"Generating Videos with Scene Dynamics"</a>. <i>carlvondrick.com</i>. <a href="/wiki/ArXiv" title="ArXiv">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="//arxiv.org/abs/1609.02612" rel="nofollow">1609.02612</a></span>. <a href="/wiki/Bibcode" title="Bibcode">Bibcode</a>:<a class="external text" href="https://ui.adsabs.harvard.edu/abs/2016arXiv160902612V" rel="nofollow">2016arXiv160902612V</a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=carlvondrick.com&amp;rft.atitle=Generating+Videos+with+Scene+Dynamics&amp;rft.date=2016&amp;rft_id=info%3Aarxiv%2F1609.02612&amp;rft_id=info%3Abibcode%2F2016arXiv160902612V&amp;rft.aulast=Vondrick&amp;rft.aufirst=Carl&amp;rft.au=Pirsiavash%2C+Hamed&amp;rft.au=Torralba%2C+Antonio&amp;rft_id=https%3A%2F%2Fwww.cs.columbia.edu%2F~vondrick%2Ftinyvideo%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGenerative+adversarial+network"></span><link href="mw-data:TemplateStyles:r935243608" rel="mw-deduplicated-inline-style"/></span>
</li>
<li id="cite_note-35"><span class="mw-cite-backlink"><b><a href="#cite_ref-35">^</a></b></span> <span class="reference-text"><cite class="citation arxiv">Antipov, Grigory; Baccouche, Moez; Dugelay, Jean-Luc (2017). "Face Aging With Conditional Generative Adversarial Networks". <a href="/wiki/ArXiv" title="ArXiv">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="//arxiv.org/abs/1702.01983" rel="nofollow">1702.01983</a></span> [<a class="external text" href="//arxiv.org/archive/cs.CV" rel="nofollow">cs.CV</a>].</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=Face+Aging+With+Conditional+Generative+Adversarial+Networks&amp;rft.date=2017&amp;rft_id=info%3Aarxiv%2F1702.01983&amp;rft.aulast=Antipov&amp;rft.aufirst=Grigory&amp;rft.au=Baccouche%2C+Moez&amp;rft.au=Dugelay%2C+Jean-Luc&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGenerative+adversarial+network"></span><link href="mw-data:TemplateStyles:r935243608" rel="mw-deduplicated-inline-style"/></span>
</li>
<li id="cite_note-36"><span class="mw-cite-backlink"><b><a href="#cite_ref-36">^</a></b></span> <span class="reference-text"><cite class="citation journal">Kang, Yuhao; Gao, Song; Roth, Rob (2019). <a class="external text" href="https://geods.geography.wisc.edu/archives/1192" rel="nofollow">"Transferring Multiscale Map Styles Using Generative Adversarial Networks"</a>. <i>International Journal of Cartography</i>. <b>5</b> (2–3): 115–141. <a href="/wiki/ArXiv" title="ArXiv">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="//arxiv.org/abs/1905.02200" rel="nofollow">1905.02200</a></span>. <a href="/wiki/Bibcode" title="Bibcode">Bibcode</a>:<a class="external text" href="https://ui.adsabs.harvard.edu/abs/2019arXiv190502200K" rel="nofollow">2019arXiv190502200K</a>. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a class="external text" href="https://doi.org/10.1080%2F23729333.2019.1615729" rel="nofollow">10.1080/23729333.2019.1615729</a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=International+Journal+of+Cartography&amp;rft.atitle=Transferring+Multiscale+Map+Styles+Using+Generative+Adversarial+Networks&amp;rft.volume=5&amp;rft.issue=2%E2%80%933&amp;rft.pages=115-141&amp;rft.date=2019&amp;rft_id=info%3Aarxiv%2F1905.02200&amp;rft_id=info%3Adoi%2F10.1080%2F23729333.2019.1615729&amp;rft_id=info%3Abibcode%2F2019arXiv190502200K&amp;rft.aulast=Kang&amp;rft.aufirst=Yuhao&amp;rft.au=Gao%2C+Song&amp;rft.au=Roth%2C+Rob&amp;rft_id=https%3A%2F%2Fgeods.geography.wisc.edu%2Farchives%2F1192&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGenerative+adversarial+network"></span><link href="mw-data:TemplateStyles:r935243608" rel="mw-deduplicated-inline-style"/></span>
</li>
<li id="cite_note-37"><span class="mw-cite-backlink"><b><a href="#cite_ref-37">^</a></b></span> <span class="reference-text"><cite class="citation journal">Wijnands, Jasper; Nice, Kerry; Thompson, Jason; Zhao, Haifeng; Stevenson, Mark (2019). "Streetscape augmentation using generative adversarial networks: Insights related to health and wellbeing". <i>Sustainable Cities and Society</i>. <b>49</b>: 101602. <a href="/wiki/ArXiv" title="ArXiv">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="//arxiv.org/abs/1905.06464" rel="nofollow">1905.06464</a></span>. <a href="/wiki/Bibcode" title="Bibcode">Bibcode</a>:<a class="external text" href="https://ui.adsabs.harvard.edu/abs/2019arXiv190506464W" rel="nofollow">2019arXiv190506464W</a>. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a class="external text" href="https://doi.org/10.1016%2Fj.scs.2019.101602" rel="nofollow">10.1016/j.scs.2019.101602</a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Sustainable+Cities+and+Society&amp;rft.atitle=Streetscape+augmentation+using+generative+adversarial+networks%3A+Insights+related+to+health+and+wellbeing&amp;rft.volume=49&amp;rft.pages=101602&amp;rft.date=2019&amp;rft_id=info%3Aarxiv%2F1905.06464&amp;rft_id=info%3Adoi%2F10.1016%2Fj.scs.2019.101602&amp;rft_id=info%3Abibcode%2F2019arXiv190506464W&amp;rft.aulast=Wijnands&amp;rft.aufirst=Jasper&amp;rft.au=Nice%2C+Kerry&amp;rft.au=Thompson%2C+Jason&amp;rft.au=Zhao%2C+Haifeng&amp;rft.au=Stevenson%2C+Mark&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGenerative+adversarial+network"></span><link href="mw-data:TemplateStyles:r935243608" rel="mw-deduplicated-inline-style"/></span>
</li>
<li id="cite_note-38"><span class="mw-cite-backlink"><b><a href="#cite_ref-38">^</a></b></span> <span class="reference-text"><cite class="citation journal">Padhi, Radhakant; Unnikrishnan, Nishant (2006). "A single network adaptive critic (SNAC) architecture for optimal control synthesis for a class of nonlinear systems". <i>Neural Networks</i>. <b>19</b> (10): 1648–1660. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a class="external text" href="https://doi.org/10.1016%2Fj.neunet.2006.08.010" rel="nofollow">10.1016/j.neunet.2006.08.010</a>. <a class="mw-redirect" href="/wiki/PubMed_Identifier" title="PubMed Identifier">PMID</a> <a class="external text" href="//pubmed.ncbi.nlm.nih.gov/17045458" rel="nofollow">17045458</a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Neural+Networks&amp;rft.atitle=A+single+network+adaptive+critic+%28SNAC%29+architecture+for+optimal+control+synthesis+for+a+class+of+nonlinear+systems&amp;rft.volume=19&amp;rft.issue=10&amp;rft.pages=1648-1660&amp;rft.date=2006&amp;rft_id=info%3Adoi%2F10.1016%2Fj.neunet.2006.08.010&amp;rft_id=info%3Apmid%2F17045458&amp;rft.aulast=Padhi&amp;rft.aufirst=Radhakant&amp;rft.au=Unnikrishnan%2C+Nishant&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGenerative+adversarial+network"></span><link href="mw-data:TemplateStyles:r935243608" rel="mw-deduplicated-inline-style"/></span>
</li>
<li id="cite_note-39"><span class="mw-cite-backlink"><b><a href="#cite_ref-39">^</a></b></span> <span class="reference-text"><cite class="citation magazine"><a class="external text" href="https://www.technologyreview.com/f/613547/ai-can-show-us-the-ravages-of-climate-change/" rel="nofollow">"AI can show us the ravages of climate change"</a>. <i>MIT Technology Review</i>. May 16, 2019.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=MIT+Technology+Review&amp;rft.atitle=AI+can+show+us+the+ravages+of+climate+change&amp;rft.date=2019-05-16&amp;rft_id=https%3A%2F%2Fwww.technologyreview.com%2Ff%2F613547%2Fai-can-show-us-the-ravages-of-climate-change%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGenerative+adversarial+network"></span><link href="mw-data:TemplateStyles:r935243608" rel="mw-deduplicated-inline-style"/></span>
</li>
<li id="cite_note-40"><span class="mw-cite-backlink"><b><a href="#cite_ref-40">^</a></b></span> <span class="reference-text"><cite class="citation news">Christian, Jon (May 28, 2019). <a class="external text" href="https://futurism.com/the-byte/ai-guesses-appearance-voice" rel="nofollow">"ASTOUNDING AI GUESSES WHAT YOU LOOK LIKE BASED ON YOUR VOICE"</a>. Futurism.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.atitle=ASTOUNDING+AI+GUESSES+WHAT+YOU+LOOK+LIKE+BASED+ON+YOUR+VOICE&amp;rft.date=2019-05-28&amp;rft.aulast=Christian&amp;rft.aufirst=Jon&amp;rft_id=https%3A%2F%2Ffuturism.com%2Fthe-byte%2Fai-guesses-appearance-voice&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGenerative+adversarial+network"></span><link href="mw-data:TemplateStyles:r935243608" rel="mw-deduplicated-inline-style"/></span>
</li>
<li id="cite_note-41"><span class="mw-cite-backlink"><b><a href="#cite_ref-41">^</a></b></span> <span class="reference-text"><cite class="citation journal">Zhavoronkov, Alex (2019). <a class="external text" href="https://www.semanticscholar.org/paper/d44ac0a7fd4734187bccafc4a2771027b8bb595e" rel="nofollow">"Deep learning enables rapid identification of potent DDR1 kinase inhibitors"</a>. <i>Nature Biotechnology</i>. <b>37</b> (9): 1038–1040. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a class="external text" href="https://doi.org/10.1038%2Fs41587-019-0224-x" rel="nofollow">10.1038/s41587-019-0224-x</a>. <a class="mw-redirect" href="/wiki/PubMed_Identifier" title="PubMed Identifier">PMID</a> <a class="external text" href="//pubmed.ncbi.nlm.nih.gov/31477924" rel="nofollow">31477924</a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Nature+Biotechnology&amp;rft.atitle=Deep+learning+enables+rapid+identification+of+potent+DDR1+kinase+inhibitors&amp;rft.volume=37&amp;rft.issue=9&amp;rft.pages=1038-1040&amp;rft.date=2019&amp;rft_id=info%3Adoi%2F10.1038%2Fs41587-019-0224-x&amp;rft_id=info%3Apmid%2F31477924&amp;rft.aulast=Zhavoronkov&amp;rft.aufirst=Alex&amp;rft_id=https%3A%2F%2Fwww.semanticscholar.org%2Fpaper%2Fd44ac0a7fd4734187bccafc4a2771027b8bb595e&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGenerative+adversarial+network"></span><link href="mw-data:TemplateStyles:r935243608" rel="mw-deduplicated-inline-style"/></span>
</li>
<li id="cite_note-42"><span class="mw-cite-backlink"><b><a href="#cite_ref-42">^</a></b></span> <span class="reference-text"><cite class="citation journal">Gregory, Barber. <a class="external text" href="https://www.wired.com/story/molecule-designed-ai-exhibits-druglike-qualities/" rel="nofollow">"A Molecule Designed By AI Exhibits 'Druglike' Qualities"</a>. <i>Wired</i>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Wired&amp;rft.atitle=A+Molecule+Designed+By+AI+Exhibits+%27Druglike%27+Qualities&amp;rft.aulast=Gregory&amp;rft.aufirst=Barber&amp;rft_id=https%3A%2F%2Fwww.wired.com%2Fstory%2Fmolecule-designed-ai-exhibits-druglike-qualities%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGenerative+adversarial+network"></span><link href="mw-data:TemplateStyles:r935243608" rel="mw-deduplicated-inline-style"/></span>
</li>
<li id="cite_note-43"><span class="mw-cite-backlink"><b><a href="#cite_ref-43">^</a></b></span> <span class="reference-text"><cite class="citation journal">Gutmann, Michael; Hyvärinen, Aapo. <a class="external text" href="http://proceedings.mlr.press/v9/gutmann10a/gutmann10a.pdf" rel="nofollow">"Noise-Contrastive Estimation"</a> <span class="cs1-format">(PDF)</span>. <i>International Conference on AI and Statistics</i>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=International+Conference+on+AI+and+Statistics&amp;rft.atitle=Noise-Contrastive+Estimation&amp;rft.aulast=Gutmann&amp;rft.aufirst=Michael&amp;rft.au=Hyv%C3%A4rinen%2C+Aapo&amp;rft_id=http%3A%2F%2Fproceedings.mlr.press%2Fv9%2Fgutmann10a%2Fgutmann10a.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGenerative+adversarial+network"></span><link href="mw-data:TemplateStyles:r935243608" rel="mw-deduplicated-inline-style"/></span>
</li>
<li id="cite_note-olli2010-44"><span class="mw-cite-backlink"><b><a href="#cite_ref-olli2010_44-0">^</a></b></span> <span class="reference-text"><cite class="citation web">Niemitalo, Olli (February 24, 2010). <a class="external text" href="https://web.archive.org/web/20120312111546/http://yehar.com:80/blog/?p=167" rel="nofollow">"A method for training artificial neural networks to generate missing data within a variable context"</a>. <i>Internet Archive (Wayback Machine)</i>. Archived from <a class="external text" href="http://yehar.com:80/blog/?p=167" rel="nofollow">the original</a> on 2012-03-12<span class="reference-accessdate">. Retrieved <span class="nowrap">February 22,</span> 2019</span>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Internet+Archive+%28Wayback+Machine%29&amp;rft.atitle=A+method+for+training+artificial+neural+networks+to+generate+missing+data+within+a+variable+context&amp;rft.date=2010-02-24&amp;rft.aulast=Niemitalo&amp;rft.aufirst=Olli&amp;rft_id=http%3A%2F%2Fyehar.com%3A80%2Fblog%2F%3Fp%3D167&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGenerative+adversarial+network"></span><link href="mw-data:TemplateStyles:r935243608" rel="mw-deduplicated-inline-style"/></span>
</li>
<li id="cite_note-reddit3-45"><span class="mw-cite-backlink"><b><a href="#cite_ref-reddit3_45-0">^</a></b></span> <span class="reference-text"><cite class="citation web"><a class="external text" href="https://www.reddit.com/r/MachineLearning/comments/bnqm0p/d_gans_were_invented_in_2010/" rel="nofollow">"GANs were invented in 2010?"</a>. <i>reddit r/MachineLearning</i>. 2019<span class="reference-accessdate">. Retrieved <span class="nowrap">2019-05-28</span></span>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=reddit+r%2FMachineLearning&amp;rft.atitle=GANs+were+invented+in+2010%3F&amp;rft.date=2019&amp;rft_id=https%3A%2F%2Fwww.reddit.com%2Fr%2FMachineLearning%2Fcomments%2Fbnqm0p%2Fd_gans_were_invented_in_2010%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGenerative+adversarial+network"></span><link href="mw-data:TemplateStyles:r935243608" rel="mw-deduplicated-inline-style"/></span>
</li>
<li id="cite_note-Li-etal-GECCO2013-46"><span class="mw-cite-backlink"><b><a href="#cite_ref-Li-etal-GECCO2013_46-0">^</a></b></span> <span class="reference-text"><cite class="citation conference">Li, Wei; Gauci, Melvin; Gross, Roderich (July 6, 2013). "A Coevolutionary Approach to Learn Animal Behavior Through Controlled Interaction". <i>Proceedings of the 15th Annual Conference on Genetic and Evolutionary Computation (GECCO 2013)</i>. Amsterdam, The Netherlands: ACM. pp. 223–230. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a class="external text" href="https://doi.org/10.1145%2F2463372.2465801" rel="nofollow">10.1145/2463372.2465801</a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=conference&amp;rft.atitle=A+Coevolutionary+Approach+to+Learn+Animal+Behavior+Through+Controlled+Interaction&amp;rft.btitle=Proceedings+of+the+15th+Annual+Conference+on+Genetic+and+Evolutionary+Computation+%28GECCO+2013%29&amp;rft.place=Amsterdam%2C+The+Netherlands&amp;rft.pages=223-230&amp;rft.pub=ACM&amp;rft.date=2013-07-06&amp;rft_id=info%3Adoi%2F10.1145%2F2463372.2465801&amp;rft.aulast=Li&amp;rft.aufirst=Wei&amp;rft.au=Gauci%2C+Melvin&amp;rft.au=Gross%2C+Roderich&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGenerative+adversarial+network"></span><link href="mw-data:TemplateStyles:r935243608" rel="mw-deduplicated-inline-style"/></span>
</li>
<li id="cite_note-47"><span class="mw-cite-backlink"><b><a href="#cite_ref-47">^</a></b></span> <span class="reference-text"><cite class="citation journal">Abu-Khalaf, Murad; Lewis, Frank L.; Huang, Jie (July 1, 2008). "Neurodynamic Programming and Zero-Sum Games for Constrained Control Systems". <i>IEEE Transactions on Neural Networks</i>. <b>19</b> (7): 1243–1252. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a class="external text" href="https://doi.org/10.1109%2FTNN.2008.2000204" rel="nofollow">10.1109/TNN.2008.2000204</a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=IEEE+Transactions+on+Neural+Networks&amp;rft.atitle=Neurodynamic+Programming+and+Zero-Sum+Games+for+Constrained+Control+Systems&amp;rft.volume=19&amp;rft.issue=7&amp;rft.pages=1243-1252&amp;rft.date=2008-07-01&amp;rft_id=info%3Adoi%2F10.1109%2FTNN.2008.2000204&amp;rft.aulast=Abu-Khalaf&amp;rft.aufirst=Murad&amp;rft.au=Lewis%2C+Frank+L.&amp;rft.au=Huang%2C+Jie&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGenerative+adversarial+network"></span><link href="mw-data:TemplateStyles:r935243608" rel="mw-deduplicated-inline-style"/></span>
</li>
<li id="cite_note-48"><span class="mw-cite-backlink"><b><a href="#cite_ref-48">^</a></b></span> <span class="reference-text"><cite class="citation journal">Abu-Khalaf, Murad; Lewis, Frank L.; Huang, Jie (December 1, 2006). "Policy Iterations on the Hamilton–Jacobi–Isaacs Equation for State Feedback Control With Input Saturation". <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a class="external text" href="https://doi.org/10.1109%2FTAC.2006.884959" rel="nofollow">10.1109/TAC.2006.884959</a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.atitle=Policy+Iterations+on+the+Hamilton%E2%80%93Jacobi%E2%80%93Isaacs+Equation+for+State+Feedback+Control+With+Input+Saturation&amp;rft.date=2006-12-01&amp;rft_id=info%3Adoi%2F10.1109%2FTAC.2006.884959&amp;rft.aulast=Abu-Khalaf&amp;rft.aufirst=Murad&amp;rft.au=Lewis%2C+Frank+L.&amp;rft.au=Huang%2C+Jie&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGenerative+adversarial+network"></span> <span class="cs1-hidden-error error citation-comment">Cite journal requires <code class="cs1-code">|journal=</code> (<a href="/wiki/Help:CS1_errors#missing_periodical" title="Help:CS1 errors">help</a>)</span><link href="mw-data:TemplateStyles:r935243608" rel="mw-deduplicated-inline-style"/></span>
</li>
<li id="cite_note-49"><span class="mw-cite-backlink"><b><a href="#cite_ref-49">^</a></b></span> <span class="reference-text"><cite class="citation arxiv">Sajjadi, Mehdi S. M.; Schölkopf, Bernhard; Hirsch, Michael (2016-12-23). "EnhanceNet: Single Image Super-Resolution Through Automated Texture Synthesis". <a href="/wiki/ArXiv" title="ArXiv">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="//arxiv.org/abs/1612.07919" rel="nofollow">1612.07919</a></span> [<a class="external text" href="//arxiv.org/archive/cs.CV" rel="nofollow">cs.CV</a>].</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=EnhanceNet%3A+Single+Image+Super-Resolution+Through+Automated+Texture+Synthesis&amp;rft.date=2016-12-23&amp;rft_id=info%3Aarxiv%2F1612.07919&amp;rft.aulast=Sajjadi&amp;rft.aufirst=Mehdi+S.+M.&amp;rft.au=Sch%C3%B6lkopf%2C+Bernhard&amp;rft.au=Hirsch%2C+Michael&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGenerative+adversarial+network"></span><link href="mw-data:TemplateStyles:r935243608" rel="mw-deduplicated-inline-style"/></span>
</li>
<li id="cite_note-50"><span class="mw-cite-backlink"><b><a href="#cite_ref-50">^</a></b></span> <span class="reference-text"><cite class="citation web"><a class="external text" href="https://medium.com/@alagraphy/this-person-does-not-exist-neither-will-anything-if-artificial-intelligence-keeps-learning-1a9fcba728f" rel="nofollow">"This Person Does Not Exist: Neither Will Anything Eventually with AI"</a>. March 20, 2019.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=This+Person+Does+Not+Exist%3A+Neither+Will+Anything+Eventually+with+AI&amp;rft.date=2019-03-20&amp;rft_id=https%3A%2F%2Fmedium.com%2F%40alagraphy%2Fthis-person-does-not-exist-neither-will-anything-if-artificial-intelligence-keeps-learning-1a9fcba728f&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGenerative+adversarial+network"></span><link href="mw-data:TemplateStyles:r935243608" rel="mw-deduplicated-inline-style"/></span>
</li>
<li id="cite_note-51"><span class="mw-cite-backlink"><b><a href="#cite_ref-51">^</a></b></span> <span class="reference-text"><cite class="citation web"><a class="external text" href="https://www.issuewire.com/artificial-intelligence-enters-the-history-of-art-1620667772563815" rel="nofollow">"ARTificial Intelligence enters the History of Art"</a>. December 28, 2018.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=ARTificial+Intelligence+enters+the+History+of+Art&amp;rft.date=2018-12-28&amp;rft_id=https%3A%2F%2Fwww.issuewire.com%2Fartificial-intelligence-enters-the-history-of-art-1620667772563815&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGenerative+adversarial+network"></span><link href="mw-data:TemplateStyles:r935243608" rel="mw-deduplicated-inline-style"/></span>
</li>
<li id="cite_note-52"><span class="mw-cite-backlink"><b><a href="#cite_ref-52">^</a></b></span> <span class="reference-text"><cite class="citation web">Tom Février (2019-02-17). <a class="external text" href="https://link.medium.com/MYqBrGHIKV" rel="nofollow">"Le scandale de l'intelligence ARTificielle"</a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Le+scandale+de+l%27intelligence+ARTificielle&amp;rft.date=2019-02-17&amp;rft.au=Tom+F%C3%A9vrier&amp;rft_id=https%3A%2F%2Flink.medium.com%2FMYqBrGHIKV&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGenerative+adversarial+network"></span><link href="mw-data:TemplateStyles:r935243608" rel="mw-deduplicated-inline-style"/></span>
</li>
<li id="cite_note-53"><span class="mw-cite-backlink"><b><a href="#cite_ref-53">^</a></b></span> <span class="reference-text"><cite class="citation web"><a class="external text" href="https://github.com/NVlabs/stylegan" rel="nofollow">"StyleGAN: Official TensorFlow Implementation"</a>. March 2, 2019 – via GitHub.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=StyleGAN%3A+Official+TensorFlow+Implementation&amp;rft.date=2019-03-02&amp;rft_id=https%3A%2F%2Fgithub.com%2FNVlabs%2Fstylegan&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGenerative+adversarial+network"></span><link href="mw-data:TemplateStyles:r935243608" rel="mw-deduplicated-inline-style"/></span>
</li>
<li id="cite_note-TPDNEitboowo2019-54"><span class="mw-cite-backlink"><b><a href="#cite_ref-TPDNEitboowo2019_54-0">^</a></b></span> <span class="reference-text"><cite class="citation web">Paez, Danny (2019-02-13). <a class="external text" href="https://www.inverse.com/article/53280-this-person-does-not-exist-gans-website=website=Inverse" rel="nofollow">"This Person Does Not Exist Is the Best One-Off Website of 2019"</a><span class="reference-accessdate">. Retrieved <span class="nowrap">2019-02-16</span></span>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=This+Person+Does+Not+Exist+Is+the+Best+One-Off+Website+of+2019&amp;rft.date=2019-02-13&amp;rft.aulast=Paez&amp;rft.aufirst=Danny&amp;rft_id=https%3A%2F%2Fwww.inverse.com%2Farticle%2F53280-this-person-does-not-exist-gans-website%3Dwebsite%3DInverse&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGenerative+adversarial+network"></span><link href="mw-data:TemplateStyles:r935243608" rel="mw-deduplicated-inline-style"/></span>
</li>
<li id="cite_note-TPDNE-55"><span class="mw-cite-backlink"><b><a href="#cite_ref-TPDNE_55-0">^</a></b></span> <span class="reference-text"><cite class="citation web">BESCHIZZA, ROB (2019-02-15). <a class="external text" href="https://boingboing.net/2019/02/15/this-person-does-not-exist.html" rel="nofollow">"This Person Does Not Exist"</a>. <i>Boing-Boing</i><span class="reference-accessdate">. Retrieved <span class="nowrap">2019-02-16</span></span>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Boing-Boing&amp;rft.atitle=This+Person+Does+Not+Exist&amp;rft.date=2019-02-15&amp;rft.aulast=BESCHIZZA&amp;rft.aufirst=ROB&amp;rft_id=https%3A%2F%2Fboingboing.net%2F2019%2F02%2F15%2Fthis-person-does-not-exist.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGenerative+adversarial+network"></span><link href="mw-data:TemplateStyles:r935243608" rel="mw-deduplicated-inline-style"/></span>
</li>
<li id="cite_note-Style-based_GANs_–_Generating_and_Tuning_Realistic_Artificial_Faces-56"><span class="mw-cite-backlink"><b><a href="#cite_ref-Style-based_GANs_–_Generating_and_Tuning_Realistic_Artificial_Faces_56-0">^</a></b></span> <span class="reference-text"><cite class="citation web">Horev, Rani (2018-12-26). <a class="external text" href="https://www.lyrn.ai/2018/12/26/a-style-based-generator-architecture-for-generative-adversarial-networks/" rel="nofollow">"Style-based GANs – Generating and Tuning Realistic Artificial Faces"</a>. <i>Lyrn.AI</i><span class="reference-accessdate">. Retrieved <span class="nowrap">2019-02-16</span></span>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Lyrn.AI&amp;rft.atitle=Style-based+GANs+%E2%80%93+Generating+and+Tuning+Realistic+Artificial+Faces&amp;rft.date=2018-12-26&amp;rft.aulast=Horev&amp;rft.aufirst=Rani&amp;rft_id=https%3A%2F%2Fwww.lyrn.ai%2F2018%2F12%2F26%2Fa-style-based-generator-architecture-for-generative-adversarial-networks%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGenerative+adversarial+network"></span><link href="mw-data:TemplateStyles:r935243608" rel="mw-deduplicated-inline-style"/></span>
</li>
<li id="cite_note-57"><span class="mw-cite-backlink"><b><a href="#cite_ref-57">^</a></b></span> <span class="reference-text"><cite class="citation arxiv">Elgammal, Ahmed; Liu, Bingchen; Elhoseiny, Mohamed; Mazzone, Marian (2017). "CAN: Creative Adversarial Networks, Generating "Art" by Learning About Styles and Deviating from Style Norms". <a href="/wiki/ArXiv" title="ArXiv">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="//arxiv.org/abs/1706.07068" rel="nofollow">1706.07068</a></span> [<a class="external text" href="//arxiv.org/archive/cs.AI" rel="nofollow">cs.AI</a>].</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=CAN%3A+Creative+Adversarial+Networks%2C+Generating+%22Art%22+by+Learning+About+Styles+and+Deviating+from+Style+Norms&amp;rft.date=2017&amp;rft_id=info%3Aarxiv%2F1706.07068&amp;rft.aulast=Elgammal&amp;rft.aufirst=Ahmed&amp;rft.au=Liu%2C+Bingchen&amp;rft.au=Elhoseiny%2C+Mohamed&amp;rft.au=Mazzone%2C+Marian&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGenerative+adversarial+network"></span><link href="mw-data:TemplateStyles:r935243608" rel="mw-deduplicated-inline-style"/></span>
</li>
<li id="cite_note-58"><span class="mw-cite-backlink"><b><a href="#cite_ref-58">^</a></b></span> <span class="reference-text"><cite class="citation news">Cohn, Gabe (2018-10-25). <a class="external text" href="https://www.nytimes.com/2018/10/25/arts/design/ai-art-sold-christies.html" rel="nofollow">"AI Art at Christie's Sells for $432,500"</a>. <i>The New York Times</i>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=The+New+York+Times&amp;rft.atitle=AI+Art+at+Christie%27s+Sells+for+%24432%2C500&amp;rft.date=2018-10-25&amp;rft.aulast=Cohn&amp;rft.aufirst=Gabe&amp;rft_id=https%3A%2F%2Fwww.nytimes.com%2F2018%2F10%2F25%2Farts%2Fdesign%2Fai-art-sold-christies.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGenerative+adversarial+network"></span><link href="mw-data:TemplateStyles:r935243608" rel="mw-deduplicated-inline-style"/></span>
</li>
<li id="cite_note-59"><span class="mw-cite-backlink"><b><a href="#cite_ref-59">^</a></b></span> <span class="reference-text"><cite class="citation journal">Mazzone, Marian; Ahmed Elgammal (21 February 2019). "Art, Creativity, and the Potential of Artificial Intelligence". <i>Arts</i>. <b>8</b>: 26. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a class="external text" href="https://doi.org/10.3390%2Farts8010026" rel="nofollow">10.3390/arts8010026</a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Arts&amp;rft.atitle=Art%2C+Creativity%2C+and+the+Potential+of+Artificial+Intelligence&amp;rft.volume=8&amp;rft.pages=26&amp;rft.date=2019-02-21&amp;rft_id=info%3Adoi%2F10.3390%2Farts8010026&amp;rft.au=Mazzone%2C+Marian&amp;rft.au=Ahmed+Elgammal&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGenerative+adversarial+network"></span><link href="mw-data:TemplateStyles:r935243608" rel="mw-deduplicated-inline-style"/></span>
</li>
<li id="cite_note-60"><span class="mw-cite-backlink"><b><a href="#cite_ref-60">^</a></b></span> <span class="reference-text"><cite class="citation magazine">Kulp, Patrick (May 23, 2019). <a class="external text" href="https://www.adweek.com/digital/samsungs-ai-lab-can-create-fake-video-footage-from-a-single-headshot/" rel="nofollow">"Samsung's AI Lab Can Create Fake Video Footage From a Single Headshot"</a>. <i>AdWeek</i>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=AdWeek&amp;rft.atitle=Samsung%27s+AI+Lab+Can+Create+Fake+Video+Footage+From+a+Single+Headshot&amp;rft.date=2019-05-23&amp;rft.aulast=Kulp&amp;rft.aufirst=Patrick&amp;rft_id=https%3A%2F%2Fwww.adweek.com%2Fdigital%2Fsamsungs-ai-lab-can-create-fake-video-footage-from-a-single-headshot%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGenerative+adversarial+network"></span><link href="mw-data:TemplateStyles:r935243608" rel="mw-deduplicated-inline-style"/></span>
</li>
<li id="cite_note-61"><span class="mw-cite-backlink"><b><a href="#cite_ref-61">^</a></b></span> <span class="reference-text"><cite class="citation arxiv">Yu, Yi; Canales, Simon (August 15, 2019). "Conditional LSTM-GAN for Melody Generation from Lyrics". <a href="/wiki/ArXiv" title="ArXiv">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="//arxiv.org/abs/1908.05551" rel="nofollow">1908.05551</a></span> [<a class="external text" href="//arxiv.org/archive/cs.AI" rel="nofollow">cs.AI</a>].</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=Conditional+LSTM-GAN+for+Melody+Generation+from+Lyrics&amp;rft.date=2019-08-15&amp;rft_id=info%3Aarxiv%2F1908.05551&amp;rft.aulast=Yu&amp;rft.aufirst=Yi&amp;rft.au=Canales%2C+Simon&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGenerative+adversarial+network"></span><link href="mw-data:TemplateStyles:r935243608" rel="mw-deduplicated-inline-style"/></span>
</li>
<li id="cite_note-62"><span class="mw-cite-backlink"><b><a href="#cite_ref-62">^</a></b></span> <span class="reference-text"><cite class="citation web">Zhirui Zhang; Shujie Liu; Mu Li; Ming Zhou; Enhong Chen (October 2018). <a class="external text" href="https://www.aclweb.org/anthology/K18-1019.pdf" rel="nofollow">"Bidirectional Generative Adversarial Networks for Neural Machine Translation"</a> <span class="cs1-format">(PDF)</span>. pp. 190–199.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Bidirectional+Generative+Adversarial+Networks+for+Neural+Machine+Translation&amp;rft.pages=190-199&amp;rft.date=2018-10&amp;rft.au=Zhirui+Zhang&amp;rft.au=Shujie+Liu&amp;rft.au=Mu+Li&amp;rft.au=Ming+Zhou&amp;rft.au=Enhong+Chen&amp;rft_id=https%3A%2F%2Fwww.aclweb.org%2Fanthology%2FK18-1019.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGenerative+adversarial+network"></span><link href="mw-data:TemplateStyles:r935243608" rel="mw-deduplicated-inline-style"/></span>
</li>
</ol></div>
<h2><span class="mw-headline" id="External_links">External links</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Generative_adversarial_network&amp;action=edit&amp;section=12" title="Edit section: External links">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<style data-mw-deduplicate="TemplateStyles:r936637989">.mw-parser-output .portal{border:solid #aaa 1px;padding:0}.mw-parser-output .portal.tleft{margin:0.5em 1em 0.5em 0}.mw-parser-output .portal.tright{margin:0.5em 0 0.5em 1em}.mw-parser-output .portal>ul{display:table;box-sizing:border-box;padding:0.1em;max-width:175px;background:#f9f9f9;font-size:85%;line-height:110%;font-style:italic;font-weight:bold}.mw-parser-output .portal>ul>li{display:table-row}.mw-parser-output .portal>ul>li>span:first-child{display:table-cell;padding:0.2em;vertical-align:middle;text-align:center}.mw-parser-output .portal>ul>li>span:last-child{display:table-cell;padding:0.2em 0.2em 0.2em 0.3em;vertical-align:middle}</style><div aria-label="Portals" class="noprint portal plainlist tright" role="navigation"><ul>
<li><span><a class="image" href="/wiki/File:Ballerina-icon.jpg"><img alt="icon" class="noviewer" data-file-height="367" data-file-width="306" decoding="async" height="28" src="//upload.wikimedia.org/wikipedia/commons/thumb/3/3a/Ballerina-icon.jpg/23px-Ballerina-icon.jpg" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/3/3a/Ballerina-icon.jpg/35px-Ballerina-icon.jpg 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/3/3a/Ballerina-icon.jpg/47px-Ballerina-icon.jpg 2x" width="23"/></a></span><span><a class="mw-redirect" href="/wiki/Portal:Art" title="Portal:Art">Art portal</a></span></li></ul></div>
<ul><li><cite class="citation news">Knight, Will. <a class="external text" href="https://www.technologyreview.com/s/603216/5-big-predictions-for-artificial-intelligence-in-2017/" rel="nofollow">"5 Big Predictions for Artificial Intelligence in 2017"</a>. <i>MIT Technology Review</i><span class="reference-accessdate">. Retrieved <span class="nowrap">2017-01-05</span></span>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=MIT+Technology+Review&amp;rft.atitle=5+Big+Predictions+for+Artificial+Intelligence+in+2017&amp;rft.aulast=Knight&amp;rft.aufirst=Will&amp;rft_id=https%3A%2F%2Fwww.technologyreview.com%2Fs%2F603216%2F5-big-predictions-for-artificial-intelligence-in-2017%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGenerative+adversarial+network"></span><link href="mw-data:TemplateStyles:r935243608" rel="mw-deduplicated-inline-style"/></li>
<li><a class="external text" href="https://arxiv.org/abs/1812.04948" rel="nofollow">A Style-Based Generator Architecture for Generative Adversarial Networks</a></li>
<li><a class="external text" href="https://www.thispersondoesnotexist.com/" rel="nofollow">This Person Does Not Exist</a> –  photorealistic images of people who do not exist, generated by <a href="/wiki/StyleGAN" title="StyleGAN">StyleGAN</a></li>
<li><a class="external text" href="https://arxiv.org/abs/1906.01529" rel="nofollow">"Generative Adversarial Networks: A Survey and Taxonomy", recent review by Zhengwei Wang, Qi She, Tomas E. Ward</a></li></ul>
<!-- 
NewPP limit report
Parsed by mw1287
Cached time: 20200407190515
Cache expiry: 2592000
Dynamic content: false
Complications: [vary‐revision‐sha1]
CPU time usage: 0.728 seconds
Real time usage: 0.878 seconds
Preprocessor visited node count: 3291/1000000
Post‐expand include size: 147230/2097152 bytes
Template argument size: 2306/2097152 bytes
Highest expansion depth: 12/40
Expensive parser function count: 8/500
Unstrip recursion depth: 1/20
Unstrip post‐expand size: 205766/5000000 bytes
Number of Wikibase entities loaded: 4/400
Lua time usage: 0.444/10.000 seconds
Lua memory usage: 6.97 MB/50 MB
-->
<!--
Transclusion expansion time report (%,ms,calls,template)
100.00%  787.799      1 -total
 70.27%  553.613      1 Template:Reflist
 21.29%  167.696     20 Template:Cite_journal
 12.09%   95.268     22 Template:Cite_web
 11.33%   89.277      2 Template:Cite_conference
  7.56%   59.532      5 Template:Cite_arXiv
  6.07%   47.834      2 Template:Citation_needed
  5.50%   43.291      1 Template:Distinguish
  5.20%   40.985      2 Template:Fix
  4.72%   37.167      1 Template:Machine_learning_bar
-->
<!-- Saved in parser cache with key enwiki:pcache:idhash:50073184-0!canonical and timestamp 20200407190514 and revision id 949655233
 -->
</div><noscript><img alt="" height="1" src="//en.wikipedia.org/wiki/Special:CentralAutoLogin/start?type=1x1" style="border: none; position: absolute;" title="" width="1"/></noscript></div>
<div class="printfooter">Retrieved from "<a dir="ltr" href="https://en.wikipedia.org/w/index.php?title=Generative_adversarial_network&amp;oldid=949655233">https://en.wikipedia.org/w/index.php?title=Generative_adversarial_network&amp;oldid=949655233</a>"</div>
<div class="catlinks" data-mw="interface" id="catlinks"><div class="mw-normal-catlinks" id="mw-normal-catlinks"><a href="/wiki/Help:Category" title="Help:Category">Categories</a>: <ul><li><a href="/wiki/Category:Artificial_neural_networks" title="Category:Artificial neural networks">Artificial neural networks</a></li><li><a href="/wiki/Category:Cognitive_science" title="Category:Cognitive science">Cognitive science</a></li><li><a href="/wiki/Category:Unsupervised_learning" title="Category:Unsupervised learning">Unsupervised learning</a></li></ul></div><div class="mw-hidden-catlinks mw-hidden-cats-hidden" id="mw-hidden-catlinks">Hidden categories: <ul><li><a href="/wiki/Category:CS1_errors:_missing_periodical" title="Category:CS1 errors: missing periodical">CS1 errors: missing periodical</a></li><li><a href="/wiki/Category:Articles_with_short_description" title="Category:Articles with short description">Articles with short description</a></li><li><a href="/wiki/Category:All_articles_with_unsourced_statements" title="Category:All articles with unsourced statements">All articles with unsourced statements</a></li><li><a href="/wiki/Category:Articles_with_unsourced_statements_from_January_2020" title="Category:Articles with unsourced statements from January 2020">Articles with unsourced statements from January 2020</a></li><li><a href="/wiki/Category:Articles_with_unsourced_statements_from_February_2018" title="Category:Articles with unsourced statements from February 2018">Articles with unsourced statements from February 2018</a></li><li><a href="/wiki/Category:Portal_templates_with_redlinked_portals" title="Category:Portal templates with redlinked portals">Portal templates with redlinked portals</a></li></ul></div></div>
<div class="visualClear"></div>
</div>
</div>
<div id="mw-data-after-content">
<div class="read-more-container"></div>
</div>
<div id="mw-navigation">
<h2>Navigation menu</h2>
<div id="mw-head">
<div aria-labelledby="p-personal-label" class="" id="p-personal" role="navigation">
<h3 id="p-personal-label">Personal tools</h3>
<ul>
<li id="pt-anonuserpage">Not logged in</li>
<li id="pt-anontalk"><a accesskey="n" href="/wiki/Special:MyTalk" title="Discussion about edits from this IP address [n]">Talk</a></li><li id="pt-anoncontribs"><a accesskey="y" href="/wiki/Special:MyContributions" title="A list of edits made from this IP address [y]">Contributions</a></li><li id="pt-createaccount"><a href="/w/index.php?title=Special:CreateAccount&amp;returnto=Generative+adversarial+network" title="You are encouraged to create an account and log in; however, it is not mandatory">Create account</a></li><li id="pt-login"><a accesskey="o" href="/w/index.php?title=Special:UserLogin&amp;returnto=Generative+adversarial+network" title="You're encouraged to log in; however, it's not mandatory. [o]">Log in</a></li>
</ul>
</div>
<div id="left-navigation">
<div aria-labelledby="p-namespaces-label" class="vectorTabs" id="p-namespaces" role="navigation">
<h3 id="p-namespaces-label">Namespaces</h3>
<ul>
<li class="selected" id="ca-nstab-main"><a accesskey="c" href="/wiki/Generative_adversarial_network" title="View the content page [c]">Article</a></li><li id="ca-talk"><a accesskey="t" href="/wiki/Talk:Generative_adversarial_network" rel="discussion" title="Discussion about the content page [t]">Talk</a></li>
</ul>
</div>
<div aria-labelledby="p-variants-label" class="vectorMenu emptyPortlet" id="p-variants" role="navigation">
<input aria-labelledby="p-variants-label" class="vectorMenuCheckbox" type="checkbox"/>
<h3 id="p-variants-label">
<span>Variants</span>
</h3>
<ul class="menu">
</ul>
</div>
</div>
<div id="right-navigation">
<div aria-labelledby="p-views-label" class="vectorTabs" id="p-views" role="navigation">
<h3 id="p-views-label">Views</h3>
<ul>
<li class="collapsible selected" id="ca-view"><a href="/wiki/Generative_adversarial_network">Read</a></li><li class="collapsible" id="ca-edit"><a accesskey="e" href="/w/index.php?title=Generative_adversarial_network&amp;action=edit" title="Edit this page [e]">Edit</a></li><li class="collapsible" id="ca-history"><a accesskey="h" href="/w/index.php?title=Generative_adversarial_network&amp;action=history" title="Past revisions of this page [h]">View history</a></li>
</ul>
</div>
<div aria-labelledby="p-cactions-label" class="vectorMenu emptyPortlet" id="p-cactions" role="navigation">
<input aria-labelledby="p-cactions-label" class="vectorMenuCheckbox" type="checkbox"/>
<h3 id="p-cactions-label">
<span>More</span>
</h3>
<ul class="menu">
</ul>
</div>
<div id="p-search" role="search">
<h3>
<label for="searchInput">Search</label>
</h3>
<form action="/w/index.php" id="searchform">
<div id="simpleSearch">
<input accesskey="f" id="searchInput" name="search" placeholder="Search Wikipedia" title="Search Wikipedia [f]" type="search"/>
<input name="title" type="hidden" value="Special:Search"/>
<input class="searchButton mw-fallbackSearchButton" id="mw-searchButton" name="fulltext" title="Search Wikipedia for this text" type="submit" value="Search"/>
<input class="searchButton" id="searchButton" name="go" title="Go to a page with this exact name if it exists" type="submit" value="Go"/>
</div>
</form>
</div>
</div>
</div>
<div id="mw-panel">
<div id="p-logo" role="banner">
<a class="mw-wiki-logo" href="/wiki/Main_Page" title="Visit the main page"></a>
</div>
<div aria-labelledby="p-navigation-label" class="portal" id="p-navigation" role="navigation">
<h3 id="p-navigation-label">
    			Navigation
    		</h3>
<div class="body">
<ul><li id="n-mainpage-description"><a accesskey="z" href="/wiki/Main_Page" title="Visit the main page [z]">Main page</a></li><li id="n-contents"><a href="/wiki/Wikipedia:Contents" title="Guides to browsing Wikipedia">Contents</a></li><li id="n-featuredcontent"><a href="/wiki/Wikipedia:Featured_content" title="Featured content – the best of Wikipedia">Featured content</a></li><li id="n-currentevents"><a href="/wiki/Portal:Current_events" title="Find background information on current events">Current events</a></li><li id="n-randompage"><a accesskey="x" href="/wiki/Special:Random" title="Load a random article [x]">Random article</a></li><li id="n-sitesupport"><a href="https://donate.wikimedia.org/wiki/Special:FundraiserRedirector?utm_source=donate&amp;utm_medium=sidebar&amp;utm_campaign=C13_en.wikipedia.org&amp;uselang=en" title="Support us">Donate to Wikipedia</a></li><li id="n-shoplink"><a href="//shop.wikimedia.org" title="Visit the Wikipedia store">Wikipedia store</a></li></ul>
</div>
</div>
<div aria-labelledby="p-interaction-label" class="portal" id="p-interaction" role="navigation">
<h3 id="p-interaction-label">
    			Interaction
    		</h3>
<div class="body">
<ul><li id="n-help"><a href="/wiki/Help:Contents" title="Guidance on how to use and edit Wikipedia">Help</a></li><li id="n-aboutsite"><a href="/wiki/Wikipedia:About" title="Find out about Wikipedia">About Wikipedia</a></li><li id="n-portal"><a href="/wiki/Wikipedia:Community_portal" title="About the project, what you can do, where to find things">Community portal</a></li><li id="n-recentchanges"><a accesskey="r" href="/wiki/Special:RecentChanges" title="A list of recent changes in the wiki [r]">Recent changes</a></li><li id="n-contactpage"><a href="//en.wikipedia.org/wiki/Wikipedia:Contact_us" title="How to contact Wikipedia">Contact page</a></li></ul>
</div>
</div>
<div aria-labelledby="p-tb-label" class="portal" id="p-tb" role="navigation">
<h3 id="p-tb-label">
    			Tools
    		</h3>
<div class="body">
<ul><li id="t-whatlinkshere"><a accesskey="j" href="/wiki/Special:WhatLinksHere/Generative_adversarial_network" title="List of all English Wikipedia pages containing links to this page [j]">What links here</a></li><li id="t-recentchangeslinked"><a accesskey="k" href="/wiki/Special:RecentChangesLinked/Generative_adversarial_network" rel="nofollow" title="Recent changes in pages linked from this page [k]">Related changes</a></li><li id="t-upload"><a accesskey="u" href="/wiki/Wikipedia:File_Upload_Wizard" title="Upload files [u]">Upload file</a></li><li id="t-specialpages"><a accesskey="q" href="/wiki/Special:SpecialPages" title="A list of all special pages [q]">Special pages</a></li><li id="t-permalink"><a href="/w/index.php?title=Generative_adversarial_network&amp;oldid=949655233" title="Permanent link to this revision of the page">Permanent link</a></li><li id="t-info"><a href="/w/index.php?title=Generative_adversarial_network&amp;action=info" title="More information about this page">Page information</a></li><li id="t-wikibase"><a accesskey="g" href="https://www.wikidata.org/wiki/Special:EntityPage/Q25104379" title="Link to connected data repository item [g]">Wikidata item</a></li><li id="t-cite"><a href="/w/index.php?title=Special:CiteThisPage&amp;page=Generative_adversarial_network&amp;id=949655233&amp;wpFormIdentifier=titleform" title="Information on how to cite this page">Cite this page</a></li></ul>
</div>
</div>
<div aria-labelledby="p-wikibase-otherprojects-label" class="portal" id="p-wikibase-otherprojects" role="navigation">
<h3 id="p-wikibase-otherprojects-label">
    			In other projects
    		</h3>
<div class="body">
<ul><li class="wb-otherproject-link wb-otherproject-commons"><a href="https://commons.wikimedia.org/wiki/Category:Generative_adversarial_network" hreflang="en">Wikimedia Commons</a></li></ul>
</div>
</div>
<div aria-labelledby="p-coll-print_export-label" class="portal" id="p-coll-print_export" role="navigation">
<h3 id="p-coll-print_export-label">
    			Print/export
    		</h3>
<div class="body">
<ul><li id="coll-create_a_book"><a href="/w/index.php?title=Special:Book&amp;bookcmd=book_creator&amp;referer=Generative+adversarial+network">Create a book</a></li><li id="coll-download-as-rl"><a href="/w/index.php?title=Special:ElectronPdf&amp;page=Generative+adversarial+network&amp;action=show-download-screen">Download as PDF</a></li><li id="t-print"><a accesskey="p" href="/w/index.php?title=Generative_adversarial_network&amp;printable=yes" title="Printable version of this page [p]">Printable version</a></li></ul>
</div>
</div>
<div aria-labelledby="p-lang-label" class="portal" id="p-lang" role="navigation">
<h3 id="p-lang-label">
    			Languages
    		</h3>
<div class="body">
<ul><li class="interlanguage-link interwiki-de"><a class="interlanguage-link-target" href="https://de.wikipedia.org/wiki/Generative_Adversarial_Networks" hreflang="de" lang="de" title="Generative Adversarial Networks – German">Deutsch</a></li><li class="interlanguage-link interwiki-el"><a class="interlanguage-link-target" href="https://el.wikipedia.org/wiki/%CE%A0%CE%B1%CF%81%CE%B1%CE%B3%CF%89%CE%B3%CE%B9%CE%BA%CF%8C_%CE%B1%CE%BD%CF%84%CE%B9%CF%80%CE%B1%CF%81%CE%B1%CE%B8%CE%B5%CF%84%CE%B9%CE%BA%CF%8C_%CE%B4%CE%AF%CE%BA%CF%84%CF%85%CE%BF" hreflang="el" lang="el" title="Παραγωγικό αντιπαραθετικό δίκτυο – Greek">Ελληνικά</a></li><li class="interlanguage-link interwiki-es"><a class="interlanguage-link-target" href="https://es.wikipedia.org/wiki/Red_generativa_antag%C3%B3nica" hreflang="es" lang="es" title="Red generativa antagónica – Spanish">Español</a></li><li class="interlanguage-link interwiki-fr"><a class="interlanguage-link-target" href="https://fr.wikipedia.org/wiki/R%C3%A9seaux_antagonistes_g%C3%A9n%C3%A9ratifs" hreflang="fr" lang="fr" title="Réseaux antagonistes génératifs – French">Français</a></li><li class="interlanguage-link interwiki-ko"><a class="interlanguage-link-target" href="https://ko.wikipedia.org/wiki/%EC%83%9D%EC%84%B1%EC%A0%81_%EC%A0%81%EB%8C%80_%EC%8B%A0%EA%B2%BD%EB%A7%9D" hreflang="ko" lang="ko" title="생성적 적대 신경망 – Korean">한국어</a></li><li class="interlanguage-link interwiki-it"><a class="interlanguage-link-target" href="https://it.wikipedia.org/wiki/Rete_generativa_avversaria" hreflang="it" lang="it" title="Rete generativa avversaria – Italian">Italiano</a></li><li class="interlanguage-link interwiki-ja"><a class="interlanguage-link-target" href="https://ja.wikipedia.org/wiki/%E6%95%B5%E5%AF%BE%E7%9A%84%E7%94%9F%E6%88%90%E3%83%8D%E3%83%83%E3%83%88%E3%83%AF%E3%83%BC%E3%82%AF" hreflang="ja" lang="ja" title="敵対的生成ネットワーク – Japanese">日本語</a></li><li class="interlanguage-link interwiki-ru"><a class="interlanguage-link-target" href="https://ru.wikipedia.org/wiki/%D0%93%D0%B5%D0%BD%D0%B5%D1%80%D0%B0%D1%82%D0%B8%D0%B2%D0%BD%D0%BE-%D1%81%D0%BE%D1%81%D1%82%D1%8F%D0%B7%D0%B0%D1%82%D0%B5%D0%BB%D1%8C%D0%BD%D0%B0%D1%8F_%D1%81%D0%B5%D1%82%D1%8C" hreflang="ru" lang="ru" title="Генеративно-состязательная сеть – Russian">Русский</a></li><li class="interlanguage-link interwiki-simple"><a class="interlanguage-link-target" href="https://simple.wikipedia.org/wiki/Generative_adversarial_networks" hreflang="en-simple" lang="en-simple" title="Generative adversarial networks – Simple English">Simple English</a></li><li class="interlanguage-link interwiki-fi"><a class="interlanguage-link-target" href="https://fi.wikipedia.org/wiki/Generatiivinen_kilpaileva_verkosto" hreflang="fi" lang="fi" title="Generatiivinen kilpaileva verkosto – Finnish">Suomi</a></li><li class="interlanguage-link interwiki-uk"><a class="interlanguage-link-target" href="https://uk.wikipedia.org/wiki/%D0%93%D0%B5%D0%BD%D0%B5%D1%80%D0%B0%D1%82%D0%B8%D0%B2%D0%BD%D0%B0_%D0%B7%D0%BC%D0%B0%D0%B3%D0%B0%D0%BB%D1%8C%D0%BD%D0%B0_%D0%BC%D0%B5%D1%80%D0%B5%D0%B6%D0%B0" hreflang="uk" lang="uk" title="Генеративна змагальна мережа – Ukrainian">Українська</a></li><li class="interlanguage-link interwiki-zh"><a class="interlanguage-link-target" href="https://zh.wikipedia.org/wiki/%E7%94%9F%E6%88%90%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C" hreflang="zh" lang="zh" title="生成对抗网络 – Chinese">中文</a></li></ul>
<div class="after-portlet after-portlet-lang"><span class="wb-langlinks-edit wb-langlinks-link"><a class="wbc-editpage" href="https://www.wikidata.org/wiki/Special:EntityPage/Q25104379#sitelinks-wikipedia" title="Edit interlanguage links">Edit links</a></span></div>
</div>
</div>
</div>
</div>
<div id="footer" role="contentinfo">
<ul class="" id="footer-info">
<li id="footer-info-lastmod"> This page was last edited on 7 April 2020, at 19:05<span class="anonymous-show"> (UTC)</span>.</li>
<li id="footer-info-copyright">Text is available under the <a href="//en.wikipedia.org/wiki/Wikipedia:Text_of_Creative_Commons_Attribution-ShareAlike_3.0_Unported_License" rel="license">Creative Commons Attribution-ShareAlike License</a><a href="//creativecommons.org/licenses/by-sa/3.0/" rel="license" style="display:none;"></a>;
additional terms may apply.  By using this site, you agree to the <a href="//foundation.wikimedia.org/wiki/Terms_of_Use">Terms of Use</a> and <a href="//foundation.wikimedia.org/wiki/Privacy_policy">Privacy Policy</a>. Wikipedia® is a registered trademark of the <a href="//www.wikimediafoundation.org/">Wikimedia Foundation, Inc.</a>, a non-profit organization.</li>
</ul>
<ul class="" id="footer-places">
<li id="footer-places-privacy"><a class="extiw" href="https://foundation.wikimedia.org/wiki/Privacy_policy" title="wmf:Privacy policy">Privacy policy</a></li>
<li id="footer-places-about"><a href="/wiki/Wikipedia:About" title="Wikipedia:About">About Wikipedia</a></li>
<li id="footer-places-disclaimer"><a href="/wiki/Wikipedia:General_disclaimer" title="Wikipedia:General disclaimer">Disclaimers</a></li>
<li id="footer-places-contact"><a href="//en.wikipedia.org/wiki/Wikipedia:Contact_us">Contact Wikipedia</a></li>
<li id="footer-places-developers"><a href="https://www.mediawiki.org/wiki/Special:MyLanguage/How_to_contribute">Developers</a></li>
<li id="footer-places-statslink"><a href="https://stats.wikimedia.org/#/en.wikipedia.org">Statistics</a></li>
<li id="footer-places-cookiestatement"><a href="https://foundation.wikimedia.org/wiki/Cookie_statement">Cookie statement</a></li>
<li id="footer-places-mobileview"><a class="noprint stopMobileRedirectToggle" href="//en.m.wikipedia.org/w/index.php?title=Generative_adversarial_network&amp;mobileaction=toggle_view_mobile">Mobile view</a></li>
</ul>
<ul class="noprint" id="footer-icons">
<li id="footer-copyrightico"><a href="https://wikimediafoundation.org/"><img alt="Wikimedia Foundation" height="31" src="/static/images/wikimedia-button.png" srcset="/static/images/wikimedia-button-1.5x.png 1.5x, /static/images/wikimedia-button-2x.png 2x" width="88"/></a></li>
<li id="footer-poweredbyico"><a href="https://www.mediawiki.org/"><img alt="Powered by MediaWiki" height="31" src="/static/images/poweredby_mediawiki_88x31.png" srcset="/static/images/poweredby_mediawiki_132x47.png 1.5x, /static/images/poweredby_mediawiki_176x62.png 2x" width="88"/></a></li>
</ul>
<div style="clear: both;"></div>
</div>
<script>(RLQ=window.RLQ||[]).push(function(){mw.config.set({"wgPageParseReport":{"limitreport":{"cputime":"0.728","walltime":"0.878","ppvisitednodes":{"value":3291,"limit":1000000},"postexpandincludesize":{"value":147230,"limit":2097152},"templateargumentsize":{"value":2306,"limit":2097152},"expansiondepth":{"value":12,"limit":40},"expensivefunctioncount":{"value":8,"limit":500},"unstrip-depth":{"value":1,"limit":20},"unstrip-size":{"value":205766,"limit":5000000},"entityaccesscount":{"value":4,"limit":400},"timingprofile":["100.00%  787.799      1 -total"," 70.27%  553.613      1 Template:Reflist"," 21.29%  167.696     20 Template:Cite_journal"," 12.09%   95.268     22 Template:Cite_web"," 11.33%   89.277      2 Template:Cite_conference","  7.56%   59.532      5 Template:Cite_arXiv","  6.07%   47.834      2 Template:Citation_needed","  5.50%   43.291      1 Template:Distinguish","  5.20%   40.985      2 Template:Fix","  4.72%   37.167      1 Template:Machine_learning_bar"]},"scribunto":{"limitreport-timeusage":{"value":"0.444","limit":"10.000"},"limitreport-memusage":{"value":7305964,"limit":52428800}},"cachereport":{"origin":"mw1287","timestamp":"20200407190515","ttl":2592000,"transientcontent":false}}});});</script>
<script type="application/ld+json">{"@context":"https:\/\/schema.org","@type":"Article","name":"Generative adversarial network","url":"https:\/\/en.wikipedia.org\/wiki\/Generative_adversarial_network","sameAs":"http:\/\/www.wikidata.org\/entity\/Q25104379","mainEntity":"http:\/\/www.wikidata.org\/entity\/Q25104379","author":{"@type":"Organization","name":"Contributors to Wikimedia projects"},"publisher":{"@type":"Organization","name":"Wikimedia Foundation, Inc.","logo":{"@type":"ImageObject","url":"https:\/\/www.wikimedia.org\/static\/images\/wmf-hor-googpub.png"}},"datePublished":"2016-04-07T13:45:58Z","dateModified":"2020-04-07T19:05:10Z","image":"https:\/\/upload.wikimedia.org\/wikipedia\/commons\/f\/fe\/Kernel_Machine.svg","headline":"deep learning method"}</script>
<script>(RLQ=window.RLQ||[]).push(function(){mw.config.set({"wgBackendResponseTime":153,"wgHostname":"mw1261"});});</script></body></html>
