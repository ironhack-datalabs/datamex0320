<!DOCTYPE html>
<html class="client-nojs" dir="ltr" lang="en">
<head>
<meta charset="utf-8"/>
<title>Supervised learning - Wikipedia</title>
<script>document.documentElement.className="client-js";RLCONF={"wgBreakFrames":!1,"wgSeparatorTransformTable":["",""],"wgDigitTransformTable":["",""],"wgDefaultDateFormat":"dmy","wgMonthNames":["","January","February","March","April","May","June","July","August","September","October","November","December"],"wgRequestId":"Xo4uNgpAMNIAA4EoR-cAAAEM","wgCSPNonce":!1,"wgCanonicalNamespace":"","wgCanonicalSpecialPageName":!1,"wgNamespaceNumber":0,"wgPageName":"Supervised_learning","wgTitle":"Supervised learning","wgCurRevisionId":949790121,"wgRevisionId":949790121,"wgArticleId":20926,"wgIsArticle":!0,"wgIsRedirect":!1,"wgAction":"view","wgUserName":null,"wgUserGroups":["*"],"wgCategories":["Articles with short description","Articles with long short description","Supervised learning"],"wgPageContentLanguage":"en","wgPageContentModel":"wikitext","wgRelevantPageName":"Supervised_learning","wgRelevantArticleId":20926,"wgIsProbablyEditable":!0,"wgRelevantPageIsProbablyEditable":!0,
"wgRestrictionEdit":[],"wgRestrictionMove":[],"wgMediaViewerOnClick":!0,"wgMediaViewerEnabledByDefault":!0,"wgPopupsReferencePreviews":!1,"wgPopupsConflictsWithNavPopupGadget":!1,"wgVisualEditor":{"pageLanguageCode":"en","pageLanguageDir":"ltr","pageVariantFallbacks":"en"},"wgMFDisplayWikibaseDescriptions":{"search":!0,"nearby":!0,"watchlist":!0,"tagline":!1},"wgWMESchemaEditAttemptStepOversample":!1,"wgULSCurrentAutonym":"English","wgNoticeProject":"wikipedia","wgWikibaseItemId":"Q334384","wgCentralAuthMobileDomain":!1,"wgEditSubmitButtonLabelPublish":!0};RLSTATE={"ext.globalCssJs.user.styles":"ready","site.styles":"ready","noscript":"ready","user.styles":"ready","ext.globalCssJs.user":"ready","user":"ready","user.options":"loading","ext.cite.styles":"ready","ext.math.styles":"ready","mediawiki.toc.styles":"ready","skins.vector.styles.legacy":"ready","wikibase.client.init":"ready","ext.visualEditor.desktopArticleTarget.noscript":"ready",
"ext.uls.interlanguage":"ready","ext.wikimediaBadges":"ready"};RLPAGEMODULES=["ext.cite.ux-enhancements","ext.math.scripts","site","mediawiki.page.startup","skins.vector.js","mediawiki.page.ready","mediawiki.toc","ext.gadget.ReferenceTooltips","ext.gadget.charinsert","ext.gadget.refToolbar","ext.gadget.extra-toolbar-buttons","ext.gadget.switcher","ext.centralauth.centralautologin","mmv.head","mmv.bootstrap.autostart","ext.popups","ext.visualEditor.desktopArticleTarget.init","ext.visualEditor.targetLoader","ext.eventLogging","ext.wikimediaEvents","ext.navigationTiming","ext.uls.compactlinks","ext.uls.interface","ext.cx.eventlogging.campaigns","ext.quicksurveys.init","ext.centralNotice.geoIP","ext.centralNotice.startUp"];</script>
<script>(RLQ=window.RLQ||[]).push(function(){mw.loader.implement("user.options@1hzgi",function($,jQuery,require,module){/*@nomin*/mw.user.tokens.set({"patrolToken":"+\\","watchToken":"+\\","csrfToken":"+\\"});
});});</script>
<link href="/w/load.php?lang=en&amp;modules=ext.cite.styles%7Cext.math.styles%7Cext.uls.interlanguage%7Cext.visualEditor.desktopArticleTarget.noscript%7Cext.wikimediaBadges%7Cmediawiki.toc.styles%7Cskins.vector.styles.legacy%7Cwikibase.client.init&amp;only=styles&amp;skin=vector" rel="stylesheet"/>
<script async="" src="/w/load.php?lang=en&amp;modules=startup&amp;only=scripts&amp;raw=1&amp;skin=vector"></script>
<meta content="" name="ResourceLoaderDynamicStyles"/>
<link href="/w/load.php?lang=en&amp;modules=site.styles&amp;only=styles&amp;skin=vector" rel="stylesheet"/>
<meta content="MediaWiki 1.35.0-wmf.26" name="generator"/>
<meta content="origin" name="referrer"/>
<meta content="origin-when-crossorigin" name="referrer"/>
<meta content="origin-when-cross-origin" name="referrer"/>
<meta content="https://upload.wikimedia.org/wikipedia/commons/thumb/f/fe/Kernel_Machine.svg/1200px-Kernel_Machine.svg.png" property="og:image"/>
<link href="/w/index.php?title=Supervised_learning&amp;action=edit" rel="alternate" title="Edit this page" type="application/x-wiki"/>
<link href="/w/index.php?title=Supervised_learning&amp;action=edit" rel="edit" title="Edit this page"/>
<link href="/static/apple-touch/wikipedia.png" rel="apple-touch-icon"/>
<link href="/static/favicon/wikipedia.ico" rel="shortcut icon"/>
<link href="/w/opensearch_desc.php" rel="search" title="Wikipedia (en)" type="application/opensearchdescription+xml"/>
<link href="//en.wikipedia.org/w/api.php?action=rsd" rel="EditURI" type="application/rsd+xml"/>
<link href="//creativecommons.org/licenses/by-sa/3.0/" rel="license"/>
<link href="/w/index.php?title=Special:RecentChanges&amp;feed=atom" rel="alternate" title="Wikipedia Atom feed" type="application/atom+xml"/>
<link href="https://en.wikipedia.org/wiki/Supervised_learning" rel="canonical"/>
<link href="//login.wikimedia.org" rel="dns-prefetch"/>
<link href="//meta.wikimedia.org" rel="dns-prefetch"/>
<!--[if lt IE 9]><script src="/w/resources/lib/html5shiv/html5shiv.js"></script><![endif]-->
</head>
<body class="mediawiki ltr sitedir-ltr mw-hide-empty-elt ns-0 ns-subject mw-editable page-Supervised_learning rootpage-Supervised_learning skin-vector action-view">
<div class="noprint" id="mw-page-base"></div>
<div class="noprint" id="mw-head-base"></div>
<div class="mw-body" id="content" role="main">
<a id="top"></a>
<div class="mw-body-content" id="siteNotice"><!-- CentralNotice --></div>
<div class="mw-indicators mw-body-content">
</div>
<h1 class="firstHeading" id="firstHeading" lang="en">Supervised learning</h1>
<div class="mw-body-content" id="bodyContent">
<div class="noprint" id="siteSub">From Wikipedia, the free encyclopedia</div>
<div id="contentSub"></div>
<div id="jump-to-nav"></div>
<a class="mw-jump-link" href="#mw-head">Jump to navigation</a>
<a class="mw-jump-link" href="#p-search">Jump to search</a>
<div class="mw-content-ltr" dir="ltr" id="mw-content-text" lang="en"><div class="mw-parser-output"><div class="shortdescription nomobile noexcerpt noprint searchaux" style="display:none">Machine learning task of learning a function that maps an input to an output based on example input-output pairs</div>
<div class="hatnote navigation-not-searchable" role="note">See also: <a href="/wiki/Unsupervised_learning" title="Unsupervised learning">Unsupervised learning</a></div>
<table class="vertical-navbox nowraplinks" style="float:right;clear:right;width:22.0em;margin:0 0 1.0em 1.0em;background:#f9f9f9;border:1px solid #aaa;padding:0.2em;border-spacing:0.4em 0;text-align:center;line-height:1.4em;font-size:88%"><tbody><tr><th style="padding:0.2em 0.4em 0.2em;font-size:145%;line-height:1.2em"><a href="/wiki/Machine_learning" title="Machine learning">Machine learning</a> and<br/><a href="/wiki/Data_mining" title="Data mining">data mining</a></th></tr><tr><td style="padding:0.2em 0 0.4em;padding:0.25em 0.25em 0.75em;"><a class="image" href="/wiki/File:Kernel_Machine.svg"><img alt="Kernel Machine.svg" data-file-height="233" data-file-width="512" decoding="async" height="100" src="//upload.wikimedia.org/wikipedia/commons/thumb/f/fe/Kernel_Machine.svg/220px-Kernel_Machine.svg.png" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/f/fe/Kernel_Machine.svg/330px-Kernel_Machine.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/f/fe/Kernel_Machine.svg/440px-Kernel_Machine.svg.png 2x" width="220"/></a></td></tr><tr><td style="padding:0 0.1em 0.4em">
<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left">Problems</div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">
<ul><li><a href="/wiki/Statistical_classification" title="Statistical classification">Classification</a></li>
<li><a href="/wiki/Cluster_analysis" title="Cluster analysis">Clustering</a></li>
<li><a href="/wiki/Regression_analysis" title="Regression analysis">Regression</a></li>
<li><a href="/wiki/Anomaly_detection" title="Anomaly detection">Anomaly detection</a></li>
<li><a href="/wiki/Automated_machine_learning" title="Automated machine learning">AutoML</a></li>
<li><a href="/wiki/Association_rule_learning" title="Association rule learning">Association rules</a></li>
<li><a href="/wiki/Reinforcement_learning" title="Reinforcement learning">Reinforcement learning</a></li>
<li><a href="/wiki/Structured_prediction" title="Structured prediction">Structured prediction</a></li>
<li><a href="/wiki/Feature_engineering" title="Feature engineering">Feature engineering</a></li>
<li><a href="/wiki/Feature_learning" title="Feature learning">Feature learning</a></li>
<li><a href="/wiki/Online_machine_learning" title="Online machine learning">Online learning</a></li>
<li><a href="/wiki/Semi-supervised_learning" title="Semi-supervised learning">Semi-supervised learning</a></li>
<li><a href="/wiki/Unsupervised_learning" title="Unsupervised learning">Unsupervised learning</a></li>
<li><a href="/wiki/Learning_to_rank" title="Learning to rank">Learning to rank</a></li>
<li><a href="/wiki/Grammar_induction" title="Grammar induction">Grammar induction</a></li></ul>
</div></div></div></td>
</tr><tr><td style="padding:0 0.1em 0.4em">
<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><div style="padding:0.1em 0;line-height:1.2em;"><a class="mw-selflink selflink">Supervised learning</a><br/><style data-mw-deduplicate="TemplateStyles:r886047488">.mw-parser-output .nobold{font-weight:normal}</style><span class="nobold"><span style="font-size:85%;">(<b><a href="/wiki/Statistical_classification" title="Statistical classification">classification</a></b> • <b><a href="/wiki/Regression_analysis" title="Regression analysis">regression</a></b>)</span></span> </div></div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">
<ul><li><a href="/wiki/Decision_tree_learning" title="Decision tree learning">Decision trees</a></li>
<li><a href="/wiki/Ensemble_learning" title="Ensemble learning">Ensembles</a>
<ul><li><a href="/wiki/Bootstrap_aggregating" title="Bootstrap aggregating">Bagging</a></li>
<li><a href="/wiki/Boosting_(machine_learning)" title="Boosting (machine learning)">Boosting</a></li>
<li><a href="/wiki/Random_forest" title="Random forest">Random forest</a></li></ul></li>
<li><a href="/wiki/K-nearest_neighbors_algorithm" title="K-nearest neighbors algorithm"><i>k</i>-NN</a></li>
<li><a href="/wiki/Linear_regression" title="Linear regression">Linear regression</a></li>
<li><a href="/wiki/Naive_Bayes_classifier" title="Naive Bayes classifier">Naive Bayes</a></li>
<li><a href="/wiki/Artificial_neural_network" title="Artificial neural network">Artificial neural networks</a></li>
<li><a href="/wiki/Logistic_regression" title="Logistic regression">Logistic regression</a></li>
<li><a href="/wiki/Perceptron" title="Perceptron">Perceptron</a></li>
<li><a href="/wiki/Relevance_vector_machine" title="Relevance vector machine">Relevance vector machine (RVM)</a></li>
<li><a href="/wiki/Support-vector_machine" title="Support-vector machine">Support vector machine (SVM)</a></li></ul>
</div></div></div></td>
</tr><tr><td style="padding:0 0.1em 0.4em">
<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><a href="/wiki/Cluster_analysis" title="Cluster analysis">Clustering</a></div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">
<ul><li><a href="/wiki/BIRCH" title="BIRCH">BIRCH</a></li>
<li><a class="mw-redirect" href="/wiki/CURE_data_clustering_algorithm" title="CURE data clustering algorithm">CURE</a></li>
<li><a href="/wiki/Hierarchical_clustering" title="Hierarchical clustering">Hierarchical</a></li>
<li><a href="/wiki/K-means_clustering" title="K-means clustering"><i>k</i>-means</a></li>
<li><a href="/wiki/Expectation%E2%80%93maximization_algorithm" title="Expectation–maximization algorithm">Expectation–maximization (EM)</a></li>
<li><br/><a href="/wiki/DBSCAN" title="DBSCAN">DBSCAN</a></li>
<li><a href="/wiki/OPTICS_algorithm" title="OPTICS algorithm">OPTICS</a></li>
<li><a class="mw-redirect" href="/wiki/Mean-shift" title="Mean-shift">Mean-shift</a></li></ul>
</div></div></div></td>
</tr><tr><td style="padding:0 0.1em 0.4em">
<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><a href="/wiki/Dimensionality_reduction" title="Dimensionality reduction">Dimensionality reduction</a></div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">
<ul><li><a href="/wiki/Factor_analysis" title="Factor analysis">Factor analysis</a></li>
<li><a href="/wiki/Canonical_correlation" title="Canonical correlation">CCA</a></li>
<li><a href="/wiki/Independent_component_analysis" title="Independent component analysis">ICA</a></li>
<li><a href="/wiki/Linear_discriminant_analysis" title="Linear discriminant analysis">LDA</a></li>
<li><a href="/wiki/Non-negative_matrix_factorization" title="Non-negative matrix factorization">NMF</a></li>
<li><a href="/wiki/Principal_component_analysis" title="Principal component analysis">PCA</a></li>
<li><a href="/wiki/Proper_generalized_decomposition" title="Proper generalized decomposition">PGD</a></li>
<li><a href="/wiki/T-distributed_stochastic_neighbor_embedding" title="T-distributed stochastic neighbor embedding">t-SNE</a></li></ul>
</div></div></div></td>
</tr><tr><td style="padding:0 0.1em 0.4em">
<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><a href="/wiki/Structured_prediction" title="Structured prediction">Structured prediction</a></div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">
<ul><li><a href="/wiki/Graphical_model" title="Graphical model">Graphical models</a>
<ul><li><a href="/wiki/Bayesian_network" title="Bayesian network">Bayes net</a></li>
<li><a href="/wiki/Conditional_random_field" title="Conditional random field">Conditional random field</a></li>
<li><a href="/wiki/Hidden_Markov_model" title="Hidden Markov model">Hidden Markov</a></li></ul></li></ul>
</div></div></div></td>
</tr><tr><td style="padding:0 0.1em 0.4em">
<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><a href="/wiki/Anomaly_detection" title="Anomaly detection">Anomaly detection</a></div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">
<ul><li><a class="mw-redirect" href="/wiki/K-nearest_neighbors_classification" title="K-nearest neighbors classification"><i>k</i>-NN</a></li>
<li><a href="/wiki/Local_outlier_factor" title="Local outlier factor">Local outlier factor</a></li></ul>
</div></div></div></td>
</tr><tr><td style="padding:0 0.1em 0.4em">
<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><a href="/wiki/Artificial_neural_network" title="Artificial neural network">Artificial neural network</a></div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">
<ul><li><a href="/wiki/Autoencoder" title="Autoencoder">Autoencoder</a></li>
<li><a href="/wiki/Deep_learning" title="Deep learning">Deep learning</a></li>
<li><a href="/wiki/DeepDream" title="DeepDream">DeepDream</a></li>
<li><a href="/wiki/Multilayer_perceptron" title="Multilayer perceptron">Multilayer perceptron</a></li>
<li><a href="/wiki/Recurrent_neural_network" title="Recurrent neural network">RNN</a>
<ul><li><a href="/wiki/Long_short-term_memory" title="Long short-term memory">LSTM</a></li>
<li><a href="/wiki/Gated_recurrent_unit" title="Gated recurrent unit">GRU</a></li></ul></li>
<li><a href="/wiki/Restricted_Boltzmann_machine" title="Restricted Boltzmann machine">Restricted Boltzmann machine</a></li>
<li><a href="/wiki/Generative_adversarial_network" title="Generative adversarial network">GAN</a></li>
<li><a href="/wiki/Self-organizing_map" title="Self-organizing map">SOM</a></li>
<li><a href="/wiki/Convolutional_neural_network" title="Convolutional neural network">Convolutional neural network</a>
<ul><li><a href="/wiki/U-Net" title="U-Net">U-Net</a></li></ul></li></ul>
</div></div></div></td>
</tr><tr><td style="padding:0 0.1em 0.4em">
<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><a href="/wiki/Reinforcement_learning" title="Reinforcement learning">Reinforcement learning</a></div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">
<ul><li><a href="/wiki/Q-learning" title="Q-learning">Q-learning</a></li>
<li><a href="/wiki/State%E2%80%93action%E2%80%93reward%E2%80%93state%E2%80%93action" title="State–action–reward–state–action">SARSA</a></li>
<li><a href="/wiki/Temporal_difference_learning" title="Temporal difference learning">Temporal difference (TD)</a></li></ul>
</div></div></div></td>
</tr><tr><td style="padding:0 0.1em 0.4em">
<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left">Theory</div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">
<ul><li><a class="mw-redirect" href="/wiki/Bias%E2%80%93variance_dilemma" title="Bias–variance dilemma">Bias–variance dilemma</a></li>
<li><a href="/wiki/Computational_learning_theory" title="Computational learning theory">Computational learning theory</a></li>
<li><a href="/wiki/Empirical_risk_minimization" title="Empirical risk minimization">Empirical risk minimization</a></li>
<li><a href="/wiki/Occam_learning" title="Occam learning">Occam learning</a></li>
<li><a href="/wiki/Probably_approximately_correct_learning" title="Probably approximately correct learning">PAC learning</a></li>
<li><a href="/wiki/Statistical_learning_theory" title="Statistical learning theory">Statistical learning</a></li>
<li><a href="/wiki/Vapnik%E2%80%93Chervonenkis_theory" title="Vapnik–Chervonenkis theory">VC theory</a></li></ul>
</div></div></div></td>
</tr><tr><td style="padding:0 0.1em 0.4em">
<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left">Machine-learning venues</div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">
<ul><li><a href="/wiki/Conference_on_Neural_Information_Processing_Systems" title="Conference on Neural Information Processing Systems">NeurIPS</a></li>
<li><a href="/wiki/International_Conference_on_Machine_Learning" title="International Conference on Machine Learning">ICML</a></li>
<li><a href="/wiki/Machine_Learning_(journal)" title="Machine Learning (journal)">ML</a></li>
<li><a href="/wiki/Journal_of_Machine_Learning_Research" title="Journal of Machine Learning Research">JMLR</a></li>
<li><a class="external text" href="https://arxiv.org/list/cs.LG/recent" rel="nofollow">ArXiv:cs.LG</a></li></ul>
</div></div></div></td>
</tr><tr><td style="padding:0 0.1em 0.4em">
<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><a href="/wiki/Glossary_of_artificial_intelligence" title="Glossary of artificial intelligence">Glossary of artificial intelligence</a></div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">
<ul><li><a href="/wiki/Glossary_of_artificial_intelligence" title="Glossary of artificial intelligence">Glossary of artificial intelligence</a></li></ul>
</div></div></div></td>
</tr><tr><td style="padding:0 0.1em 0.4em">
<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left">Related articles</div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">
<ul><li><a href="/wiki/List_of_datasets_for_machine-learning_research" title="List of datasets for machine-learning research">List of datasets for machine-learning research</a></li>
<li><a href="/wiki/Outline_of_machine_learning" title="Outline of machine learning">Outline of machine learning</a></li></ul>
</div></div></div></td>
</tr><tr><td style="text-align:right;font-size:115%;padding-top: 0.6em;"><div class="plainlinks hlist navbar mini"><ul><li class="nv-view"><a href="/wiki/Template:Machine_learning_bar" title="Template:Machine learning bar"><abbr title="View this template">v</abbr></a></li><li class="nv-talk"><a href="/wiki/Template_talk:Machine_learning_bar" title="Template talk:Machine learning bar"><abbr title="Discuss this template">t</abbr></a></li><li class="nv-edit"><a class="external text" href="https://en.wikipedia.org/w/index.php?title=Template:Machine_learning_bar&amp;action=edit"><abbr title="Edit this template">e</abbr></a></li></ul></div></td></tr></tbody></table>
<p><b>Supervised learning</b> is the <a href="/wiki/Machine_learning" title="Machine learning">machine learning</a> task of learning a function that maps an input to an output based on example input-output pairs.<sup class="reference" id="cite_ref-1"><a href="#cite_note-1">[1]</a></sup> It infers a function from <i><span id="LABELLED_DATA"></span><span id="labeled_[[training_set|training_data]]">labeled <a class="mw-redirect" href="/wiki/Training_set" title="Training set">training data</a></span></i> consisting of a set of <i>training examples</i>.<sup class="reference" id="cite_ref-2"><a href="#cite_note-2">[2]</a></sup>  In supervised learning, each example is a <i>pair</i> consisting of an input object (typically a vector) and a desired output value (also called the <i>supervisory signal</i>).  A supervised learning algorithm analyzes the training data and produces an inferred function, which can be used for mapping new examples. An optimal scenario will allow for the algorithm to correctly determine the class labels for unseen instances. This requires the learning algorithm to generalize from the training data to unseen situations in a "reasonable" way (see <a href="/wiki/Inductive_bias" title="Inductive bias">inductive bias</a>).
</p><p>The parallel task in human and animal psychology is often referred to as <a href="/wiki/Concept_learning" title="Concept learning">concept learning</a>.
</p>
<div aria-labelledby="mw-toc-heading" class="toc" id="toc" role="navigation"><input class="toctogglecheckbox" id="toctogglecheckbox" role="button" style="display:none" type="checkbox"/><div class="toctitle" dir="ltr" lang="en"><h2 id="mw-toc-heading">Contents</h2><span class="toctogglespan"><label class="toctogglelabel" for="toctogglecheckbox"></label></span></div>
<ul>
<li class="toclevel-1 tocsection-1"><a href="#Steps"><span class="tocnumber">1</span> <span class="toctext">Steps</span></a></li>
<li class="toclevel-1 tocsection-2"><a href="#Algorithm_choice"><span class="tocnumber">2</span> <span class="toctext">Algorithm choice</span></a>
<ul>
<li class="toclevel-2 tocsection-3"><a href="#Bias-variance_tradeoff"><span class="tocnumber">2.1</span> <span class="toctext">Bias-variance tradeoff</span></a></li>
<li class="toclevel-2 tocsection-4"><a href="#Function_complexity_and_amount_of_training_data"><span class="tocnumber">2.2</span> <span class="toctext">Function complexity and amount of training data</span></a></li>
<li class="toclevel-2 tocsection-5"><a href="#Dimensionality_of_the_input_space"><span class="tocnumber">2.3</span> <span class="toctext">Dimensionality of the input space</span></a></li>
<li class="toclevel-2 tocsection-6"><a href="#Noise_in_the_output_values"><span class="tocnumber">2.4</span> <span class="toctext">Noise in the output values</span></a></li>
<li class="toclevel-2 tocsection-7"><a href="#Other_factors_to_consider_(important)"><span class="tocnumber">2.5</span> <span class="toctext">Other factors to consider (important)</span></a></li>
<li class="toclevel-2 tocsection-8"><a href="#Algorithms"><span class="tocnumber">2.6</span> <span class="toctext">Algorithms</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-9"><a href="#How_supervised_learning_algorithms_work"><span class="tocnumber">3</span> <span class="toctext">How supervised learning algorithms work</span></a>
<ul>
<li class="toclevel-2 tocsection-10"><a href="#Empirical_risk_minimization"><span class="tocnumber">3.1</span> <span class="toctext">Empirical risk minimization</span></a></li>
<li class="toclevel-2 tocsection-11"><a href="#Structural_risk_minimization"><span class="tocnumber">3.2</span> <span class="toctext">Structural risk minimization</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-12"><a href="#Generative_training"><span class="tocnumber">4</span> <span class="toctext">Generative training</span></a></li>
<li class="toclevel-1 tocsection-13"><a href="#Generalizations"><span class="tocnumber">5</span> <span class="toctext">Generalizations</span></a></li>
<li class="toclevel-1 tocsection-14"><a href="#Approaches_and_algorithms"><span class="tocnumber">6</span> <span class="toctext">Approaches and algorithms</span></a></li>
<li class="toclevel-1 tocsection-15"><a href="#Applications"><span class="tocnumber">7</span> <span class="toctext">Applications</span></a></li>
<li class="toclevel-1 tocsection-16"><a href="#General_issues"><span class="tocnumber">8</span> <span class="toctext">General issues</span></a></li>
<li class="toclevel-1 tocsection-17"><a href="#See_also"><span class="tocnumber">9</span> <span class="toctext">See also</span></a></li>
<li class="toclevel-1 tocsection-18"><a href="#References"><span class="tocnumber">10</span> <span class="toctext">References</span></a></li>
<li class="toclevel-1 tocsection-19"><a href="#External_links"><span class="tocnumber">11</span> <span class="toctext">External links</span></a></li>
</ul>
</div>
<h2><span class="mw-headline" id="Steps">Steps</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Supervised_learning&amp;action=edit&amp;section=1" title="Edit section: Steps">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>In order to solve a given problem of supervised learning, one has to perform the following steps:
</p>
<ol><li>Determine the type of training examples. Before doing anything else, the user should decide what kind of data is to be used as a training set. In the case of <a class="mw-redirect" href="/wiki/Handwriting_analysis" title="Handwriting analysis">handwriting analysis</a>, for example, this might be a single handwritten character, an entire handwritten word, or an entire line of handwriting.</li>
<li>Gather a training set. The training set needs to be representative of the real-world use of the function. Thus, a set of input objects is gathered and corresponding outputs are also gathered, either from human experts or from measurements.</li>
<li>Determine the input feature representation of the learned function. The accuracy of the learned function depends strongly on how the input object is represented. Typically, the input object is transformed into a <a class="mw-redirect" href="/wiki/Feature_vector" title="Feature vector">feature vector</a>, which contains a number of features that are descriptive of the object. The number of features should not be too large, because of the <a href="/wiki/Curse_of_dimensionality" title="Curse of dimensionality">curse of dimensionality</a>; but should contain enough information to accurately predict the output.</li>
<li>Determine the structure of the learned function and corresponding learning algorithm. For example, the engineer may choose to use <a class="mw-redirect" href="/wiki/Support_vector_machine" title="Support vector machine">support vector machines</a> or <a href="/wiki/Decision_tree_learning" title="Decision tree learning">decision trees</a>.</li>
<li>Complete the design. Run the learning algorithm on the gathered training set. Some supervised learning algorithms require the user to determine certain control parameters. These parameters may be adjusted by optimizing performance on a subset (called a <i>validation</i> set) of the training set, or via <a href="/wiki/Cross-validation_(statistics)" title="Cross-validation (statistics)">cross-validation</a>.</li>
<li>Evaluate the accuracy of the learned function. After parameter adjustment and learning, the performance of the resulting function should be measured on a test set that is separate from the training set.Training data already trained.</li></ol>
<h2><span class="mw-headline" id="Algorithm_choice">Algorithm choice</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Supervised_learning&amp;action=edit&amp;section=2" title="Edit section: Algorithm choice">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>A wide range of supervised learning algorithms are available, each with its strengths and weaknesses. There is no single learning algorithm that works best on all supervised learning problems (see the <a href="/wiki/No_free_lunch_in_search_and_optimization" title="No free lunch in search and optimization">No free lunch theorem</a>).
</p><p>There are four major issues to consider in supervised learning:
</p>
<h3><span class="mw-headline" id="Bias-variance_tradeoff">Bias-variance tradeoff</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Supervised_learning&amp;action=edit&amp;section=3" title="Edit section: Bias-variance tradeoff">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<div class="hatnote navigation-not-searchable" role="note">Main article: <a class="mw-redirect" href="/wiki/Bias-variance_dilemma" title="Bias-variance dilemma">Bias-variance dilemma</a></div>
<p>A first issue is the tradeoff between <i>bias</i> and <i>variance</i>.<sup class="reference" id="cite_ref-3"><a href="#cite_note-3">[3]</a></sup>  Imagine that we have available several different, but equally good, training data sets.  A learning algorithm is biased for a particular input <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle x}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>x</mi>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle x}</annotation>
</semantics>
</math></span><img alt="x" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/87f9e315fd7e2ba406057a97300593c4802b53e4" style="vertical-align: -0.338ex; width:1.33ex; height:1.676ex;"/></span> if, when trained on each of these data sets, it is systematically incorrect when predicting the correct output for <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle x}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>x</mi>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle x}</annotation>
</semantics>
</math></span><img alt="x" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/87f9e315fd7e2ba406057a97300593c4802b53e4" style="vertical-align: -0.338ex; width:1.33ex; height:1.676ex;"/></span>.  A learning algorithm has high variance for a particular input <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle x}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>x</mi>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle x}</annotation>
</semantics>
</math></span><img alt="x" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/87f9e315fd7e2ba406057a97300593c4802b53e4" style="vertical-align: -0.338ex; width:1.33ex; height:1.676ex;"/></span> if it predicts different output values when trained on different training sets.  The prediction error of a learned classifier is related to the sum of the bias and the variance of the learning algorithm.<sup class="reference" id="cite_ref-4"><a href="#cite_note-4">[4]</a></sup>  Generally, there is a tradeoff between bias and variance.  A learning algorithm with low bias must be "flexible" so that it can fit the data well.  But if the learning algorithm is too flexible, it will fit each training data set differently, and hence have high variance.  A key aspect of many supervised learning methods is that they are able to adjust this tradeoff between bias and variance (either automatically or by providing a bias/variance parameter that the user can adjust).
</p>
<h3><span class="mw-headline" id="Function_complexity_and_amount_of_training_data">Function complexity and amount of training data</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Supervised_learning&amp;action=edit&amp;section=4" title="Edit section: Function complexity and amount of training data">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>The second issue is the amount of training data available relative to the complexity of the "true" function (classifier or regression function).  If the true function is simple, then an "inflexible" learning algorithm with high bias and low variance will be able to learn it from a small amount of data.  But if the true function is highly complex (e.g., because it involves complex interactions among many different input features and behaves differently in different parts of the input space), then the function will only be able to learn from a very large amount of training data and using a "flexible" learning algorithm with low bias and high variance.
</p>
<h3><span class="mw-headline" id="Dimensionality_of_the_input_space">Dimensionality of the input space</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Supervised_learning&amp;action=edit&amp;section=5" title="Edit section: Dimensionality of the input space">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>A third issue is the dimensionality of the input space.  If the input feature vectors have very high dimension, the learning problem can be difficult even if the true function only depends on a small number of those features.  This is because the many "extra" dimensions can confuse the learning algorithm and cause it to have high variance.  Hence, high input dimensional typically requires tuning the classifier to have low variance and high bias.  In practice, if the engineer can manually remove irrelevant features from the input data, this is likely to improve the accuracy of the learned function.  In addition, there are many algorithms for <a href="/wiki/Feature_selection" title="Feature selection">feature selection</a> that seek to identify the relevant features and discard the irrelevant ones.  This is an instance of the more general strategy of <a href="/wiki/Dimensionality_reduction" title="Dimensionality reduction">dimensionality reduction</a>, which seeks to map the input data into a lower-dimensional space prior to running the supervised learning algorithm.
</p>
<h3><span class="mw-headline" id="Noise_in_the_output_values">Noise in the output values</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Supervised_learning&amp;action=edit&amp;section=6" title="Edit section: Noise in the output values">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>A fourth issue is the degree of noise in the desired output values (the supervisory <a class="mw-redirect" href="/wiki/Target_variable" title="Target variable">target variables</a>).  If the desired output values are often incorrect (because of human error or sensor errors), then the learning algorithm should not attempt to find a function that exactly matches the training examples.  Attempting to fit the data too carefully leads to <a href="/wiki/Overfitting" title="Overfitting">overfitting</a>.  You can overfit even when there are no measurement errors (stochastic noise) if the function you are trying to learn is too complex for your learning model. In such a situation, the part of the target function that cannot be modeled "corrupts" your training data - this phenomenon has been called <a href="/wiki/Deterministic_noise" title="Deterministic noise">deterministic noise</a>. When either type of noise is present, it is better to go with a higher bias, lower variance estimator.
</p><p>In practice, there are several approaches to alleviate noise in the output values such as <a href="/wiki/Early_stopping" title="Early stopping">early stopping</a> to prevent <a href="/wiki/Overfitting" title="Overfitting">overfitting</a> as well as <a href="/wiki/Anomaly_detection" title="Anomaly detection">detecting</a> and removing the noisy training examples prior to training the supervised learning algorithm.  There are several algorithms that identify noisy training examples and removing the suspected noisy training examples prior to training has decreased <a href="/wiki/Generalization_error" title="Generalization error">generalization error</a> with <a href="/wiki/Statistical_significance" title="Statistical significance">statistical significance</a>.<sup class="reference" id="cite_ref-5"><a href="#cite_note-5">[5]</a></sup><sup class="reference" id="cite_ref-6"><a href="#cite_note-6">[6]</a></sup>
</p>
<h3><span id="Other_factors_to_consider_.28important.29"></span><span class="mw-headline" id="Other_factors_to_consider_(important)">Other factors to consider (important)</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Supervised_learning&amp;action=edit&amp;section=7" title="Edit section: Other factors to consider (important)">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>Other factors to consider when choosing and applying a learning algorithm include the following:
</p>
<ul><li>Heterogeneity of the data.  If the feature vectors include features of many different kinds (discrete, discrete ordered, counts, continuous values), some algorithms are easier to apply than others.  Many algorithms, including <a class="mw-redirect" href="/wiki/Support_Vector_Machines" title="Support Vector Machines">Support Vector Machines</a>, <a href="/wiki/Linear_regression" title="Linear regression">linear regression</a>, <a href="/wiki/Logistic_regression" title="Logistic regression">logistic regression</a>, <a href="/wiki/Artificial_neural_network" title="Artificial neural network">neural networks</a>, and <a class="mw-redirect" href="/wiki/K-nearest_neighbor_algorithm" title="K-nearest neighbor algorithm">nearest neighbor methods</a>, require that the input features be numerical and scaled to similar ranges (e.g., to the [-1,1] interval).  Methods that employ a distance function, such as <a class="mw-redirect" href="/wiki/K-nearest_neighbor_algorithm" title="K-nearest neighbor algorithm">nearest neighbor methods</a> and <a class="mw-redirect" href="/wiki/Support_Vector_Machines" title="Support Vector Machines">support vector machines with Gaussian kernels</a>, are particularly sensitive to this. An advantage of <a href="/wiki/Decision_tree_learning" title="Decision tree learning">decision trees</a> is that they easily handle heterogeneous data.</li>
<li>Redundancy in the data.  If the input features contain redundant information (e.g., highly correlated features), some learning algorithms (e.g., <a href="/wiki/Linear_regression" title="Linear regression">linear regression</a>, <a href="/wiki/Logistic_regression" title="Logistic regression">logistic regression</a>, and <a class="mw-redirect" href="/wiki/K-nearest_neighbor_algorithm" title="K-nearest neighbor algorithm">distance based methods</a>) will perform poorly because of numerical instabilities.  These problems can often be solved by imposing some form of <a href="/wiki/Regularization_(mathematics)" title="Regularization (mathematics)">regularization</a>.</li>
<li>Presence of interactions and non-linearities.  If each of the features makes an independent contribution to the output, then algorithms based on linear functions (e.g., <a href="/wiki/Linear_regression" title="Linear regression">linear regression</a>, <a href="/wiki/Logistic_regression" title="Logistic regression">logistic regression</a>, <a class="mw-redirect" href="/wiki/Support_Vector_Machines" title="Support Vector Machines">Support Vector Machines</a>, <a href="/wiki/Naive_Bayes_classifier" title="Naive Bayes classifier">naive Bayes</a>) and distance functions (e.g., <a class="mw-redirect" href="/wiki/K-nearest_neighbor_algorithm" title="K-nearest neighbor algorithm">nearest neighbor methods</a>, <a class="mw-redirect" href="/wiki/Support_Vector_Machines" title="Support Vector Machines">support vector machines with Gaussian kernels</a>) generally perform well.  However, if there are complex interactions among features, then algorithms such as <a href="/wiki/Decision_tree_learning" title="Decision tree learning">decision trees</a> and <a href="/wiki/Artificial_neural_network" title="Artificial neural network">neural networks</a> work better, because they are specifically designed to discover these interactions.  Linear methods can also be applied, but the engineer must manually specify the interactions when using them.</li></ul>
<p>When considering a new application, the engineer can compare multiple learning algorithms and experimentally determine which one works best on the problem at hand (see <a href="/wiki/Cross-validation_(statistics)" title="Cross-validation (statistics)">cross validation</a>).  Tuning the performance of a learning algorithm can be very time-consuming.  Given fixed resources, it is often better to spend more time collecting additional training data and more informative features than it is to spend extra time tuning the learning algorithms.
</p>
<h3><span class="mw-headline" id="Algorithms">Algorithms</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Supervised_learning&amp;action=edit&amp;section=8" title="Edit section: Algorithms">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>The most widely used learning algorithms are: 
</p>
<ul><li><a class="mw-redirect" href="/wiki/Support_Vector_Machines" title="Support Vector Machines">Support Vector Machines</a></li>
<li><a href="/wiki/Linear_regression" title="Linear regression">linear regression</a></li>
<li><a href="/wiki/Logistic_regression" title="Logistic regression">logistic regression</a></li>
<li><a href="/wiki/Naive_Bayes_classifier" title="Naive Bayes classifier">naive Bayes</a></li>
<li><a href="/wiki/Linear_discriminant_analysis" title="Linear discriminant analysis">linear discriminant analysis</a></li>
<li><a href="/wiki/Decision_tree_learning" title="Decision tree learning">decision trees</a></li>
<li><a class="mw-redirect" href="/wiki/K-nearest_neighbor_algorithm" title="K-nearest neighbor algorithm">k-nearest neighbor algorithm</a></li>
<li><a href="/wiki/Artificial_neural_network" title="Artificial neural network">Neural Networks</a> (<a href="/wiki/Multilayer_perceptron" title="Multilayer perceptron">Multilayer perceptron</a>)</li>
<li><a href="/wiki/Similarity_learning" title="Similarity learning">Similarity learning</a></li></ul>
<h2><span class="mw-headline" id="How_supervised_learning_algorithms_work">How supervised learning algorithms work</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Supervised_learning&amp;action=edit&amp;section=9" title="Edit section: How supervised learning algorithms work">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>Given a set of <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle N}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>N</mi>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle N}</annotation>
</semantics>
</math></span><img alt="N" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/f5e3890c981ae85503089652feb48b191b57aae3" style="vertical-align: -0.338ex; width:2.064ex; height:2.176ex;"/></span> training examples of the form <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle \{(x_{1},y_{1}),...,(x_{N},\;y_{N})\}}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mo fence="false" stretchy="false">{</mo>
<mo stretchy="false">(</mo>
<msub>
<mi>x</mi>
<mrow class="MJX-TeXAtom-ORD">
<mn>1</mn>
</mrow>
</msub>
<mo>,</mo>
<msub>
<mi>y</mi>
<mrow class="MJX-TeXAtom-ORD">
<mn>1</mn>
</mrow>
</msub>
<mo stretchy="false">)</mo>
<mo>,</mo>
<mo>.</mo>
<mo>.</mo>
<mo>.</mo>
<mo>,</mo>
<mo stretchy="false">(</mo>
<msub>
<mi>x</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>N</mi>
</mrow>
</msub>
<mo>,</mo>
<mspace width="thickmathspace"></mspace>
<msub>
<mi>y</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>N</mi>
</mrow>
</msub>
<mo stretchy="false">)</mo>
<mo fence="false" stretchy="false">}</mo>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle \{(x_{1},y_{1}),...,(x_{N},\;y_{N})\}}</annotation>
</semantics>
</math></span><img alt="\{(x_1, y_1), ..., (x_N,\; y_N)\}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/3688abd5ec58027a9d879916c83b6890744ce4dd" style="vertical-align: -0.838ex; width:24.255ex; height:2.843ex;"/></span> such that <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle x_{i}}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<msub>
<mi>x</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
</mrow>
</msub>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle x_{i}}</annotation>
</semantics>
</math></span><img alt="x_{i}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/e87000dd6142b81d041896a30fe58f0c3acb2158" style="vertical-align: -0.671ex; width:2.129ex; height:2.009ex;"/></span> is the <a class="mw-redirect" href="/wiki/Feature_vector" title="Feature vector">feature vector</a> of the i-th example and <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle y_{i}}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<msub>
<mi>y</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
</mrow>
</msub>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle y_{i}}</annotation>
</semantics>
</math></span><img alt="y_{i}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/67d30d30b6c2dbe4d6f150d699de040937ecc95f" style="vertical-align: -0.671ex; width:1.939ex; height:2.009ex;"/></span> is its label (i.e., class), a learning algorithm seeks a function <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle g:X\to Y}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>g</mi>
<mo>:</mo>
<mi>X</mi>
<mo stretchy="false">→<!-- → --></mo>
<mi>Y</mi>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle g:X\to Y}</annotation>
</semantics>
</math></span><img alt="g: X \to Y" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/5c825617c180ee9cbba1d56f8514978bf7c33b7c" style="vertical-align: -0.671ex; width:10.421ex; height:2.509ex;"/></span>, where <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle X}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>X</mi>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle X}</annotation>
</semantics>
</math></span><img alt="X" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/68baa052181f707c662844a465bfeeb135e82bab" style="vertical-align: -0.338ex; width:1.98ex; height:2.176ex;"/></span> is the input space and
<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle Y}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>Y</mi>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle Y}</annotation>
</semantics>
</math></span><img alt="Y" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/961d67d6b454b4df2301ac571808a3538b3a6d3f" style="vertical-align: -0.171ex; width:1.773ex; height:2.009ex;"/></span> is the output space.  The function <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle g}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>g</mi>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle g}</annotation>
</semantics>
</math></span><img alt="g" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/d3556280e66fe2c0d0140df20935a6f057381d77" style="vertical-align: -0.671ex; width:1.116ex; height:2.009ex;"/></span> is an element of some space of possible functions <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle G}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>G</mi>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle G}</annotation>
</semantics>
</math></span><img alt="G" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/f5f3c8921a3b352de45446a6789b104458c9f90b" style="vertical-align: -0.338ex; width:1.827ex; height:2.176ex;"/></span>, usually called the <i>hypothesis space</i>.  It is sometimes convenient to
represent <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle g}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>g</mi>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle g}</annotation>
</semantics>
</math></span><img alt="g" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/d3556280e66fe2c0d0140df20935a6f057381d77" style="vertical-align: -0.671ex; width:1.116ex; height:2.009ex;"/></span> using a scoring function <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle f:X\times Y\to \mathbb {R} }" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>f</mi>
<mo>:</mo>
<mi>X</mi>
<mo>×<!-- × --></mo>
<mi>Y</mi>
<mo stretchy="false">→<!-- → --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="double-struck">R</mi>
</mrow>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle f:X\times Y\to \mathbb {R} }</annotation>
</semantics>
</math></span><img alt="{\displaystyle f:X\times Y\to \mathbb {R} }" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/e2c7bc3330b76d58cdb3bff67e7b0ec60a2509c9" style="vertical-align: -0.671ex; width:15.102ex; height:2.509ex;"/></span> such that <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle g}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>g</mi>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle g}</annotation>
</semantics>
</math></span><img alt="g" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/d3556280e66fe2c0d0140df20935a6f057381d77" style="vertical-align: -0.671ex; width:1.116ex; height:2.009ex;"/></span> is defined as returning the <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle y}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>y</mi>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle y}</annotation>
</semantics>
</math></span><img alt="y" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/b8a6208ec717213d4317e666f1ae872e00620a0d" style="vertical-align: -0.671ex; width:1.155ex; height:2.009ex;"/></span> value that gives the highest score: <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle g(x)={\underset {y}{\arg \max }}\;f(x,y)}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>g</mi>
<mo stretchy="false">(</mo>
<mi>x</mi>
<mo stretchy="false">)</mo>
<mo>=</mo>
<mrow class="MJX-TeXAtom-ORD">
<munder>
<mrow>
<mi>arg</mi>
<mo>⁡<!-- ⁡ --></mo>
<mo form="prefix" movablelimits="true">max</mo>
</mrow>
<mi>y</mi>
</munder>
</mrow>
<mspace width="thickmathspace"></mspace>
<mi>f</mi>
<mo stretchy="false">(</mo>
<mi>x</mi>
<mo>,</mo>
<mi>y</mi>
<mo stretchy="false">)</mo>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle g(x)={\underset {y}{\arg \max }}\;f(x,y)}</annotation>
</semantics>
</math></span><img alt="{\displaystyle g(x)={\underset {y}{\arg \max }}\;f(x,y)}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/cba4bc7532dc87fa4312abad85326b21e99f96d8" style="vertical-align: -2.671ex; width:22.555ex; height:4.676ex;"/></span>.  Let <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle F}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>F</mi>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle F}</annotation>
</semantics>
</math></span><img alt="F" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/545fd099af8541605f7ee55f08225526be88ce57" style="vertical-align: -0.338ex; width:1.741ex; height:2.176ex;"/></span> denote the space of scoring functions.
</p><p>Although <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle G}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>G</mi>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle G}</annotation>
</semantics>
</math></span><img alt="G" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/f5f3c8921a3b352de45446a6789b104458c9f90b" style="vertical-align: -0.338ex; width:1.827ex; height:2.176ex;"/></span> and <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle F}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>F</mi>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle F}</annotation>
</semantics>
</math></span><img alt="F" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/545fd099af8541605f7ee55f08225526be88ce57" style="vertical-align: -0.338ex; width:1.741ex; height:2.176ex;"/></span> can be any space of functions, many learning algorithms are probabilistic models where <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle g}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>g</mi>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle g}</annotation>
</semantics>
</math></span><img alt="g" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/d3556280e66fe2c0d0140df20935a6f057381d77" style="vertical-align: -0.671ex; width:1.116ex; height:2.009ex;"/></span> takes the form of a <a href="/wiki/Conditional_probability" title="Conditional probability">conditional probability</a> model <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle g(x)=P(y|x)}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>g</mi>
<mo stretchy="false">(</mo>
<mi>x</mi>
<mo stretchy="false">)</mo>
<mo>=</mo>
<mi>P</mi>
<mo stretchy="false">(</mo>
<mi>y</mi>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">|</mo>
</mrow>
<mi>x</mi>
<mo stretchy="false">)</mo>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle g(x)=P(y|x)}</annotation>
</semantics>
</math></span><img alt="g(x) =
P(y|x)" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/82a1706f757c0414d749cef961f6a82975b963c5" style="vertical-align: -0.838ex; width:14.04ex; height:2.843ex;"/></span>, or <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle f}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>f</mi>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle f}</annotation>
</semantics>
</math></span><img alt="f" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/132e57acb643253e7810ee9702d9581f159a1c61" style="vertical-align: -0.671ex; width:1.279ex; height:2.509ex;"/></span> takes the form of a <a class="mw-redirect" href="/wiki/Joint_probability" title="Joint probability">joint probability</a> model <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle f(x,y)=P(x,y)}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>f</mi>
<mo stretchy="false">(</mo>
<mi>x</mi>
<mo>,</mo>
<mi>y</mi>
<mo stretchy="false">)</mo>
<mo>=</mo>
<mi>P</mi>
<mo stretchy="false">(</mo>
<mi>x</mi>
<mo>,</mo>
<mi>y</mi>
<mo stretchy="false">)</mo>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle f(x,y)=P(x,y)}</annotation>
</semantics>
</math></span><img alt="f(x,y) = P(x,y)" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/497c7a6614b31a86270a3a7bed89410bcd1e001c" style="vertical-align: -0.838ex; width:16.779ex; height:2.843ex;"/></span>.  For example, <a href="/wiki/Naive_Bayes_classifier" title="Naive Bayes classifier">naive Bayes</a> and <a href="/wiki/Linear_discriminant_analysis" title="Linear discriminant analysis">linear discriminant analysis</a> are joint probability models, whereas <a href="/wiki/Logistic_regression" title="Logistic regression">logistic regression</a> is a conditional probability model.
</p><p>There are two basic approaches to choosing <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle f}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>f</mi>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle f}</annotation>
</semantics>
</math></span><img alt="f" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/132e57acb643253e7810ee9702d9581f159a1c61" style="vertical-align: -0.671ex; width:1.279ex; height:2.509ex;"/></span> or <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle g}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>g</mi>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle g}</annotation>
</semantics>
</math></span><img alt="g" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/d3556280e66fe2c0d0140df20935a6f057381d77" style="vertical-align: -0.671ex; width:1.116ex; height:2.009ex;"/></span>: <a href="/wiki/Empirical_risk_minimization" title="Empirical risk minimization">empirical risk minimization</a> and <a href="/wiki/Structural_risk_minimization" title="Structural risk minimization">structural risk minimization</a>.<sup class="reference" id="cite_ref-7"><a href="#cite_note-7">[7]</a></sup>  Empirical risk minimization seeks the function that best fits the training data.  Structural risk minimization includes a <i>penalty function</i> that controls the bias/variance tradeoff.
</p><p>In both cases, it is assumed that the training set consists of a sample of <a class="mw-redirect" href="/wiki/Independent_and_identically-distributed_random_variables" title="Independent and identically-distributed random variables">independent and identically distributed pairs</a>, <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle (x_{i},\;y_{i})}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mo stretchy="false">(</mo>
<msub>
<mi>x</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
</mrow>
</msub>
<mo>,</mo>
<mspace width="thickmathspace"></mspace>
<msub>
<mi>y</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
</mrow>
</msub>
<mo stretchy="false">)</mo>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle (x_{i},\;y_{i})}</annotation>
</semantics>
</math></span><img alt="(x_i, \;y_i)" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/413bed828a4750e458455095965e7082bece1e98" style="vertical-align: -0.838ex; width:7.557ex; height:2.843ex;"/></span>.  In order to measure how well a function fits the training data, a <a href="/wiki/Loss_function" title="Loss function">loss function</a> <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle L:Y\times Y\to \mathbb {R} ^{\geq 0}}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>L</mi>
<mo>:</mo>
<mi>Y</mi>
<mo>×<!-- × --></mo>
<mi>Y</mi>
<mo stretchy="false">→<!-- → --></mo>
<msup>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="double-struck">R</mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mo>≥<!-- ≥ --></mo>
<mn>0</mn>
</mrow>
</msup>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle L:Y\times Y\to \mathbb {R} ^{\geq 0}}</annotation>
</semantics>
</math></span><img alt="{\displaystyle L:Y\times Y\to \mathbb {R} ^{\geq 0}}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/881dc7b502a2b6a4970fb06609e170cf79475a59" style="vertical-align: -0.338ex; width:17.532ex; height:2.676ex;"/></span> is defined.  For training example <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle (x_{i},\;y_{i})}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mo stretchy="false">(</mo>
<msub>
<mi>x</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
</mrow>
</msub>
<mo>,</mo>
<mspace width="thickmathspace"></mspace>
<msub>
<mi>y</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
</mrow>
</msub>
<mo stretchy="false">)</mo>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle (x_{i},\;y_{i})}</annotation>
</semantics>
</math></span><img alt="(x_i,\;y_i)" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/413bed828a4750e458455095965e7082bece1e98" style="vertical-align: -0.838ex; width:7.557ex; height:2.843ex;"/></span>, the loss of predicting the value <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle {\hat {y}}}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mrow class="MJX-TeXAtom-ORD">
<mrow class="MJX-TeXAtom-ORD">
<mover>
<mi>y</mi>
<mo stretchy="false">^<!-- ^ --></mo>
</mover>
</mrow>
</mrow>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle {\hat {y}}}</annotation>
</semantics>
</math></span><img alt="{\hat {y}}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/3dc8de3d8ea01304329ef9518fad7a6d196c4c01" style="vertical-align: -0.671ex; width:1.302ex; height:2.509ex;"/></span> is <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle L(y_{i},{\hat {y}})}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>L</mi>
<mo stretchy="false">(</mo>
<msub>
<mi>y</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
</mrow>
</msub>
<mo>,</mo>
<mrow class="MJX-TeXAtom-ORD">
<mrow class="MJX-TeXAtom-ORD">
<mover>
<mi>y</mi>
<mo stretchy="false">^<!-- ^ --></mo>
</mover>
</mrow>
</mrow>
<mo stretchy="false">)</mo>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle L(y_{i},{\hat {y}})}</annotation>
</semantics>
</math></span><img alt="L(y_i,\hat{y})" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/6ac9025f28e57a00e0b20d64598436fe7a7477e9" style="vertical-align: -0.838ex; width:7.667ex; height:2.843ex;"/></span>.
</p><p>The <i>risk</i> <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle R(g)}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>R</mi>
<mo stretchy="false">(</mo>
<mi>g</mi>
<mo stretchy="false">)</mo>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle R(g)}</annotation>
</semantics>
</math></span><img alt="R(g)" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/ae075d527038ed7d449f85ced07e487b5807446c" style="vertical-align: -0.838ex; width:4.689ex; height:2.843ex;"/></span> of function <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle g}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>g</mi>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle g}</annotation>
</semantics>
</math></span><img alt="g" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/d3556280e66fe2c0d0140df20935a6f057381d77" style="vertical-align: -0.671ex; width:1.116ex; height:2.009ex;"/></span> is defined as the expected loss of <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle g}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>g</mi>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle g}</annotation>
</semantics>
</math></span><img alt="g" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/d3556280e66fe2c0d0140df20935a6f057381d77" style="vertical-align: -0.671ex; width:1.116ex; height:2.009ex;"/></span>.  This can be estimated from the training data as
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle R_{emp}(g)={\frac {1}{N}}\sum _{i}L(y_{i},g(x_{i}))}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<msub>
<mi>R</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>e</mi>
<mi>m</mi>
<mi>p</mi>
</mrow>
</msub>
<mo stretchy="false">(</mo>
<mi>g</mi>
<mo stretchy="false">)</mo>
<mo>=</mo>
<mrow class="MJX-TeXAtom-ORD">
<mfrac>
<mn>1</mn>
<mi>N</mi>
</mfrac>
</mrow>
<munder>
<mo>∑<!-- ∑ --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
</mrow>
</munder>
<mi>L</mi>
<mo stretchy="false">(</mo>
<msub>
<mi>y</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
</mrow>
</msub>
<mo>,</mo>
<mi>g</mi>
<mo stretchy="false">(</mo>
<msub>
<mi>x</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
</mrow>
</msub>
<mo stretchy="false">)</mo>
<mo stretchy="false">)</mo>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle R_{emp}(g)={\frac {1}{N}}\sum _{i}L(y_{i},g(x_{i}))}</annotation>
</semantics>
</math></span><img alt="R_{emp}(g) = \frac{1}{N} \sum_i L(y_i, g(x_i))" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/87fa2fe2f731e8e1b02e2710d36fc16076e449bf" style="vertical-align: -3.005ex; width:29.504ex; height:6.343ex;"/></span>.</dd></dl>
<h3><span class="mw-headline" id="Empirical_risk_minimization">Empirical risk minimization</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Supervised_learning&amp;action=edit&amp;section=10" title="Edit section: Empirical risk minimization">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<div class="hatnote navigation-not-searchable" role="note">Main article: <a href="/wiki/Empirical_risk_minimization" title="Empirical risk minimization">Empirical risk minimization</a></div>
<p>In empirical risk minimization, the supervised learning algorithm seeks the function <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle g}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>g</mi>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle g}</annotation>
</semantics>
</math></span><img alt="g" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/d3556280e66fe2c0d0140df20935a6f057381d77" style="vertical-align: -0.671ex; width:1.116ex; height:2.009ex;"/></span> that minimizes <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle R(g)}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>R</mi>
<mo stretchy="false">(</mo>
<mi>g</mi>
<mo stretchy="false">)</mo>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle R(g)}</annotation>
</semantics>
</math></span><img alt="R(g)" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/ae075d527038ed7d449f85ced07e487b5807446c" style="vertical-align: -0.838ex; width:4.689ex; height:2.843ex;"/></span>.  Hence, a supervised learning algorithm can be constructed by applying an <a class="mw-redirect" href="/wiki/Optimization_(mathematics)" title="Optimization (mathematics)">optimization algorithm</a> to find <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle g}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>g</mi>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle g}</annotation>
</semantics>
</math></span><img alt="g" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/d3556280e66fe2c0d0140df20935a6f057381d77" style="vertical-align: -0.671ex; width:1.116ex; height:2.009ex;"/></span>.
</p><p>When <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle g}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>g</mi>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle g}</annotation>
</semantics>
</math></span><img alt="g" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/d3556280e66fe2c0d0140df20935a6f057381d77" style="vertical-align: -0.671ex; width:1.116ex; height:2.009ex;"/></span> is a conditional probability distribution <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle P(y|x)}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>P</mi>
<mo stretchy="false">(</mo>
<mi>y</mi>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">|</mo>
</mrow>
<mi>x</mi>
<mo stretchy="false">)</mo>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle P(y|x)}</annotation>
</semantics>
</math></span><img alt="P(y|x)" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/5d08508dff9e465cc317804ff19999c4ffbf7d94" style="vertical-align: -0.838ex; width:6.687ex; height:2.843ex;"/></span> and the loss function is the negative log likelihood: <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle L(y,{\hat {y}})=-\log P(y|x)}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>L</mi>
<mo stretchy="false">(</mo>
<mi>y</mi>
<mo>,</mo>
<mrow class="MJX-TeXAtom-ORD">
<mrow class="MJX-TeXAtom-ORD">
<mover>
<mi>y</mi>
<mo stretchy="false">^<!-- ^ --></mo>
</mover>
</mrow>
</mrow>
<mo stretchy="false">)</mo>
<mo>=</mo>
<mo>−<!-- − --></mo>
<mi>log</mi>
<mo>⁡<!-- ⁡ --></mo>
<mi>P</mi>
<mo stretchy="false">(</mo>
<mi>y</mi>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">|</mo>
</mrow>
<mi>x</mi>
<mo stretchy="false">)</mo>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle L(y,{\hat {y}})=-\log P(y|x)}</annotation>
</semantics>
</math></span><img alt="L(y, \hat{y}) = -\log P(y | x)" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/eaee3db78a569f2bb35e3dced4a1953ace44665b" style="vertical-align: -0.838ex; width:22.223ex; height:2.843ex;"/></span>, then empirical risk minimization is equivalent to <a class="mw-redirect" href="/wiki/Maximum_likelihood" title="Maximum likelihood">maximum likelihood estimation</a>.
</p><p>When <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle G}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>G</mi>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle G}</annotation>
</semantics>
</math></span><img alt="G" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/f5f3c8921a3b352de45446a6789b104458c9f90b" style="vertical-align: -0.338ex; width:1.827ex; height:2.176ex;"/></span> contains many candidate functions or the training set is not sufficiently large, empirical risk minimization leads to high variance and poor generalization.  The learning algorithm is able
to memorize the training examples without generalizing well.  This is called <a href="/wiki/Overfitting" title="Overfitting">overfitting</a>.
</p>
<h3><span class="mw-headline" id="Structural_risk_minimization">Structural risk minimization</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Supervised_learning&amp;action=edit&amp;section=11" title="Edit section: Structural risk minimization">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p><a href="/wiki/Structural_risk_minimization" title="Structural risk minimization">Structural risk minimization</a> seeks to prevent overfitting by incorporating a <a href="/wiki/Regularization_(mathematics)" title="Regularization (mathematics)">regularization penalty</a> into the optimization.  The regularization penalty can be viewed as implementing a form of <a href="/wiki/Occam%27s_razor" title="Occam's razor">Occam's razor</a> that prefers simpler functions over more complex ones.
</p><p>A wide variety of penalties have been employed that correspond to different definitions of complexity.  For example, consider the case where the function <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle g}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>g</mi>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle g}</annotation>
</semantics>
</math></span><img alt="g" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/d3556280e66fe2c0d0140df20935a6f057381d77" style="vertical-align: -0.671ex; width:1.116ex; height:2.009ex;"/></span> is a linear function of the form
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle g(x)=\sum _{j=1}^{d}\beta _{j}x_{j}}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>g</mi>
<mo stretchy="false">(</mo>
<mi>x</mi>
<mo stretchy="false">)</mo>
<mo>=</mo>
<munderover>
<mo>∑<!-- ∑ --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mi>j</mi>
<mo>=</mo>
<mn>1</mn>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mi>d</mi>
</mrow>
</munderover>
<msub>
<mi>β<!-- β --></mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>j</mi>
</mrow>
</msub>
<msub>
<mi>x</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>j</mi>
</mrow>
</msub>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle g(x)=\sum _{j=1}^{d}\beta _{j}x_{j}}</annotation>
</semantics>
</math></span><img alt=" g(x) = \sum_{j=1}^d \beta_j x_j" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/86f23781682d33c596d0cda976b013e2b6fdf939" style="vertical-align: -3.338ex; width:15.56ex; height:7.676ex;"/></span>.</dd></dl>
<p>A popular regularization penalty is <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle \sum _{j}\beta _{j}^{2}}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<munder>
<mo>∑<!-- ∑ --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mi>j</mi>
</mrow>
</munder>
<msubsup>
<mi>β<!-- β --></mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>j</mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mn>2</mn>
</mrow>
</msubsup>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle \sum _{j}\beta _{j}^{2}}</annotation>
</semantics>
</math></span><img alt="\sum_j \beta_j^2" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/f7df304919e1cdf3dfc49b9db648afce80a189ce" style="vertical-align: -3.338ex; width:6.133ex; height:5.843ex;"/></span>, which is the squared <a class="mw-redirect" href="/wiki/Euclidean_norm" title="Euclidean norm">Euclidean norm</a> of the weights, also known as the <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle L_{2}}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<msub>
<mi>L</mi>
<mrow class="MJX-TeXAtom-ORD">
<mn>2</mn>
</mrow>
</msub>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle L_{2}}</annotation>
</semantics>
</math></span><img alt="L_{2}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/c6a952cfe42c86b7741f55a817da0e251793a358" style="vertical-align: -0.671ex; width:2.637ex; height:2.509ex;"/></span> norm.  Other norms include the <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle L_{1}}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<msub>
<mi>L</mi>
<mrow class="MJX-TeXAtom-ORD">
<mn>1</mn>
</mrow>
</msub>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle L_{1}}</annotation>
</semantics>
</math></span><img alt="L_{1}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/0e79dc1b001f8b923df475ed14de023cbc456013" style="vertical-align: -0.671ex; width:2.637ex; height:2.509ex;"/></span> norm, <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle \sum _{j}|\beta _{j}|}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<munder>
<mo>∑<!-- ∑ --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mi>j</mi>
</mrow>
</munder>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">|</mo>
</mrow>
<msub>
<mi>β<!-- β --></mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>j</mi>
</mrow>
</msub>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">|</mo>
</mrow>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle \sum _{j}|\beta _{j}|}</annotation>
</semantics>
</math></span><img alt="\sum_j |\beta_j|" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/4f7c345923255a0cf76b3e2080b915eeb02f4126" style="vertical-align: -3.338ex; width:7.261ex; height:5.843ex;"/></span>, and the <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle L_{0}}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<msub>
<mi>L</mi>
<mrow class="MJX-TeXAtom-ORD">
<mn>0</mn>
</mrow>
</msub>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle L_{0}}</annotation>
</semantics>
</math></span><img alt="L_{0}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/db742b8c210fc611329a4c2dcc3af4b4e1a110cb" style="vertical-align: -0.671ex; width:2.637ex; height:2.509ex;"/></span> norm, which is the number of non-zero  <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle \beta _{j}}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<msub>
<mi>β<!-- β --></mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>j</mi>
</mrow>
</msub>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle \beta _{j}}</annotation>
</semantics>
</math></span><img alt="\beta _{j}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/83edf0558c67ad56ca5c05096b550bd733d62c4b" style="vertical-align: -1.005ex; width:2.225ex; height:2.843ex;"/></span>s.  The penalty will be denoted by <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle C(g)}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>C</mi>
<mo stretchy="false">(</mo>
<mi>g</mi>
<mo stretchy="false">)</mo>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle C(g)}</annotation>
</semantics>
</math></span><img alt="C(g)" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/e60538c5c17aadb0567923ff496ba4da02bcd40c" style="vertical-align: -0.838ex; width:4.692ex; height:2.843ex;"/></span>.
</p><p>The supervised learning optimization problem is to find the function <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle g}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>g</mi>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle g}</annotation>
</semantics>
</math></span><img alt="g" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/d3556280e66fe2c0d0140df20935a6f057381d77" style="vertical-align: -0.671ex; width:1.116ex; height:2.009ex;"/></span> that minimizes
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle J(g)=R_{emp}(g)+\lambda C(g).}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>J</mi>
<mo stretchy="false">(</mo>
<mi>g</mi>
<mo stretchy="false">)</mo>
<mo>=</mo>
<msub>
<mi>R</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>e</mi>
<mi>m</mi>
<mi>p</mi>
</mrow>
</msub>
<mo stretchy="false">(</mo>
<mi>g</mi>
<mo stretchy="false">)</mo>
<mo>+</mo>
<mi>λ<!-- λ --></mi>
<mi>C</mi>
<mo stretchy="false">(</mo>
<mi>g</mi>
<mo stretchy="false">)</mo>
<mo>.</mo>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle J(g)=R_{emp}(g)+\lambda C(g).}</annotation>
</semantics>
</math></span><img alt=" J(g) = R_{emp}(g) + \lambda C(g)." aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/f66b4b813c97f6598ed08791352e014fc7e16514" style="vertical-align: -1.005ex; width:24.987ex; height:3.009ex;"/></span></dd></dl>
<p>The parameter <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle \lambda }" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>λ<!-- λ --></mi>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle \lambda }</annotation>
</semantics>
</math></span><img alt="\lambda " aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/b43d0ea3c9c025af1be9128e62a18fa74bedda2a" style="vertical-align: -0.338ex; width:1.355ex; height:2.176ex;"/></span> controls the bias-variance tradeoff.  When <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle \lambda =0}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>λ<!-- λ --></mi>
<mo>=</mo>
<mn>0</mn>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle \lambda =0}</annotation>
</semantics>
</math></span><img alt="\lambda =0" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/00c4bba30544017fe76932de5a4e25adb5512d95" style="vertical-align: -0.338ex; width:5.616ex; height:2.176ex;"/></span>, this gives empirical risk minimization with low bias and high variance.  When <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle \lambda }" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>λ<!-- λ --></mi>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle \lambda }</annotation>
</semantics>
</math></span><img alt="\lambda " aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/b43d0ea3c9c025af1be9128e62a18fa74bedda2a" style="vertical-align: -0.338ex; width:1.355ex; height:2.176ex;"/></span> is large, the learning algorithm will have high bias and low variance.  The value of <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle \lambda }" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>λ<!-- λ --></mi>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle \lambda }</annotation>
</semantics>
</math></span><img alt="\lambda " aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/b43d0ea3c9c025af1be9128e62a18fa74bedda2a" style="vertical-align: -0.338ex; width:1.355ex; height:2.176ex;"/></span> can be chosen empirically via <a href="/wiki/Cross-validation_(statistics)" title="Cross-validation (statistics)">cross validation</a>.
</p><p>The complexity penalty has a Bayesian interpretation as the negative log prior probability of <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle g}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>g</mi>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle g}</annotation>
</semantics>
</math></span><img alt="g" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/d3556280e66fe2c0d0140df20935a6f057381d77" style="vertical-align: -0.671ex; width:1.116ex; height:2.009ex;"/></span>, <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle -\log P(g)}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mo>−<!-- − --></mo>
<mi>log</mi>
<mo>⁡<!-- ⁡ --></mo>
<mi>P</mi>
<mo stretchy="false">(</mo>
<mi>g</mi>
<mo stretchy="false">)</mo>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle -\log P(g)}</annotation>
</semantics>
</math></span><img alt="-\log P(g)" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/140f8e655a53130f7068d9341b32891142e3a80c" style="vertical-align: -0.838ex; width:10.225ex; height:2.843ex;"/></span>, in which case <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle J(g)}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>J</mi>
<mo stretchy="false">(</mo>
<mi>g</mi>
<mo stretchy="false">)</mo>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle J(g)}</annotation>
</semantics>
</math></span><img alt="J(g)" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/81eae208007bd0ddec50b7f177e991b914a11508" style="vertical-align: -0.838ex; width:4.397ex; height:2.843ex;"/></span> is the <a href="/wiki/Posterior_probability" title="Posterior probability">posterior probabability</a> of <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle g}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>g</mi>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle g}</annotation>
</semantics>
</math></span><img alt="g" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/d3556280e66fe2c0d0140df20935a6f057381d77" style="vertical-align: -0.671ex; width:1.116ex; height:2.009ex;"/></span>.
</p>
<h2><span class="mw-headline" id="Generative_training">Generative training</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Supervised_learning&amp;action=edit&amp;section=12" title="Edit section: Generative training">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>The training methods described above are <i>discriminative training</i> methods, because they seek to find a function <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle g}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>g</mi>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle g}</annotation>
</semantics>
</math></span><img alt="g" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/d3556280e66fe2c0d0140df20935a6f057381d77" style="vertical-align: -0.671ex; width:1.116ex; height:2.009ex;"/></span> that discriminates well between the different output values (see <a href="/wiki/Discriminative_model" title="Discriminative model">discriminative model</a>).  For the special case where <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle f(x,y)=P(x,y)}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>f</mi>
<mo stretchy="false">(</mo>
<mi>x</mi>
<mo>,</mo>
<mi>y</mi>
<mo stretchy="false">)</mo>
<mo>=</mo>
<mi>P</mi>
<mo stretchy="false">(</mo>
<mi>x</mi>
<mo>,</mo>
<mi>y</mi>
<mo stretchy="false">)</mo>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle f(x,y)=P(x,y)}</annotation>
</semantics>
</math></span><img alt="f(x,y) = P(x,y)" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/497c7a6614b31a86270a3a7bed89410bcd1e001c" style="vertical-align: -0.838ex; width:16.779ex; height:2.843ex;"/></span> is a <a href="/wiki/Joint_probability_distribution" title="Joint probability distribution">joint probability distribution</a> and the loss function is the negative log likelihood <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle -\sum _{i}\log P(x_{i},y_{i}),}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mo>−<!-- − --></mo>
<munder>
<mo>∑<!-- ∑ --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
</mrow>
</munder>
<mi>log</mi>
<mo>⁡<!-- ⁡ --></mo>
<mi>P</mi>
<mo stretchy="false">(</mo>
<msub>
<mi>x</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
</mrow>
</msub>
<mo>,</mo>
<msub>
<mi>y</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
</mrow>
</msub>
<mo stretchy="false">)</mo>
<mo>,</mo>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle -\sum _{i}\log P(x_{i},y_{i}),}</annotation>
</semantics>
</math></span><img alt="- \sum_i \log P(x_i, y_i)," aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/89be2acbbec6725f4ac254167f2d9cd7e97d2c7c" style="vertical-align: -3.005ex; width:18.6ex; height:5.509ex;"/></span> a risk minimization algorithm is said to perform <i>generative training</i>, because <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle f}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>f</mi>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle f}</annotation>
</semantics>
</math></span><img alt="f" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/132e57acb643253e7810ee9702d9581f159a1c61" style="vertical-align: -0.671ex; width:1.279ex; height:2.509ex;"/></span> can be regarded as a <a href="/wiki/Generative_model" title="Generative model">generative model</a> that explains how the data were generated.  Generative training algorithms are often simpler and more computationally efficient than discriminative training algorithms.  In some cases, the solution can be computed in closed form as in <a href="/wiki/Naive_Bayes_classifier" title="Naive Bayes classifier">naive Bayes</a> and <a href="/wiki/Linear_discriminant_analysis" title="Linear discriminant analysis">linear discriminant analysis</a>.
</p>
<h2><span class="mw-headline" id="Generalizations">Generalizations</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Supervised_learning&amp;action=edit&amp;section=13" title="Edit section: Generalizations">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>There are several ways in which the standard supervised learning problem can be generalized:
</p>
<ul><li><a href="/wiki/Semi-supervised_learning" title="Semi-supervised learning">Semi-supervised learning</a>: In this setting, the desired output values are provided only for a subset of the training data.  The remaining data is unlabeled.</li>
<li><a href="/wiki/Weak_supervision" title="Weak supervision">Weak supervision</a>: In this setting, noisy, limited, or imprecise sources are used to provide supervision signal for labeling training data.</li>
<li><a href="/wiki/Active_learning_(machine_learning)" title="Active learning (machine learning)">Active learning</a>: Instead of assuming that all of the training examples are given at the start, active learning algorithms interactively collect new examples, typically by making queries to a human user.  Often, the queries are based on unlabeled data, which is a scenario that combines semi-supervised learning with active learning.</li>
<li><a href="/wiki/Structured_prediction" title="Structured prediction">Structured prediction</a>: When the desired output value is a complex object, such as a parse tree or a labeled graph, then standard methods must be extended.</li>
<li><a href="/wiki/Learning_to_rank" title="Learning to rank">Learning to rank</a>: When the input is a set of objects and the desired output is a ranking of those objects, then again the standard methods must be extended.</li></ul>
<h2><span class="mw-headline" id="Approaches_and_algorithms">Approaches and algorithms</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Supervised_learning&amp;action=edit&amp;section=14" title="Edit section: Approaches and algorithms">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<ul><li>Analytical learning</li>
<li><a href="/wiki/Artificial_neural_network" title="Artificial neural network">Artificial neural network</a></li>
<li><a href="/wiki/Backpropagation" title="Backpropagation">Backpropagation</a></li>
<li><a class="mw-redirect" href="/wiki/Boosting_(meta-algorithm)" title="Boosting (meta-algorithm)">Boosting (meta-algorithm)</a></li>
<li><a href="/wiki/Bayesian_statistics" title="Bayesian statistics">Bayesian statistics</a></li>
<li><a href="/wiki/Case-based_reasoning" title="Case-based reasoning">Case-based reasoning</a></li>
<li><a href="/wiki/Decision_tree_learning" title="Decision tree learning">Decision tree learning</a></li>
<li><a href="/wiki/Inductive_logic_programming" title="Inductive logic programming">Inductive logic programming</a></li>
<li><a class="mw-redirect" href="/wiki/Gaussian_process_regression" title="Gaussian process regression">Gaussian process regression</a></li>
<li><a class="mw-redirect" href="/wiki/Genetic_Programming" title="Genetic Programming">Genetic Programming</a></li>
<li><a href="/wiki/Group_method_of_data_handling" title="Group method of data handling">Group method of data handling</a></li>
<li><a href="/wiki/Variable_kernel_density_estimation#Use_for_statistical_classification" title="Variable kernel density estimation">Kernel estimators</a></li>
<li><a class="mw-redirect" href="/wiki/Learning_Automata" title="Learning Automata">Learning Automata</a></li>
<li><a href="/wiki/Learning_classifier_system" title="Learning classifier system">Learning Classifier Systems</a></li>
<li><a href="/wiki/Minimum_message_length" title="Minimum message length">Minimum message length</a> (<a href="/wiki/Decision_tree" title="Decision tree">decision trees</a>, decision graphs, etc.)</li>
<li><a href="/wiki/Multilinear_subspace_learning" title="Multilinear subspace learning">Multilinear subspace learning</a></li>
<li><a href="/wiki/Naive_Bayes_classifier" title="Naive Bayes classifier">Naive Bayes classifier</a></li>
<li><a class="mw-redirect" href="/wiki/Maximum_entropy_classifier" title="Maximum entropy classifier">Maximum entropy classifier</a></li>
<li><a href="/wiki/Conditional_random_field" title="Conditional random field">Conditional random field</a></li>
<li><a class="mw-redirect" href="/wiki/Nearest_neighbor_(pattern_recognition)" title="Nearest neighbor (pattern recognition)">Nearest Neighbor Algorithm</a></li>
<li><a href="/wiki/Probably_approximately_correct_learning" title="Probably approximately correct learning">Probably approximately correct learning</a> (PAC) learning</li>
<li><a class="mw-redirect" href="/wiki/Ripple_down_rules" title="Ripple down rules">Ripple down rules</a>, a knowledge acquisition methodology</li>
<li>Symbolic machine learning algorithms</li>
<li>Subsymbolic machine learning algorithms</li>
<li><a class="mw-redirect" href="/wiki/Support_vector_machine" title="Support vector machine">Support vector machines</a></li>
<li>Minimum Complexity Machines (MCM)</li>
<li><a href="/wiki/Random_forest" title="Random forest">Random Forests</a></li>
<li><a class="mw-redirect" href="/wiki/Ensembles_of_Classifiers" title="Ensembles of Classifiers">Ensembles of Classifiers</a></li>
<li><a class="mw-redirect" href="/wiki/Ordinal_classification" title="Ordinal classification">Ordinal classification</a></li>
<li><a class="mw-redirect" href="/wiki/Data_Pre-processing" title="Data Pre-processing">Data Pre-processing</a></li>
<li>Handling imbalanced datasets</li>
<li><a href="/wiki/Statistical_relational_learning" title="Statistical relational learning">Statistical relational learning</a></li>
<li><a href="/wiki/Proaftn" title="Proaftn">Proaftn</a>, a multicriteria classification algorithm</li></ul>
<h2><span class="mw-headline" id="Applications">Applications</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Supervised_learning&amp;action=edit&amp;section=15" title="Edit section: Applications">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<ul><li><a href="/wiki/Bioinformatics" title="Bioinformatics">Bioinformatics</a></li>
<li><a href="/wiki/Cheminformatics" title="Cheminformatics">Cheminformatics</a>
<ul><li><a href="/wiki/Quantitative_structure%E2%80%93activity_relationship" title="Quantitative structure–activity relationship">Quantitative structure–activity relationship</a></li></ul></li>
<li><a href="/wiki/Database_marketing" title="Database marketing">Database marketing</a></li>
<li><a href="/wiki/Handwriting_recognition" title="Handwriting recognition">Handwriting recognition</a></li>
<li><a href="/wiki/Information_retrieval" title="Information retrieval">Information retrieval</a>
<ul><li><a href="/wiki/Learning_to_rank" title="Learning to rank">Learning to rank</a></li></ul></li>
<li><a href="/wiki/Information_extraction" title="Information extraction">Information extraction</a></li>
<li>Object recognition in <a href="/wiki/Computer_vision" title="Computer vision">computer vision</a></li>
<li><a href="/wiki/Optical_character_recognition" title="Optical character recognition">Optical character recognition</a></li>
<li><a href="/wiki/Spamming" title="Spamming">Spam detection</a></li>
<li><a href="/wiki/Pattern_recognition" title="Pattern recognition">Pattern recognition</a></li>
<li><a href="/wiki/Speech_recognition" title="Speech recognition">Speech recognition</a></li>
<li>Supervised learning is a special case of <a href="/wiki/Downward_causation" title="Downward causation">Downward causation</a> in biological systems</li></ul>
<h2><span class="mw-headline" id="General_issues">General issues</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Supervised_learning&amp;action=edit&amp;section=16" title="Edit section: General issues">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<ul><li><a href="/wiki/Computational_learning_theory" title="Computational learning theory">Computational learning theory</a></li>
<li><a href="/wiki/Inductive_bias" title="Inductive bias">Inductive bias</a></li>
<li><a class="mw-redirect" href="/wiki/Overfitting_(machine_learning)" title="Overfitting (machine learning)">Overfitting (machine learning)</a></li>
<li>(Uncalibrated) <a class="mw-redirect" href="/wiki/Class_membership_probabilities" title="Class membership probabilities">Class membership probabilities</a></li>
<li><a href="/wiki/Unsupervised_learning" title="Unsupervised learning">Unsupervised learning</a></li>
<li><a class="mw-redirect" href="/wiki/Version_space" title="Version space">Version spaces</a></li></ul>
<h2><span class="mw-headline" id="See_also">See also</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Supervised_learning&amp;action=edit&amp;section=17" title="Edit section: See also">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<ul><li><a class="mw-redirect" href="/wiki/List_of_datasets_for_machine_learning_research" title="List of datasets for machine learning research">List of datasets for machine learning research</a></li></ul>
<h2><span class="mw-headline" id="References">References</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Supervised_learning&amp;action=edit&amp;section=18" title="Edit section: References">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<div class="reflist" style="list-style-type: decimal;">
<div class="mw-references-wrap"><ol class="references">
<li id="cite_note-1"><span class="mw-cite-backlink"><b><a href="#cite_ref-1">^</a></b></span> <span class="reference-text">Stuart J. Russell, Peter Norvig (2010) <i><a href="/wiki/Artificial_Intelligence:_A_Modern_Approach" title="Artificial Intelligence: A Modern Approach">Artificial Intelligence: A Modern Approach</a>, Third Edition</i>, Prentice Hall <style data-mw-deduplicate="TemplateStyles:r935243608">.mw-parser-output cite.citation{font-style:inherit}.mw-parser-output .citation q{quotes:"\"""\"""'""'"}.mw-parser-output .id-lock-free a,.mw-parser-output .citation .cs1-lock-free a{background:url("//upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/9px-Lock-green.svg.png")no-repeat;background-position:right .1em center}.mw-parser-output .id-lock-limited a,.mw-parser-output .id-lock-registration a,.mw-parser-output .citation .cs1-lock-limited a,.mw-parser-output .citation .cs1-lock-registration a{background:url("//upload.wikimedia.org/wikipedia/commons/thumb/d/d6/Lock-gray-alt-2.svg/9px-Lock-gray-alt-2.svg.png")no-repeat;background-position:right .1em center}.mw-parser-output .id-lock-subscription a,.mw-parser-output .citation .cs1-lock-subscription a{background:url("//upload.wikimedia.org/wikipedia/commons/thumb/a/aa/Lock-red-alt-2.svg/9px-Lock-red-alt-2.svg.png")no-repeat;background-position:right .1em center}.mw-parser-output .cs1-subscription,.mw-parser-output .cs1-registration{color:#555}.mw-parser-output .cs1-subscription span,.mw-parser-output .cs1-registration span{border-bottom:1px dotted;cursor:help}.mw-parser-output .cs1-ws-icon a{background:url("//upload.wikimedia.org/wikipedia/commons/thumb/4/4c/Wikisource-logo.svg/12px-Wikisource-logo.svg.png")no-repeat;background-position:right .1em center}.mw-parser-output code.cs1-code{color:inherit;background:inherit;border:inherit;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;font-size:100%}.mw-parser-output .cs1-visible-error{font-size:100%}.mw-parser-output .cs1-maint{display:none;color:#33aa33;margin-left:0.3em}.mw-parser-output .cs1-subscription,.mw-parser-output .cs1-registration,.mw-parser-output .cs1-format{font-size:95%}.mw-parser-output .cs1-kern-left,.mw-parser-output .cs1-kern-wl-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right,.mw-parser-output .cs1-kern-wl-right{padding-right:0.2em}</style><a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a> <a href="/wiki/Special:BookSources/9780136042594" title="Special:BookSources/9780136042594">9780136042594</a>.</span>
</li>
<li id="cite_note-2"><span class="mw-cite-backlink"><b><a href="#cite_ref-2">^</a></b></span> <span class="reference-text"><a href="/wiki/Mehryar_Mohri" title="Mehryar Mohri">Mehryar Mohri</a>, Afshin Rostamizadeh, Ameet Talwalkar (2012) <i>Foundations of Machine Learning</i>, The MIT Press <link href="mw-data:TemplateStyles:r935243608" rel="mw-deduplicated-inline-style"/><a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a> <a href="/wiki/Special:BookSources/9780262018258" title="Special:BookSources/9780262018258">9780262018258</a>.</span>
</li>
<li id="cite_note-3"><span class="mw-cite-backlink"><b><a href="#cite_ref-3">^</a></b></span> <span class="reference-text">S. Geman, E. Bienenstock, and R. Doursat (1992). <a class="external text" href="http://delta-apache-vm.cs.tau.ac.il/~nin/Courses/NC06/VarbiasBiasGeman.pdf" rel="nofollow">Neural networks and the bias/variance dilemma</a>. Neural Computation 4, 1–58.</span>
</li>
<li id="cite_note-4"><span class="mw-cite-backlink"><b><a href="#cite_ref-4">^</a></b></span> <span class="reference-text">G. James (2003) Variance and Bias for General Loss Functions,  Machine Learning 51, 115-135. (<a class="external free" href="http://www-bcf.usc.edu/~gareth/research/bv.pdf" rel="nofollow">http://www-bcf.usc.edu/~gareth/research/bv.pdf</a>)</span>
</li>
<li id="cite_note-5"><span class="mw-cite-backlink"><b><a href="#cite_ref-5">^</a></b></span> <span class="reference-text">C.E. Brodely and M.A. Friedl (1999). Identifying and Eliminating Mislabeled Training Instances,  Journal of Artificial Intelligence Research 11, 131-167. (<a class="external free" href="http://jair.org/media/606/live-606-1803-jair.pdf" rel="nofollow">http://jair.org/media/606/live-606-1803-jair.pdf</a>)</span>
</li>
<li id="cite_note-6"><span class="mw-cite-backlink"><b><a href="#cite_ref-6">^</a></b></span> <span class="reference-text"><cite class="citation conference">M.R. Smith and T. Martinez (2011). "Improving Classification Accuracy by Identifying and Removing Instances that Should Be Misclassified". <i>Proceedings of International Joint Conference on Neural Networks (IJCNN 2011)</i>. pp. 2690–2697. <a href="/wiki/CiteSeerX" title="CiteSeerX">CiteSeerX</a> <span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="//citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.221.1371" rel="nofollow">10.1.1.221.1371</a></span>. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a class="external text" href="https://doi.org/10.1109%2FIJCNN.2011.6033571" rel="nofollow">10.1109/IJCNN.2011.6033571</a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=conference&amp;rft.atitle=Improving+Classification+Accuracy+by+Identifying+and+Removing+Instances+that+Should+Be+Misclassified&amp;rft.btitle=Proceedings+of+International+Joint+Conference+on+Neural+Networks+%28IJCNN+2011%29&amp;rft.pages=2690-2697&amp;rft.date=2011&amp;rft_id=%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fsummary%3Fdoi%3D10.1.1.221.1371&amp;rft_id=info%3Adoi%2F10.1109%2FIJCNN.2011.6033571&amp;rft.au=M.R.+Smith+and+T.+Martinez&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASupervised+learning"></span><link href="mw-data:TemplateStyles:r935243608" rel="mw-deduplicated-inline-style"/></span>
</li>
<li id="cite_note-7"><span class="mw-cite-backlink"><b><a href="#cite_ref-7">^</a></b></span> <span class="reference-text">Vapnik, V. N. <a class="external text" href="https://books.google.com/books?id=EqgACAAAQBAJ&amp;printsec=frontcover#v=snippet&amp;q=%22empirical%20risk%20minimization%22%20OR%20%22structural%20risk%20minimization%22&amp;f=false" rel="nofollow">The Nature of Statistical Learning Theory</a> (2nd Ed.), Springer Verlag, 2000.</span>
</li>
</ol></div></div>
<h2><span class="mw-headline" id="External_links">External links</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Supervised_learning&amp;action=edit&amp;section=19" title="Edit section: External links">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<ul><li><a class="external text" href="http://www.mloss.org/" rel="nofollow">Machine Learning Open Source Software (MLOSS)</a></li></ul>
<!-- 
NewPP limit report
Parsed by mw1377
Cached time: 20200408150108
Cache expiry: 2592000
Dynamic content: false
Complications: [vary‐revision‐sha1]
CPU time usage: 0.360 seconds
Real time usage: 0.618 seconds
Preprocessor visited node count: 1413/1000000
Post‐expand include size: 32877/2097152 bytes
Template argument size: 2429/2097152 bytes
Highest expansion depth: 15/40
Expensive parser function count: 2/500
Unstrip recursion depth: 1/20
Unstrip post‐expand size: 13163/5000000 bytes
Number of Wikibase entities loaded: 2/400
Lua time usage: 0.091/10.000 seconds
Lua memory usage: 2.55 MB/50 MB
-->
<!--
Transclusion expansion time report (%,ms,calls,template)
100.00%  367.489      1 -total
 58.40%  214.618      1 Template:Reflist
 35.58%  130.741      1 Template:Cite_conference
 18.72%   68.777      2 Template:ISBN
 18.48%   67.928      1 Template:Short_description
 13.82%   50.805      2 Template:Pagetype
 12.64%   46.444      1 Template:Machine_learning_bar
 11.63%   42.750      1 Template:Sidebar_with_collapsible_lists
 10.07%   36.989      2 Template:Catalog_lookup_link
  6.70%   24.621      1 Template:Longitem
-->
<!-- Saved in parser cache with key enwiki:pcache:idhash:20926-0!canonical!math=5 and timestamp 20200408150108 and revision id 949790121
 -->
</div><noscript><img alt="" height="1" src="//en.wikipedia.org/wiki/Special:CentralAutoLogin/start?type=1x1" style="border: none; position: absolute;" title="" width="1"/></noscript></div>
<div class="printfooter">Retrieved from "<a dir="ltr" href="https://en.wikipedia.org/w/index.php?title=Supervised_learning&amp;oldid=949790121">https://en.wikipedia.org/w/index.php?title=Supervised_learning&amp;oldid=949790121</a>"</div>
<div class="catlinks" data-mw="interface" id="catlinks"><div class="mw-normal-catlinks" id="mw-normal-catlinks"><a href="/wiki/Help:Category" title="Help:Category">Categories</a>: <ul><li><a href="/wiki/Category:Supervised_learning" title="Category:Supervised learning">Supervised learning</a></li></ul></div><div class="mw-hidden-catlinks mw-hidden-cats-hidden" id="mw-hidden-catlinks">Hidden categories: <ul><li><a href="/wiki/Category:Articles_with_short_description" title="Category:Articles with short description">Articles with short description</a></li><li><a href="/wiki/Category:Articles_with_long_short_description" title="Category:Articles with long short description">Articles with long short description</a></li></ul></div></div>
<div class="visualClear"></div>
</div>
</div>
<div id="mw-data-after-content">
<div class="read-more-container"></div>
</div>
<div id="mw-navigation">
<h2>Navigation menu</h2>
<div id="mw-head">
<div aria-labelledby="p-personal-label" class="" id="p-personal" role="navigation">
<h3 id="p-personal-label">Personal tools</h3>
<ul>
<li id="pt-anonuserpage">Not logged in</li>
<li id="pt-anontalk"><a accesskey="n" href="/wiki/Special:MyTalk" title="Discussion about edits from this IP address [n]">Talk</a></li><li id="pt-anoncontribs"><a accesskey="y" href="/wiki/Special:MyContributions" title="A list of edits made from this IP address [y]">Contributions</a></li><li id="pt-createaccount"><a href="/w/index.php?title=Special:CreateAccount&amp;returnto=Supervised+learning" title="You are encouraged to create an account and log in; however, it is not mandatory">Create account</a></li><li id="pt-login"><a accesskey="o" href="/w/index.php?title=Special:UserLogin&amp;returnto=Supervised+learning" title="You're encouraged to log in; however, it's not mandatory. [o]">Log in</a></li>
</ul>
</div>
<div id="left-navigation">
<div aria-labelledby="p-namespaces-label" class="vectorTabs" id="p-namespaces" role="navigation">
<h3 id="p-namespaces-label">Namespaces</h3>
<ul>
<li class="selected" id="ca-nstab-main"><a accesskey="c" href="/wiki/Supervised_learning" title="View the content page [c]">Article</a></li><li id="ca-talk"><a accesskey="t" href="/wiki/Talk:Supervised_learning" rel="discussion" title="Discussion about the content page [t]">Talk</a></li>
</ul>
</div>
<div aria-labelledby="p-variants-label" class="vectorMenu emptyPortlet" id="p-variants" role="navigation">
<input aria-labelledby="p-variants-label" class="vectorMenuCheckbox" type="checkbox"/>
<h3 id="p-variants-label">
<span>Variants</span>
</h3>
<ul class="menu">
</ul>
</div>
</div>
<div id="right-navigation">
<div aria-labelledby="p-views-label" class="vectorTabs" id="p-views" role="navigation">
<h3 id="p-views-label">Views</h3>
<ul>
<li class="collapsible selected" id="ca-view"><a href="/wiki/Supervised_learning">Read</a></li><li class="collapsible" id="ca-edit"><a accesskey="e" href="/w/index.php?title=Supervised_learning&amp;action=edit" title="Edit this page [e]">Edit</a></li><li class="collapsible" id="ca-history"><a accesskey="h" href="/w/index.php?title=Supervised_learning&amp;action=history" title="Past revisions of this page [h]">View history</a></li>
</ul>
</div>
<div aria-labelledby="p-cactions-label" class="vectorMenu emptyPortlet" id="p-cactions" role="navigation">
<input aria-labelledby="p-cactions-label" class="vectorMenuCheckbox" type="checkbox"/>
<h3 id="p-cactions-label">
<span>More</span>
</h3>
<ul class="menu">
</ul>
</div>
<div id="p-search" role="search">
<h3>
<label for="searchInput">Search</label>
</h3>
<form action="/w/index.php" id="searchform">
<div id="simpleSearch">
<input accesskey="f" id="searchInput" name="search" placeholder="Search Wikipedia" title="Search Wikipedia [f]" type="search"/>
<input name="title" type="hidden" value="Special:Search"/>
<input class="searchButton mw-fallbackSearchButton" id="mw-searchButton" name="fulltext" title="Search Wikipedia for this text" type="submit" value="Search"/>
<input class="searchButton" id="searchButton" name="go" title="Go to a page with this exact name if it exists" type="submit" value="Go"/>
</div>
</form>
</div>
</div>
</div>
<div id="mw-panel">
<div id="p-logo" role="banner">
<a class="mw-wiki-logo" href="/wiki/Main_Page" title="Visit the main page"></a>
</div>
<div aria-labelledby="p-navigation-label" class="portal" id="p-navigation" role="navigation">
<h3 id="p-navigation-label">
    			Navigation
    		</h3>
<div class="body">
<ul><li id="n-mainpage-description"><a accesskey="z" href="/wiki/Main_Page" title="Visit the main page [z]">Main page</a></li><li id="n-contents"><a href="/wiki/Wikipedia:Contents" title="Guides to browsing Wikipedia">Contents</a></li><li id="n-featuredcontent"><a href="/wiki/Wikipedia:Featured_content" title="Featured content – the best of Wikipedia">Featured content</a></li><li id="n-currentevents"><a href="/wiki/Portal:Current_events" title="Find background information on current events">Current events</a></li><li id="n-randompage"><a accesskey="x" href="/wiki/Special:Random" title="Load a random article [x]">Random article</a></li><li id="n-sitesupport"><a href="https://donate.wikimedia.org/wiki/Special:FundraiserRedirector?utm_source=donate&amp;utm_medium=sidebar&amp;utm_campaign=C13_en.wikipedia.org&amp;uselang=en" title="Support us">Donate to Wikipedia</a></li><li id="n-shoplink"><a href="//shop.wikimedia.org" title="Visit the Wikipedia store">Wikipedia store</a></li></ul>
</div>
</div>
<div aria-labelledby="p-interaction-label" class="portal" id="p-interaction" role="navigation">
<h3 id="p-interaction-label">
    			Interaction
    		</h3>
<div class="body">
<ul><li id="n-help"><a href="/wiki/Help:Contents" title="Guidance on how to use and edit Wikipedia">Help</a></li><li id="n-aboutsite"><a href="/wiki/Wikipedia:About" title="Find out about Wikipedia">About Wikipedia</a></li><li id="n-portal"><a href="/wiki/Wikipedia:Community_portal" title="About the project, what you can do, where to find things">Community portal</a></li><li id="n-recentchanges"><a accesskey="r" href="/wiki/Special:RecentChanges" title="A list of recent changes in the wiki [r]">Recent changes</a></li><li id="n-contactpage"><a href="//en.wikipedia.org/wiki/Wikipedia:Contact_us" title="How to contact Wikipedia">Contact page</a></li></ul>
</div>
</div>
<div aria-labelledby="p-tb-label" class="portal" id="p-tb" role="navigation">
<h3 id="p-tb-label">
    			Tools
    		</h3>
<div class="body">
<ul><li id="t-whatlinkshere"><a accesskey="j" href="/wiki/Special:WhatLinksHere/Supervised_learning" title="List of all English Wikipedia pages containing links to this page [j]">What links here</a></li><li id="t-recentchangeslinked"><a accesskey="k" href="/wiki/Special:RecentChangesLinked/Supervised_learning" rel="nofollow" title="Recent changes in pages linked from this page [k]">Related changes</a></li><li id="t-upload"><a accesskey="u" href="/wiki/Wikipedia:File_Upload_Wizard" title="Upload files [u]">Upload file</a></li><li id="t-specialpages"><a accesskey="q" href="/wiki/Special:SpecialPages" title="A list of all special pages [q]">Special pages</a></li><li id="t-permalink"><a href="/w/index.php?title=Supervised_learning&amp;oldid=949790121" title="Permanent link to this revision of the page">Permanent link</a></li><li id="t-info"><a href="/w/index.php?title=Supervised_learning&amp;action=info" title="More information about this page">Page information</a></li><li id="t-wikibase"><a accesskey="g" href="https://www.wikidata.org/wiki/Special:EntityPage/Q334384" title="Link to connected data repository item [g]">Wikidata item</a></li><li id="t-cite"><a href="/w/index.php?title=Special:CiteThisPage&amp;page=Supervised_learning&amp;id=949790121&amp;wpFormIdentifier=titleform" title="Information on how to cite this page">Cite this page</a></li></ul>
</div>
</div>
<div aria-labelledby="p-coll-print_export-label" class="portal" id="p-coll-print_export" role="navigation">
<h3 id="p-coll-print_export-label">
    			Print/export
    		</h3>
<div class="body">
<ul><li id="coll-create_a_book"><a href="/w/index.php?title=Special:Book&amp;bookcmd=book_creator&amp;referer=Supervised+learning">Create a book</a></li><li id="coll-download-as-rl"><a href="/w/index.php?title=Special:ElectronPdf&amp;page=Supervised+learning&amp;action=show-download-screen">Download as PDF</a></li><li id="t-print"><a accesskey="p" href="/w/index.php?title=Supervised_learning&amp;printable=yes" title="Printable version of this page [p]">Printable version</a></li></ul>
</div>
</div>
<div aria-labelledby="p-lang-label" class="portal" id="p-lang" role="navigation">
<h3 id="p-lang-label">
    			Languages
    		</h3>
<div class="body">
<ul><li class="interlanguage-link interwiki-ar"><a class="interlanguage-link-target" href="https://ar.wikipedia.org/wiki/%D8%AA%D8%B9%D9%84%D9%8A%D9%85_%D9%85%D8%B1%D8%A7%D9%82%D8%A8_(%D8%A8%D8%A7%D9%84%D8%A5%D8%B4%D8%B1%D8%A7%D9%81)" hreflang="ar" lang="ar" title="تعليم مراقب (بالإشراف) – Arabic">العربية</a></li><li class="interlanguage-link interwiki-bn"><a class="interlanguage-link-target" href="https://bn.wikipedia.org/wiki/%E0%A6%A4%E0%A6%A4%E0%A7%8D%E0%A6%A4%E0%A7%8D%E0%A6%AC%E0%A6%BE%E0%A6%AC%E0%A6%A7%E0%A6%BE%E0%A6%A8%E0%A7%87_%E0%A6%9C%E0%A7%8D%E0%A6%9E%E0%A6%BE%E0%A6%A8%E0%A6%BE%E0%A6%B0%E0%A7%8D%E0%A6%9C%E0%A6%A8" hreflang="bn" lang="bn" title="তত্ত্বাবধানে জ্ঞানার্জন – Bangla">বাংলা</a></li><li class="interlanguage-link interwiki-zh-min-nan"><a class="interlanguage-link-target" href="https://zh-min-nan.wikipedia.org/wiki/K%C3%A0m-tok_ha%CC%8Dk-si%CC%8Dp" hreflang="nan" lang="nan" title="Kàm-tok ha̍k-si̍p – Chinese (Min Nan)">Bân-lâm-gú</a></li><li class="interlanguage-link interwiki-ca"><a class="interlanguage-link-target" href="https://ca.wikipedia.org/wiki/Aprenentatge_supervisat" hreflang="ca" lang="ca" title="Aprenentatge supervisat – Catalan">Català</a></li><li class="interlanguage-link interwiki-cs"><a class="interlanguage-link-target" href="https://cs.wikipedia.org/wiki/U%C4%8Den%C3%AD_s_u%C4%8Ditelem" hreflang="cs" lang="cs" title="Učení s učitelem – Czech">Čeština</a></li><li class="interlanguage-link interwiki-de"><a class="interlanguage-link-target" href="https://de.wikipedia.org/wiki/%C3%9Cberwachtes_Lernen" hreflang="de" lang="de" title="Überwachtes Lernen – German">Deutsch</a></li><li class="interlanguage-link interwiki-el"><a class="interlanguage-link-target" href="https://el.wikipedia.org/wiki/%CE%95%CF%80%CE%B9%CE%B2%CE%BB%CE%B5%CF%80%CF%8C%CE%BC%CE%B5%CE%BD%CE%B7_%CE%BC%CE%AC%CE%B8%CE%B7%CF%83%CE%B7" hreflang="el" lang="el" title="Επιβλεπόμενη μάθηση – Greek">Ελληνικά</a></li><li class="interlanguage-link interwiki-es"><a class="interlanguage-link-target" href="https://es.wikipedia.org/wiki/Aprendizaje_supervisado" hreflang="es" lang="es" title="Aprendizaje supervisado – Spanish">Español</a></li><li class="interlanguage-link interwiki-fa"><a class="interlanguage-link-target" href="https://fa.wikipedia.org/wiki/%DB%8C%D8%A7%D8%AF%DA%AF%DB%8C%D8%B1%DB%8C_%D8%A8%D8%A7_%D9%86%D8%B8%D8%A7%D8%B1%D8%AA" hreflang="fa" lang="fa" title="یادگیری با نظارت – Persian">فارسی</a></li><li class="interlanguage-link interwiki-fr"><a class="interlanguage-link-target" href="https://fr.wikipedia.org/wiki/Apprentissage_supervis%C3%A9" hreflang="fr" lang="fr" title="Apprentissage supervisé – French">Français</a></li><li class="interlanguage-link interwiki-ko"><a class="interlanguage-link-target" href="https://ko.wikipedia.org/wiki/%EC%A7%80%EB%8F%84_%ED%95%99%EC%8A%B5" hreflang="ko" lang="ko" title="지도 학습 – Korean">한국어</a></li><li class="interlanguage-link interwiki-hy"><a class="interlanguage-link-target" href="https://hy.wikipedia.org/wiki/%D5%8E%D5%A5%D6%80%D5%A1%D5%B0%D5%BD%D5%AF%D5%BE%D5%B8%D5%B2_%D5%B8%D6%82%D5%BD%D5%B8%D6%82%D6%81%D5%B8%D6%82%D5%B4" hreflang="hy" lang="hy" title="Վերահսկվող ուսուցում – Armenian">Հայերեն</a></li><li class="interlanguage-link interwiki-it"><a class="interlanguage-link-target" href="https://it.wikipedia.org/wiki/Apprendimento_supervisionato" hreflang="it" lang="it" title="Apprendimento supervisionato – Italian">Italiano</a></li><li class="interlanguage-link interwiki-he"><a class="interlanguage-link-target" href="https://he.wikipedia.org/wiki/%D7%9C%D7%9E%D7%99%D7%93%D7%94_%D7%9E%D7%95%D7%A0%D7%97%D7%99%D7%AA" hreflang="he" lang="he" title="למידה מונחית – Hebrew">עברית</a></li><li class="interlanguage-link interwiki-ja"><a class="interlanguage-link-target" href="https://ja.wikipedia.org/wiki/%E6%95%99%E5%B8%AB%E3%81%82%E3%82%8A%E5%AD%A6%E7%BF%92" hreflang="ja" lang="ja" title="教師あり学習 – Japanese">日本語</a></li><li class="interlanguage-link interwiki-or"><a class="interlanguage-link-target" href="https://or.wikipedia.org/wiki/%E0%AC%B8%E0%AD%81%E0%AC%AA%E0%AC%B0%E0%AC%AD%E0%AC%BE%E0%AC%87%E0%AC%9C%E0%AC%A1_%E0%AC%B2%E0%AC%B0%E0%AD%8D%E0%AC%A3%E0%AC%BF%E0%AC%82" hreflang="or" lang="or" title="ସୁପରଭାଇଜଡ ଲର୍ଣିଂ – Odia">ଓଡ଼ିଆ</a></li><li class="interlanguage-link interwiki-pl"><a class="interlanguage-link-target" href="https://pl.wikipedia.org/wiki/Uczenie_nadzorowane" hreflang="pl" lang="pl" title="Uczenie nadzorowane – Polish">Polski</a></li><li class="interlanguage-link interwiki-ru"><a class="interlanguage-link-target" href="https://ru.wikipedia.org/wiki/%D0%9E%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5_%D1%81_%D1%83%D1%87%D0%B8%D1%82%D0%B5%D0%BB%D0%B5%D0%BC" hreflang="ru" lang="ru" title="Обучение с учителем – Russian">Русский</a></li><li class="interlanguage-link interwiki-simple"><a class="interlanguage-link-target" href="https://simple.wikipedia.org/wiki/Supervised_learning" hreflang="en-simple" lang="en-simple" title="Supervised learning – Simple English">Simple English</a></li><li class="interlanguage-link interwiki-ckb"><a class="interlanguage-link-target" href="https://ckb.wikipedia.org/wiki/%D9%81%DB%8E%D8%B1%D8%A8%D9%88%D9%88%D9%86%DB%8C_%DA%86%D8%A7%D9%88%D8%AF%DB%8E%D8%B1%DB%8C%DA%A9%D8%B1%D8%A7%D9%88" hreflang="ckb" lang="ckb" title="فێربوونی چاودێریکراو – Central Kurdish">کوردی</a></li><li class="interlanguage-link interwiki-fi"><a class="interlanguage-link-target" href="https://fi.wikipedia.org/wiki/Ohjattu_oppiminen" hreflang="fi" lang="fi" title="Ohjattu oppiminen – Finnish">Suomi</a></li><li class="interlanguage-link interwiki-th"><a class="interlanguage-link-target" href="https://th.wikipedia.org/wiki/%E0%B8%81%E0%B8%B2%E0%B8%A3%E0%B9%80%E0%B8%A3%E0%B8%B5%E0%B8%A2%E0%B8%99%E0%B8%A3%E0%B8%B9%E0%B9%89%E0%B9%81%E0%B8%9A%E0%B8%9A%E0%B8%A1%E0%B8%B5%E0%B8%9C%E0%B8%B9%E0%B9%89%E0%B8%AA%E0%B8%AD%E0%B8%99" hreflang="th" lang="th" title="การเรียนรู้แบบมีผู้สอน – Thai">ไทย</a></li><li class="interlanguage-link interwiki-tr"><a class="interlanguage-link-target" href="https://tr.wikipedia.org/wiki/G%C3%B6zetimli_%C3%B6%C4%9Frenme" hreflang="tr" lang="tr" title="Gözetimli öğrenme – Turkish">Türkçe</a></li><li class="interlanguage-link interwiki-uk"><a class="interlanguage-link-target" href="https://uk.wikipedia.org/wiki/%D0%9D%D0%B0%D0%B2%D1%87%D0%B0%D0%BD%D0%BD%D1%8F_%D0%B7_%D1%83%D1%87%D0%B8%D1%82%D0%B5%D0%BB%D0%B5%D0%BC" hreflang="uk" lang="uk" title="Навчання з учителем – Ukrainian">Українська</a></li><li class="interlanguage-link interwiki-vi"><a class="interlanguage-link-target" href="https://vi.wikipedia.org/wiki/H%E1%BB%8Dc_c%C3%B3_gi%C3%A1m_s%C3%A1t" hreflang="vi" lang="vi" title="Học có giám sát – Vietnamese">Tiếng Việt</a></li><li class="interlanguage-link interwiki-zh-yue"><a class="interlanguage-link-target" href="https://zh-yue.wikipedia.org/wiki/%E7%9B%A3%E7%9D%A3%E5%BC%8F%E5%AD%B8%E7%BF%92" hreflang="yue" lang="yue" title="監督式學習 – Cantonese">粵語</a></li><li class="interlanguage-link interwiki-zh"><a class="interlanguage-link-target" href="https://zh.wikipedia.org/wiki/%E7%9B%A3%E7%9D%A3%E5%BC%8F%E5%AD%B8%E7%BF%92" hreflang="zh" lang="zh" title="監督式學習 – Chinese">中文</a></li></ul>
<div class="after-portlet after-portlet-lang"><span class="wb-langlinks-edit wb-langlinks-link"><a class="wbc-editpage" href="https://www.wikidata.org/wiki/Special:EntityPage/Q334384#sitelinks-wikipedia" title="Edit interlanguage links">Edit links</a></span></div>
</div>
</div>
</div>
</div>
<div id="footer" role="contentinfo">
<ul class="" id="footer-info">
<li id="footer-info-lastmod"> This page was last edited on 8 April 2020, at 15:00<span class="anonymous-show"> (UTC)</span>.</li>
<li id="footer-info-copyright">Text is available under the <a href="//en.wikipedia.org/wiki/Wikipedia:Text_of_Creative_Commons_Attribution-ShareAlike_3.0_Unported_License" rel="license">Creative Commons Attribution-ShareAlike License</a><a href="//creativecommons.org/licenses/by-sa/3.0/" rel="license" style="display:none;"></a>;
additional terms may apply.  By using this site, you agree to the <a href="//foundation.wikimedia.org/wiki/Terms_of_Use">Terms of Use</a> and <a href="//foundation.wikimedia.org/wiki/Privacy_policy">Privacy Policy</a>. Wikipedia® is a registered trademark of the <a href="//www.wikimediafoundation.org/">Wikimedia Foundation, Inc.</a>, a non-profit organization.</li>
</ul>
<ul class="" id="footer-places">
<li id="footer-places-privacy"><a class="extiw" href="https://foundation.wikimedia.org/wiki/Privacy_policy" title="wmf:Privacy policy">Privacy policy</a></li>
<li id="footer-places-about"><a href="/wiki/Wikipedia:About" title="Wikipedia:About">About Wikipedia</a></li>
<li id="footer-places-disclaimer"><a href="/wiki/Wikipedia:General_disclaimer" title="Wikipedia:General disclaimer">Disclaimers</a></li>
<li id="footer-places-contact"><a href="//en.wikipedia.org/wiki/Wikipedia:Contact_us">Contact Wikipedia</a></li>
<li id="footer-places-developers"><a href="https://www.mediawiki.org/wiki/Special:MyLanguage/How_to_contribute">Developers</a></li>
<li id="footer-places-statslink"><a href="https://stats.wikimedia.org/#/en.wikipedia.org">Statistics</a></li>
<li id="footer-places-cookiestatement"><a href="https://foundation.wikimedia.org/wiki/Cookie_statement">Cookie statement</a></li>
<li id="footer-places-mobileview"><a class="noprint stopMobileRedirectToggle" href="//en.m.wikipedia.org/w/index.php?title=Supervised_learning&amp;mobileaction=toggle_view_mobile">Mobile view</a></li>
</ul>
<ul class="noprint" id="footer-icons">
<li id="footer-copyrightico"><a href="https://wikimediafoundation.org/"><img alt="Wikimedia Foundation" height="31" src="/static/images/wikimedia-button.png" srcset="/static/images/wikimedia-button-1.5x.png 1.5x, /static/images/wikimedia-button-2x.png 2x" width="88"/></a></li>
<li id="footer-poweredbyico"><a href="https://www.mediawiki.org/"><img alt="Powered by MediaWiki" height="31" src="/static/images/poweredby_mediawiki_88x31.png" srcset="/static/images/poweredby_mediawiki_132x47.png 1.5x, /static/images/poweredby_mediawiki_176x62.png 2x" width="88"/></a></li>
</ul>
<div style="clear: both;"></div>
</div>
<script>(RLQ=window.RLQ||[]).push(function(){mw.config.set({"wgPageParseReport":{"limitreport":{"cputime":"0.360","walltime":"0.618","ppvisitednodes":{"value":1413,"limit":1000000},"postexpandincludesize":{"value":32877,"limit":2097152},"templateargumentsize":{"value":2429,"limit":2097152},"expansiondepth":{"value":15,"limit":40},"expensivefunctioncount":{"value":2,"limit":500},"unstrip-depth":{"value":1,"limit":20},"unstrip-size":{"value":13163,"limit":5000000},"entityaccesscount":{"value":2,"limit":400},"timingprofile":["100.00%  367.489      1 -total"," 58.40%  214.618      1 Template:Reflist"," 35.58%  130.741      1 Template:Cite_conference"," 18.72%   68.777      2 Template:ISBN"," 18.48%   67.928      1 Template:Short_description"," 13.82%   50.805      2 Template:Pagetype"," 12.64%   46.444      1 Template:Machine_learning_bar"," 11.63%   42.750      1 Template:Sidebar_with_collapsible_lists"," 10.07%   36.989      2 Template:Catalog_lookup_link","  6.70%   24.621      1 Template:Longitem"]},"scribunto":{"limitreport-timeusage":{"value":"0.091","limit":"10.000"},"limitreport-memusage":{"value":2670047,"limit":52428800}},"cachereport":{"origin":"mw1377","timestamp":"20200408150108","ttl":2592000,"transientcontent":false}}});});</script>
<script type="application/ld+json">{"@context":"https:\/\/schema.org","@type":"Article","name":"Supervised learning","url":"https:\/\/en.wikipedia.org\/wiki\/Supervised_learning","sameAs":"http:\/\/www.wikidata.org\/entity\/Q334384","mainEntity":"http:\/\/www.wikidata.org\/entity\/Q334384","author":{"@type":"Organization","name":"Contributors to Wikimedia projects"},"publisher":{"@type":"Organization","name":"Wikimedia Foundation, Inc.","logo":{"@type":"ImageObject","url":"https:\/\/www.wikimedia.org\/static\/images\/wmf-hor-googpub.png"}},"datePublished":"2002-01-08T05:43:27Z","dateModified":"2020-04-08T15:00:59Z","image":"https:\/\/upload.wikimedia.org\/wikipedia\/commons\/f\/fe\/Kernel_Machine.svg","headline":"machine learning task of learning a function that maps an input to an output based on example input-output pairs"}</script>
<script>(RLQ=window.RLQ||[]).push(function(){mw.config.set({"wgBackendResponseTime":110,"wgHostname":"mw1368"});});</script></body></html>
